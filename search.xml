<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[QIs for All Quality Aspects]]></title>
    <url>%2F2019%2F03%2F06%2Fallaspects%2F</url>
    <content type="text"><![CDATA[一方面一拖再拖，一方面后面的 indicators 很多都是单独的一整篇论文，并非后面的一小部分，阅读并理解起来比较吃力，也有很多地方只看了算法步骤，而没有细看具体推导与证明，其中一篇，记忆很深刻，姚老师的 DoM-indicator 行文很严谨，并且断断续续看了四天才大概理解。 这类中的质量指标在文献中最常用，因为它们涵盖了解决方案集质量的所有四个方面。表2中的75-100项列出了这些QIs。一般可分为两类:基于距离的QIs(项目75-91)和基于容量的QIs(项目92-100)。 distance-based QIs： volume-based QIs： Distance-based QIs基于距离的QIs的基本思想是测量PF到所考虑解集的距离。因此，需要一个能很好地表示PF的参考集(reference set)。只有接近参考集的每个成员的解集才能有一个好的评估值，从而反映所有质量方面的收敛性、扩散性、一致性和基数性。这个想法可以通过平均(或累加)引用集的成员到解集中它们最近的解的距离，或者从这些距离中找到最大值来实现。对于前者，反向代际距离(IGD)是一个典型的例子，它考虑了平均值欧氏距离。其他的例子包括Dist1(D1)和一些IGD的变异。他们使用差异距离度量(如Tchebycheff distance和Hausdorff distance)，或者在评价中引入支配关系或附加点。 测量帕累托前沿到解集的最大差分(距离)可以很容易地识别出它们之间的差距，从而判断解集在前沿是否具有良好的覆盖性。Dist2(D2)和$\epsilon$-indicator就是这样的QIs。Dist2指标考虑Tchebycheff距离，而$\epsilon$-indicator考虑的是在目标上的最大区别：参考集的点优越于所考虑的解。与averaging difference-based QIs不同，maximum difference-based QIs可能具有明确的物理意义；例如，$\epsilon$-indicator是测量最小值添加到任何的解将使它被至少一个参考点集所weakly dominated。然而，他们的结果通常只涉及到一个特定目标的一个特解，因此自然会有大量的信息丢失。 最近提出了一种质量指标，称为优势移动(DoM)，它可以看作是上述两种QIs的组合。具体地说，给定两个解集A和B，A到B的DoM是移动A中一些点以便B中的任意一点都至少由A中的一点所支配。这种直观的指标具有许多可取的性质，如两种解决方案比较的自然延伸，符合帕累托优势，不需要问题知识和参数。然而，它的计算并不简单。虽然提出了一种双目标情况下的高效计算方法，但如何在有三个或三个以上目标的情况下高效计算仍有待探索。值得一提的是，早期的质量指标[126]可以看作是DoM的简化版本。它划分了引用集(即，$A\cup B$)为许多集群,将A对每个簇的最大差分累加。这使得计算变得高效，但是自然地失去了它的物理意义。 Inverted Generational Distance(IGD)它是最常用的指标之一，尽管之前提出了一些类似的观点。顾名思义，IGD是GD指标的反演，即测量从帕累托前沿到解集的距离。 形式上，给定解集A和参考集 $R=\{ r_1,r_2,…,r_M \}$ IGD(A,R) = \frac{1}{M} \sum_{i=1}^M \min_{a \in A} d_2(r_i,a)$d_2(r_i,a)$ 表示 $r_i$ 与 $a$ 的欧式距离。IGD值越低越好，说明该集合具有较好的收敛性、扩散性、均匀性和基数性的组合特性。 然而，IGD评估的准确性在很大程度上取决于参考集对帕累托前沿的逼近质量。不同的参考集可以使指标偏好不同的解集。通常建议对帕累托前沿采用高分辨率的大参考集。如[89,92]所示，集合中点数不足很容易导致反直觉的评价。此外，由优化器生成的所有非支配解决方案组成的引用集也可能导致误导结果，尽管这种做法在实际问题中得到了广泛采用。 Front to set distance看了好几遍，没有发现和IGD有什么不同，，，笨死了 为了度量MOEA的性能，我们只考虑运行MOEA所产生的最终总体中包含的所有非支配解决方案的子集。我们称这样的子集为近似集并用 $S$ 表示。近似集的大小取决于用于运行MOEA的设置。此指标计算离散帕累托最优集中每个解到近似集S中最近解的距离，并取平均值作为指标值： D_{P_F \rightarrow S}(S) = \frac{1}{|P_S|} \sum_{z^1 \in P_S}\min_{z^0 \in S}\{ d(z^0,z^1) \}由于我们感兴趣的是在目标空间中测量性能，两个多目标解 $z^0$ 和 $z^1$ 之间的距离就是它们的目标值 $f(z^0)$ 和 $f(z^1)$ 之间的欧氏距离。$D_{P_F \rightarrow S}(S) $ 指标既表示接近帕累托最优前沿的目标，也表示得到一个diverse、wide-spread 解决方案前沿的目标。这个性能指标的值越小越好。一个与此indicator密切相关的性能指标的hypervolume指标。在hypervolume指示器中，选择目标空间中的一个点，使其由需要测量的近似集中的所有点支配。然后，指示值等于由逼近集和所选参考点包围的多维区域的超体积。这个值是由近似集支配的目标空间中区域的指标。hypervolume 指示器和 $D_{P_F \rightarrow S} $ 指示器之间的主要区别在于，对于 hypervolume 指示器，必须选择一个参考点。不同的参考点导致不同的指示值。此外，不同的参考点可能导致指示值表明对不同的近似集的偏好。由于在 $D_{P_F \rightarrow S} $ 指标中使用了真正的帕累托最优前沿，因此 $D_{P_F \rightarrow S} $ 指标并不适用于此缺点。当然， $D_{P_F \rightarrow S} $ 指标的一个主要缺点是，在实际应用中，真正的帕累托最优前沿是未知的。在这种情况下，所有逼近集的帕累托前缘可以用来代替实际的帕累托最优前缘。 Delineation of Pareto Optimal Front介绍了描述度量 $\Phi$ 评价收敛性和多样性的程度一个已知的帕累托最优。本研究的目标是确定一组能够很好地表示帕累托最优。这个度量背后的思想是在帕累托最优前沿上的每个解能被已得到的非支配解有多好的表示出来。计算描述度量 $\Phi$ ，大量的H等间隔的解必须知道以反映真实帕累托最优前沿的帕累托最优集。用于计算的距离度量 $\gamma$ 同一组 $H$ 解决方案使用。从每个帕累托最优解到以获得的解 $l_i$ 的欧氏距离,这距离的平均值作为描述度量 $\Phi$,也就是说: \Phi(P_T) = \frac{1}{H} \sum_{i=1}^H l_i需要注意的是，在计算这个度量时，要考虑算法获得的所有解，包括那些受支配的解。 Dist1(D1)我们假设 $M$ 是一个好的 R 的近似解，如果它可以给 $R$ 中的所有地区的重要信息，换句话说，如果对于每一个解 $y \in R$ ，这里都有一个比较接近的解 $x \in M$ 。我们建议用以下基于成就尺度函数的度量方法来度量两个解的亲密性： c(x,y) = \max_{j=0,...,J}\{0,w_j(f_j(y)-f(j(x) )\}$J$ 为目标函数的个数。因此，如果在所有目标上x达到解y的值，则测量值为0。否则，它取特定目标相对于y的最大加权偏差值。上述表达式中使用的权重设置为： w_j = 1 / \Delta_j其中，$\Delta_j$ 是在reference set的 $f_j$ 的范围。 Dist1=\frac{1}{card\{R\}} \sum_{y \in R} \{ min_{x \in M} \{c(x,y)\} \}Dist2(D2) Dist2= \max_{y \in R} \{ min_{x \in M} \{c(x,y)\} \}第一个度量给出关于 $y \in R$ 到 $M$ 中最接近解的平均距离的信息，而第二个度量给出关于最坏情况的信息。值越低，集合 $M$ 越接近集合 $R$。而且，$Dist2/Dist1$ 比值越低，从集合 $M$ 到集合 $R$ 的解分布越均匀。 $\epsilon$-indicator$\epsilon$-indicator 考虑sets之间的最大差异，它是受$\epsilon$-approximation所感，著名的测量设计和比较近似优化算法,运筹学和理论计算机科学。给定两个解集，$\epsilon$-indicator是一个集合在目标中被转换(以加法或乘法的方式)以弱支配另一个集合的最小因子。这就产生了两个版本:加法$\epsilon$-indicator和乘法$\epsilon$-indicator。数学上，解集A对于解集B的加法$\epsilon$-indicator定义如下： \epsilon_+(A,B) = \max_{b \in B} \min_{a \in A} \max_{j \in \{1...m\}} a_j - b_j$a_j$ 是 $a$ 的第 j 个目标，$m$ 是目标函数的个数。解集A对于解集B的乘法$\epsilon$-indicator定义如下： \epsilon_\times(A,B) = \max_{b \in B} \min_{a \in A} \max_{j \in \{1...m\}} \frac{a_j}{ b_j}这两个indicators都是越小越好。$\epsilon_+(A,B) \leq 0$ 或者 $\epsilon_\times(A,B) \leq 1$ 意味着 A weakly dominate B。当用代表PF的参考集R替换B时，$\epsilon$-indicator可以用作一元指标。它衡量的是被考虑的集合到帕累托前沿的距离。但是，由于返回的值只涉及两个集合中一个特解的一个特定目标(其中最大的差异)，指示器可能会忽略大量集合的差异。这可能导致不同执行的解决方案集具有相同/类似的评估结果。 (前提每个目标都是越小越好)对于加法拆解理解：设 $k = \min_{a \in A} \max_{j \in \{1…m\}} a_j - b_j$ 就是说对于B中指定一个解 $B_i$ ,把A中所有的解都减 $k$，那么A中至少(意味着min)存在一个解可以 weakly dominate $B_i$ ；如果遍历所有的$B$，那么需要取最大的那个 $k$，才能满足把 $A$ 中所有解都减掉 $k$ ，对于B任意一个解，A中都存在解可以 weakly dominate。对于乘法同理。 具体例子如图： 可知：$\epsilon_+(A_1,A_2) = 1$,$\epsilon_+(A_1,A_3) = 9/10$,$\epsilon_+(A_1,P) = 4$ $A_1$=(4,7),(5,6),(7,5),(8,4),(9,2) $A_3$=(6,8),(7,7)(8,6)(9,5)(10,4) 因为，想求 $\epsilon_+(A_1,A_3) $ 因此，先遍历 $A_3$ 中的元素，定性上说，在 $A_1$ 中里此元素越远，$k = \min_{a \in A_1} \max_{j \in \{1…m\}} a_j / b_j$越难被选上。 最后可以看到，(9,2) 与 (10,4) 的距离为标准，求得的结果，(10,4) 刚好在边缘上，且也可以看到，横轴间的距离差会比纵轴间的间隔会更大，因为横轴的数值就大。 ObjIGDObjective-wise Inverse Generational Distance(ObjIGD) ObjIGD度量评估MaOOA在每个目标上的收敛性和分布性能。ObjIGD的主要思想类似于IGD度量，然而ObjIGD测量的是PF与最接近的解决方案之间基于一个目标的距离。第i个目标的对象定义如下： ObjIGD_i(S,P)=\frac{ \sum_{j=1}^{|P|} \min_{s \in S}|F_i(p_j)-F_i(s)| }{|P|}$P$ 是 reference($PF_{true}$)。$S$ 是 $PF$ 近似集。$F_i(p_j)$ 是第$ i$ 个目标的第 $j$ 个解，$F_i(s)$ 是近似解的第 $i$ 个目标，因此，整体$ObjIGD$为： ObjIGD(S,P)=\frac{\sum_{i=1}^M ObjIGD_i(S,P)}{M}其中，$ObjIGD_i(S,P)$ 是第 $i$ 个目标的 $ObjIGD$ 的值，$M$ 是目标函数的个数。测度值越低，表明目标的收敛性和分布性越好。 IGD-NS在 IGD 计算中，我们经常发现，一些非支配解往往被忽略，因为它们不是均匀地从Pareto optimal front选取的计算 IGD 的任意参考点的最近邻。这意味着这些非支配解集中的解对集合的IGD值没有任何贡献，因此在逼近帕累托最优前沿方面，它们的重要性低于集合中其他非支配解。因此，我们将这些解称为非支配解集中的无贡献解(noncontributing)。具体地说，无贡献解的定义如下。 解 $y’$ 被认为在解集 $P$ 中，对于解 $P^*$是无贡献解，满足： \nexists x \in P^*:dist(x,y')=\min_{y \in P}dist(x,y)其中，$P^*$ 是一组参考点均匀采样的帕累托最优。从上面的方程,它可以学到无贡献解不是 $P^*$ 中任意点的最近邻点。 在考虑无贡献解的情况下，将提出的性能度量，即带无贡献解检测的IGD的度量(IGD-NS)，定义如下： IGD-NS(P,P^*)=\sum_{x \in P^*}\min_{y \in P} dis(x,y) + \sum_{y' \in P'}\min_{x \in P^*} dis(x,y')$P’$ 是population中无贡献解，上式的第一部分与IGD类似，控制了 $P$ 的多样性和收敛性；然而第二部分是对于每一个无贡献解到 $P^*$ 中点的最小距离的总和。因此，当且仅当满足以下两个条件时，可以得到一个较小(良好)的IGD-NS度规值:首先，种群具有良好的收敛性和多样性;第二，总体包含尽可能少的无贡献解。 个人理解：就是遍历 $P^*$ 中的每一个点，找到与此点距离最近的 $P$ 中的点都删掉，$P$ 中剩下的就是 $P’$ $IGD_p$ IGD_p(X,Y) = \left( \frac{1}{M}\sum_{i=1}^M dist(y_i,X)^p \right)^{1/p}这个就没有什么好说的了。。。 $\Delta_p$ \Delta_p(X,Y)=\max(GD_p(X,Y),IGD_p(X,Y))\\ =\max \left( \left( \frac{1}{N}\sum_{i=1}^N dist(x_i,Y)^p \right)^{1/p}, \left( \frac{1}{M}\sum_{i=1}^M dist(y_i,X)^p \right)^{1/p} \right)这个也是。。。。 $\epsilon$-performanceε-dominance是一个概念,用户可以指定他们想要的精度得到帕累托最优解决方案的多目标问题,在本质上给他们的能力来分配每个目标的相对重要性。这是通过应用一个网格(由用户指定大小的值)问题的搜索空间。$\epsilon$ 值较大导致巨大网格(和最终减少解决方案),而较小的 $\epsilon$ 值产生一个更精细的网格。每种解决方案的健身然后映射到一个盒子健身根据指定的 $\epsilon$ 值。 $\epsilon$-dominance适用于一套参考解根据用户指定的ε值 在每一代,匹配算法生成的每个解决方案,其相应的 $\epsilon$-nondominated参考集解。每个参考解只能有一个与之相关的算法解。如果存在多个解在 $\epsilon$-nondominated 参考集解，然后用欧氏距离最小的解来选择。这考虑了在参考解中的 $\epsilon$ 重叠地区，并且腾出额外的解与其他 $\epsilon$-nondominated参考解。 Each $\epsilon$-nondominated reference solution that has a corresponding algorithm solution receives a score of one, while each reference solution that has no corresponding algorithm solution receives a score of zero. ： \epsilon(P) = \sum_{i=1}^n h_i/n$h_i$ 是 对于 $\epsilon$-nondominated reference set 的第 $i$ 个解，并且 n 是reference set的个数。 这个指标测量了收敛性通过考虑,聚集在 $\epsilon$ 的引用集的解。多样性是占每个$\epsilon$-nondominated引用包括只有一个解决方案的解决方案,不管$\epsilon$-block额外的解的存在性。这可以确保集群解决方案不会对度量的计算产生影响。 说实话没太看懂，，，怎么个对应(corresponding algorithm)法子。 $I_{SDE}$ I_{SDE}(x,y) = \sqrt{\sum_{1 \leq i \leq m }sd(f_i(x),f_i(y))^2}其中： sd(f_i(x),f_i(y))=\begin{cases} f_i(y)-f_i(x) & if \ f_i(x) < f_i(y)\\ 0 & otherwise \end{cases}m 为目标函数个数。需要计算所有的 x 与 y 对。 PCI定义1：p 为一个点，Q为一组点$\{ q_1,q_2,..,q_k \}$ 。p 对 Q 的支配距离定义为p在目标空间中满足 p weakly dominate 所有的 Q 的最小距离： D(p,Q) = \sqrt{\sum_{i=1}^m(p^{(i)}-d(p^{(i)},Q))^2}其中： d(p^{(i)},Q) = \begin{cases} min\{ q_1^{(i)},q_2^{(i)},...,q_k^{(i)} \},&if \ p^{(i)} > min\{ q_1^{(i)},q_2^{(i)},...,q_k^{(i)} \}\\ p^{(i)},&otherwise \end{cases}$p^{(i)}$ 是 解 p 的第 i 个目标，m 为目标函数的个数。 $D(p,Q)$ 只考虑了 Q 中优于 p 的解，无关差于 p 的解。这可以使指标不受收敛性差的参考点的影响，如优势抵抗解。$D(p,Q)$ 的范围是0到无穷，越小越好。如果 p 在少数的目标函数中，轻微差于 Q ，$D(p,Q)$ 会很小，只有 p weakly dominate Q ：$D(p,Q)=0$ 易证： \max\{D(p,q_1),...,D(p,q_k)\} \leq D(p,Q) < D(p,q_1)+...+D(p,q_k)定义2： P，Q为两个解集。P 对 Q 的支配解集 $D(P,Q)$ 。定义如下：对于任意点 $q \in Q$ 中 P 的最小的总距离，使得至少有一个点 $p \in P$ weakly dominate q。 在该指标中，由于参考集由所有的近似集组成，因此一个聚类可以包含来自不同近似集的点。让一个聚类 C 包含 P 和 Q。$P = \{ p_1,…,p_i \}$ 与 $Q = \{ q_1,…,q_j \}$，显然 $D(P,C) = D(P,Q)$ 。当 $i=1$ 时，$D(P,C)$ 是 $p_1$ 对 C 的理想点的支配距离。当 $i \geq 2$ 时，$D(P,C)$ 可以小于 $\min\{D(p_1,C),…,D(p_i,C)\}$。 如上图：ideal point 代表了 每个cluster中每个函数的最小值 cluster $C_1$ ：$P_1$ 只有一个点，因此 $D(P_1,C_1) = (0.5^2 + 0.5^2)^{0.5} = 0.707$ cluster $C_2$ ：$P_2$ 有两个点，为 $D(P_2,C_2)= 0.559 &lt; \min\{1.031,1.25\}$ ,其中1.031与1.25是 $P_2$中的点分别到ideal point的点的距离。 cluster $C_3$： $P_3$ 是一个极端情况， $D(P_2,C_2)=0$，但是如果单个计算的话均为 1。 由此可以知道：当 $i \geq 2$ 时，$D(P,C)$ 可以小于 $\min\{D(p_1,C),…,D(p_i,C)\}$。这是因为共有 $i^j$ 种可能性，对于$p_1,p_2,…,p_i$ 去分开 $q_1,q_2,…,q_j$ ，就是对于每一个 $q$ 都有 $i$ 个可能性被 $p$ weakly dominate。因此，粗略计算如下： D'(P,C) = \max\{ \min\{ D(p_1,q_1),...,D(p_i,q_1) \},\\ ...\min\{ D(p_1,q_j),...,D(p_i,q_j) \} \}当 $i \geq 2$ 时，这仅仅有 $i \times j$ 个比较，尽管 $D’(P,C) \leq D(P,C)$ ，但是当 $C$ 的尺寸小时差距是很小的，例如：$D’(P_2,C_2) = 0.5 &lt; D(P_2,C_2)=0.559$ 与 $D’(P_3,C_3) = D(P_3,C_3) = 0$ 。 首先。所有的解集都要归一化， 如果评估的近似解小于两个，PCI考虑 the minimum move of one solution in the approximation set to weakly dominate the cluster (Step 8 否则计算the minimum move of the set’s solutions in the cluster to weakly dominate the cluster (Step 10 在 cluster 算法中：使用贪心的方法来逐步合并点根据他们的优势距离。设为归一化超平面上具有N个点理想分布的两个相邻点的区间(优势距离的意义)，其中N为参考集的大小。在这种情况下，$\sigma = 1/h$ 与 $N=C_{m-1+h}^{m-1}$ 其中，$h$ 为每个目标的分支，$m$ 为目标函数的个数，因为： (h+m-1)\times (h+m-2)\times ...\times (h+1) \approx (h + m/2)^{m-1}因此： \sigma \approx \frac{1}{\sqrt[m-1]{N(m-1)!}-(m/2)}G-Metric规定：$A_1,A_2,…,A_m$ 是 m 个NSs(non-dominated sets)： Scale the values of the vectors in the NSs Group the NSs by levels of complete outperformance For each level of complete outperformance and for every $A_i$ in the level, calculate the zone of infuence $I_{A_i}$ For every $A_i$, combine its convergence and DE to create a number that represents its relative performance respect to the other NSs Scale and normalization Take the union of the m sets, $C = \cup_{i=1}^m A_i$ From C take its non-dominated elements.$C^*=ND(C)$ Find $max_j$ and $min_j$ as the max and min value respectively, for the component j for all points $p \in C$ 暗指在known pareto front 中挑选。 Using $max_j$ and $min_j$ make a linear normalization of all points in all $A_i$ . Convergence Component已知 $D={A_1,A_2,…,A_m}$ ，其中 $A_i$ 是一个NS 令 $j=1$ 令 $L_j=\{\}$ 从 D 中提取出，并放入 $L_j$ 中，这些 $A_i$ 满足 $ \urcorner ((\bigcup_{A_k \in D }A_k) \ O_C \ A_i)$ 如果 D 不空，那么 j = j + 1，返回到第二步 结束 注意：这是以每一个NS作为整体的。 $L_1$ 是不能被 D 中除了 $L_1$ 的解所completely outperform。如果$A\in L_j$ ,$B \in L_k$ 并且 $j &lt; k$ ，我们可以知道 A 要好于 B，如下图，这有5个NSs ：A，B，C，D 和 E。我们分三个层次： $L_1 = \{A\}$，$L_2 = \{B,C\}$，$L_3 = \{D,E\}$ Dispersion–Extension Component定义1：$I_{p_i}$ 是一些据点 $p_i$ 的距离小于或等于一个正实数 $U$ 的一些点集，U 可以当作为半径。 定义2：$I_S$ 是 $I_{p_i}$ 的并集，$for \ all \ p_i \in S $ 一般来说(对于点或集合)，我们将影响区域称为I。 $I$ 的测量 $\mu(I)$ ：它是对一个点或NS的注入带的测量。它是对一个点或NS的测量。对于 2d 它意味着是面积，在 3d中意味着体积，依次类推。 如果 S 有一个较差的 DE(Dispersion–Extension)，那么他们中的许多都挨着很近，并且相互交叉，结果 $\mu(I_S)$ 就会变小。现在假设我们重新定位S的元素以改进DE。我们通过增加元素之间的扩展和距离，以及/或使它们的距离更均匀来实现这一点(如下图)。随着我们提高了 DE，$I_{p_i}$ 会下降，与此同时，DE 与 $\mu(I_S)$ 都会增加，因此，$\mu(I_S)$ 正比于DE，并且 $\mu(I_S)$ 是一个好的 DE indicator。 $I_S$ 也正比于 $I_{p_i}$ 之间的交叠。具有良好DE的NSs比具有不良DE的NSs重叠更少。 Computing the G–Metric已知 m 个 非支配解集，$A_1,A_2,…,A_m$ 归一化所有的解集 把所有的解集分类成$A_k$ for k = 1~Q ，其中，Q 是等级的数量。 对于每一个 $A_i \in L_k$ ，消除所有的点 $p \in A_i$，满足 $p$ 被另一个点 $q$ 所支配，$q \in A_j$ 对于任意 $A_j \in L_k$ 翻译一下就是：在 $L_k$ 中留下非支配解，其他的都删去。 计算基于所有的 $A_i \in L_k$ 的 U (下面会详细说) 计算 $\mu(I_{A_i})$ 对每一个 $A_i \in L_k$ (下面会详细说) 对于每一个 k = 1~Q-1 对于所有的 $A_i \in L_k$ : G(A_i) = \mu(I_{A_i}) + \sum_{j = k + 1} ^Q \mu_{max}(L_j)其中，$\mu_{max}(L_j)$ 是 对于 $A_i \in L_j$ 最大的 $\mu(I_{A_i})$ . 例如下图： 这段有点不会了，索性直接贴图了。。。。 Dominance move(DoM)我看了四天！！！ 好多证明和推导，在这里就不解释了…. 定义：$n_R(q)$ ，为在 $R$ 中最接近点 $q$ 的点。 距离测量： D(P,Q) = \min_{P' \preceq Q} \sum_{i = 1}^n d(p_i,p_i')\\ d(p_i,p_i') = \sum_{j=1}^m |p^j_i - p_i'^j|$p_i^j$ 是 在 $P$ 中第 $i$ 个解的第 $j$ 个目标函数。$p’$ 是 $p$ 转移到 $p$ 试支配 $Q$，使得：$Q$ 中的任意一点都可以被 $P^‘$ 支配。$m$ 是目标函数的个数。 d(p,Q_s) = \sum_{j=1}^m(p^j - \min\{ p^j,q^j_{s1},q^j_{s2},...,q^j_{sk} \})m$ 是目标函数的个数。 假设计算 $D(P,Q)$ 删除 $Q$,$P$ 个子中的被支配的解，再删除 $Q$ 中被 $P$ 支配(存在一个就行)的点。 设 $R = P \bigcup Q$ ，首先把 $Q$ 中的每一个点当作一组，然后对于 $Q$ 中的每一个点，在 $R$ 中寻找它的最近邻点；对 $Q$ 中的每一个点，寻找到一个 $ r \in R$ ，使 $r = n_R(q)$ ，如果 $r \in P$ ，那么把 $r$ 归为此 $q$ 一组；如果 $ r \in Q$ ，如果 $q$ 和 $r$ 已经在一组，什么都不需要做，否则，把这两组归为一组。 如果在任何组中不存在 $q \in Q$ ，满足：$q = n_R(n_R(q))$ ，即这两个点互为最近邻，那么结束； 对于有环(互为最近邻)的组，用这两个点的理想点取代这两个点，产生新的集合名为 $Q’$ ，寻找在 $P \bigcup Q’$ 中此理想点的最近邻点，并归类为一组，转向，Step.3 举例： 以下为 在收敛性，一致性，延展性，基数性，四个方面做出比较，效果都不错，但有一个很大的问题就是，只能比较二元问题，对于二元以上的存在一些漏洞，证明上不是充要条件。 Volume-based QIsHypervolume(HV)HV首次作为空间的大小所展示，然后被用作几个专业术语hyperarea metric，S-metric，Lebesgue measure。由于HV指标具有理想的实际可用性和理论特性，因此可以说是最常用的QIs。计算HV不需要表示帕累托前沿的参考集，这使得它适合于许多实际的优化场景。HV结果对帕累托优势集的任何改进都是敏感的。当一个集合A优于另一个集合B时(即,一个A◁B)，然后HV返回A的质量值高于B。因此，对于给定的问题，达到最大HV值的集合将包含所有帕累托最优解。 HV indicator 的定义如下。已知解集A和参考点r, HV可计算为： HV(A) = \lambda(\cup\{ x | a \prec x \prec r \})$\lambda$ 表示勒贝格测度，简而言之，一个集合的HV值可以看作是由每个解和参考点(分别为左底顶点和右顶顶点)确定的超立方体的并集的体积。 HV的局限性是它的数量关于目标数而指数增加的运行时间(除非P=NP)。HV的另一个问题是其参考点的设置。对于如何为给定的问题选择合适的参考点仍然没有共识，尽管有一些常见的实践，例如帕累托前沿的最低点或比较解集集合的最低点的1.1倍。不同的参考点会导致HV评价结果不一致[110]。除了少数特殊情况外，关于高压参考点的选择缺乏系统的研究/理论指导。Recently,have demonstrated a clear difference of specifying the proper reference point for problems with a simplex-like Pareto front and an inverted simplex-like Pareto front. 他们还通过实验表明，一个比最低点稍差的参考点并不总是合适的，特别是在多目标优化和/或小群体规模的情况下。此外，HV指标偏向膝关节区域，偏向凸区域多于凹区域。证明，一组达到最大HV值的解的分布很大程度上取决于帕累托前缘的斜率。例如，HV可能倾向于高度非线性帕累托前缘上非常不均匀的解集。这已经得到证明。 hyperarea ratiohyperarea 定义为 $PF_{known}$ 值所包含的空间，例如，在二维目标优化中，就是原点和函数值所覆盖的矩形面积： H = \{ \bigcup_i a_i | v_i \in PF_{known} \}其中，$v_i$ 是 $PF_{known}$ 中的非支配解向量，$a_i$ 是由 $v_i$ 分量和原点确定的超面积。 以下图为例： 被(0,0) 与 (4,4) 所围成的矩形的面积是 16。被 (0,0) 与 (3,6) 所围成的为 (3 x (6-4)) = 6个，依次…结果： $P_{true}$ ‘s H = 16 + 6 + 4 + 3 = 29. $PF_{true}$ ‘s H = 20 + 6 + 7.5 = 33.5. 同时，也注意到：如果 $PF_{true}$ 是 non-convex ，这种测量方法会有错误。它们还隐式地假设MOP的目标空间原点坐标为(0..，0)，但情况并非总是如此。$PF_{known}$ 中的向量可以转换为以零为中心的原点，但是由于MOPs之间每个目标的范围可能完全不同，因此最佳 $H$ 值可能相差很大。也定义了 $hyperarea \ ratio$ 定义如下： HR = \frac{H_1}{H_2}$H_1$ 为 $PF_{known}$ 的超面积，$H_2$ 为 $PF_{true}$ 的超面积。在极小化问题里：ratio 值为 1，当 $PF_{known} = PF_{true}$ ；如果大于 1，即为 $PF_{known}$ 的超面积大于 $PF_{true}$ ，上例中，$HR = \frac{33.5}{29} = 1.155$ 。 Hyperarea Difference (HD)使 $A,B \subseteq X $ 是两个decision vectors，那么，函数 $D$ 定义如下： D(A,B):= \xi (A+B) - \xi (B)所给的是被 $A$ weakly dominate 但是不被 B weakly dominate 的空间的大小(objective space)。 如上右图，A 为 前沿1，B 为前沿2。一方面，$\alpha $ 是被前沿1但不被前沿2所占的大小。另一方面，$\beta$ 是被前沿2但是不被前沿1所占的大小，黑色的区域是被两个都占的大小，因此，$D(A,B) = \alpha$ ，$D(B,A) = \beta$ 。因为： \alpha + \beta + \gamma = l(A+B)\\ \alpha + \beta = l(A)\\ \alpha + \gamma = l(B)\\在这个例子中，$D(B,A) &gt; D(A,B)$ 意味着与C度量相比，这两个方面的差异体现。另外，它给出了集合是否完全支配另一个集合的信息，例如 $D(A,B) = 0$，$D(B,A) &gt;0$ 意味着 $A$ 支配 $B$。 理想下，D 测量常用于被 $V$ 归一化的 $l$ 指标，对于应该最大化问题： V = \prod_{i = 1}^k (f_i^{max} - f_i^{min})$f_i^{max},f_i^{min}$ 是 目标 $f_i$ 的最大值，最小值。可是，也有其他的情况，$V = l(X_p)$ ，表现得也不错。结果，四个值被考虑，当考虑两个解集时，$A,B \in X_f$: $l(A) / V$ ，它给出了目标空间中被 $A$ 弱支配的区域的相对大小。 $l(B) / V$ ，它给出了目标空间中被 $B$ 弱支配的区域的相对大小。 $D(A,B) / V$ ，她给了被 $A$ 弱支配但不被 $B$ 弱支配的区域的相对大小。 $D(B,A) / V$ ，她给了被 $B$ 弱支配但不被 $A$ 弱支配的区域的相对大小。 由于 $D$ 度量是在 $l$ 度量的基础上定义的，因此不需要额外的实现工作。 Volume measure粗略的说$ \mathcal{V}(A,B) $ 是包含严格由 $A$ 的元素支配但不受 $B$ 的元素支配的两条边的最小超立方体的体积的分数(并且在[0,1]区间内)。如下图所示，两个连续的前沿 $A$ 和 $B$ 在目标空间的不同区域存在不同程度的差异，并且相互支配。(目标函数最小化) $\mathcal{V}(A,B)$ 定义如下，对任何D维的向量 $Y$ ，$H_Y$ 为包括 $Y$ 的最小的轴平行超立方体。 H_Y=\{ z \in R^D:a_i \leq z_i \leq b_i \ for \ some \ a,b \in Y \ i=1,...,D \}现在用映射到单位超立方体上的规格化缩放和平移来表示$h_Y(y):H_Y \rightarrow [0,1]^D$。此转换用于消除目标伸缩的影响。相当于 $k = h_Y(y)$ 把原来的点 $y$ 通过缩放与平移到单位超立方体中的点 $k$ 。 D_Y(A)=\{ z \in [1,0]^D:z \prec h_Y(a) \ for \ some \ a \in A \}上式为超立方体中被归一化控制的点的集合，那么$\mathcal{V}(A,B)$定义如下： \mathcal{V}(A,B)=\lambda(D_{A \cup B}(A) \backslash D_{A \cup B}(B) )其中，$\lambda(A)$ 是 $A$ 的勒贝格测量。个人认为： ​ 绿色的部分为$\mathcal{V}(B,A)$ 。 ​ 红色的部分为$\mathcal{V}(A,B)$ 。 尽管这个描述相当繁琐，但是 $\mathcal{V}(A,B)$ 和 $\mathcal{V}(B,A)$ 很容易通过对 $H_{A \cup B}$ 的蒙特卡罗抽样来计算，并计算A或b占绝对优势的样本的比例。本研究选取5万个样本进行蒙特卡罗估计。体积测量 $\mathcal{V}$ 的好处是,它将奖励设置更大的区段当这些区段是前面的比较,而不是当他们在后面,不受点分布方面,而且它也给信息多远一组(平均)面前的另一个地方。 不幸的是，这个测度 $\mathcal{V}$ ，像原来的度规$\mathcal{C}$ 一样，具有这样的性质，如果$\mathcal{W}$ 是一个非支配集，并且 $A \subseteq W$，$B \subseteq W$ ，$\mathcal{V}(A,B)$ 与 $\mathcal{V}(B,A)$ 两者都是积极的。 Integrated Preference Functional (IPF)作为一组在运筹学上已建立完善的QIs，IPF测量由集合中的每个非支配解和给定的效用函数在相应的最优权值上确定的polytopes的体积。它可以被理解为表示解决方案集为DM[16]所携带的预期实用程序。IPF指标的计算分为两个步骤:1)找出每个非优解的最优权重区间;2)对这些最优权重区间上的效用函数进行积分。 形式上，$A \subset \mathcal{R}^m$ 是非支配解集，其中 m 是目标函数个数。考虑一个参数化的效用函数族 $u (a,w)$，其中给定的权重 $w$ 产生一个要优化的值函数，其中 $a \subset A$ 和 $w \in W \subset \mathcal{R}^m$ ,对于给定的 $w$，让 $𝑢^*(A,𝑤)$ 为在A中最好的效用函数值的解决方案。给定权重密度函数$h:W \rightarrow \mathcal{R}^+$ ，表示未知权重w的概率分布，并且$\int_{w \in W}h(w)dw=1$，那么集合A的IPF值为： IPF(A)=\int_{w\in W} h(w)u^*(A,w)dw效用函数可以表示作为目标的凸组合(即加权线性和函数)或加权Tchebycheff函数。前者只考虑受支持的解决方案，而后者则涵盖所有非支配的解决方案。IPF indicator可以在/不需要 DM 的输入的情况下使用。当DM的偏好可以按照某个部分权重空间来表达时，IPF衡量的是该集合在部分帕累托前沿所代表的偏好的好坏。当没有可用的偏好信息时，可以假设所有的权重都是相等的(即$h(W)=1,\forall w \in W$)，IPF 衡量的是这组数据如何很好地代表整体帕累托。较低的IPF值为佳。然而，使用IPF指标的一个限制是，随着目标数量的增加，其计算复杂度呈指数级增长，因为它需要在(连续的)权重空间上进行积分。 以下为论文原文： 对于多目标优化问题，经常使用值(utility)函数法将各种目标函数组合成输入的一个标量函数。这个组合目标可以表示为参数化函数族 $g(x;α)$，一个给定的值参数向量 $\alpha$ 在它的领域 A 中代表一个特定的标量目标，并且目标是最小化。在二元目标的情况下0和1之间的 $\alpha$ 是一个标量,凸组合的情况下的目标。 对于给定的集合 $X$ (多目标函数的非支配解)，对于任意给定 $\alpha$ ，通过 $g(x;\alpha)$ 至少存在一个最优解。对于给定的 $g$ ，定义一个函数 $x_g:A \rightarrow X$，它把参数值( $\alpha$ )映射到 $X$ 中的相应解上。这个函数 $x_g(\alpha)$ 很清晰的把 $A$ 分成了几个区域，反函数 $x_g^{-1}(x)$ ，随着 $x \in X$，定义参数空间 A 在解上的分区，其中 $x_g$ 是常量： A = \bigcup_{x \in X}x^{-1}_g(x) = \bigcup_{x \in X} A_x对于，$x_1 \neq x_2$ ，其中，$A_{x_1} \ and \ A_{x_2}$ ，在二元目标例子中，至多有一个值相同。通常情况下，$A_{x_1} \bigcap A_{x_2}$ 是 对于 $x_1 \ and \ x_2$ 最优解时，两个区域间的边界。在所有实际情况下，这将是一组测度零，不会影响指规数的计算。给定: $h:A \rightarrow R_+$ ,$\int_{\alpha \in A} h(\alpha) d \alpha = 1$, IPF(X) = \int h(\alpha) g(x_g(\alpha);\alpha)d\alpha将解集映射到实数的积分偏好函数。因为 $x_g$ 是(piecewise)分开的常量，上式的积分可以分解成与 $x \in X$ 相对应的 $x_g^{-1}(x)$ 的不同区域。 IPF(X) = \int_{\alpha \in A} h(\alpha) g(x_g(\alpha);\alpha)d\alpha = \sum_{x \in X}\left[ \int_{\alpha \in x^{-1}_g(x)} h(\alpha) g(x;\alpha)d\alpha \right]因此,给定一个 $\alpha$ 的值产生一个特定的目标函数，因为至少有一个最优解在集 $x_g(\alpha)$ 。密度函数 $h(\alpha)$ 分配不同的值给权重向量 $\alpha$ 值,然后 $IPF$ 提供了一个通用的“最优”的解决方案,在已选择权重密度函数。 最后形式的方程表明,我们只需要能够评估积分 $h(\alpha)$ ,因此目标函数的形式是无关紧要的。此外，这里提出的 $IPF$ 测度没有考虑到决策者的任何个人偏好结构，因此可以认为是一般性的。当然，所有这些的主要困难是计算出 $x_g$ 为分段常数的 $A$ 的适当区域，以及计算式(2)中的积分。这些困难取决于函数g、函数h的类型和考虑的目标的数量。 $h(\alpha)$ 如下图： 在实际问题中应用IPF测量，需要对每个目标进行适当的标度。当所考虑的目标是不可比较的(例如，延迟作业的数量和总完成时间)，则无法解释混合的目标值。此外，当每个目标值的范围之间的差异非常大，以至于一个目标值可以被另一个目标值抵消时，将多个目标混合到一个合理的标量值需要适当的缩放。Schenkerman(1990)提出在缩放目标值时，合适的最小值和最大值分别是最大化问题中近似集的非支配最小值和理想点。他还坚持认为，其他的最低要求可能会阻止决策者做出自己喜欢的决定。De et al.(1992)在比较最小化问题的近似集与面积和长度度量时采用了相同的比例方法。正如Gershon(1984)所指出的，规模可以衡量目标的重要性，这影响所考虑的权重。 另外下面是在另一个论文里对 $IPF$ 的介绍，觉得更通俗，就摘过来了。 IPF(Tchebycheff)如Carlyle et al.(2003)所述，决策者的价值函数可以表示为目标的凸组合这一假设意味着只有支持的点才有助于IPF度量。一般来说，当决策者的隐式值函数是非线性的时，这是一个严重的限制，因此，在非支配解集中某些不受支持的点实际上可能是更可取的。在极端情况下，可能会出现这样的问题:受支持的有效解决方案非常少，而绝大多数有效解决方案可能不受支持。在评估非支配点集时，考虑不支持点的影响的一个好方法是使用加权的Tchebycheff函数来表示决策者的价值函数。Tchebycheff函数对应于权重规度$L_p​$ ,在下式中，当 $p = \infty​$ : minimize_{i \in I} \left( \sum_{j \in J} \alpha^p_j (z_j^i - z_j ^{**})^p \right)^{1/p}其中，$I=\{ 1,2,…,n \}$ 是解集的索引，$J=\{ 1,2,…,m \}$ 是目标的索引，$\alpha_j$ 是第 j 个目标的权重，并且 $\alpha_j \geq 0$，同时，$\sum_{j \in J} \alpha_j = 1$ ，$z^i_j$ 是第 i 个解的第 j 个目标函数值，$z^{**}_j$ 是第 j 个目标的理想值。注意到这一点可以通过最小化第 j 个目标本身来找到。当 $p = 1$ 时，测度对应于目标函数的凸组合当 $z^{**}_j = 0$ 时。当 $p = \infty$ 时，权重测度 $L_{\infty}$ 测度为： minimize_{i \in I} [ \max_{j \in J}\{ \alpha_j(z^i_j - z^{**}_j) \} ]加权Tchebycheff函数可用于生成所有非支配点，支持点和不支持点，因此在多目标优化问题中得到了广泛的应用。当使用加权Tchebycheff函数时，集合中的每个非支配点都有一个最优权区间。本文给出加权契比雪夫函数的IPF测度的计算方法。如果我们假设所有的权值都是等可能发生的($h(\alpha ) = 1 ,for \ all \ \alpha \in A​$)。当考虑二元函数时： minimize_{i \in I} [ \max \{ \alpha z^i_1, (1-\alpha) z^i_2 \} ]其中，$0 \leq \alpha \leq 1$ ， 并且考虑两个问题，1). 找出每个非支配点的最优权区间。2).在分解后的最优权值区间上对标量值函数积分。 以下的 Step.1~Srep.3可解释第一个问题，Step.4解释第二个问题。 Step.1：按照解的第一维度升序排好解如下： z_1^1 < z_1 ^2...>z_2^n Step.2：获得 break-even 权重，$\alpha ^i_b$ 对于每一个点 $i \in I$ ，其中，关系如下： \alpha_b^iz_1^i = (1-\alpha_b^i)z_2^i下图a，有在目标空间中的一个点，虚线表示一个break-even点 $\alpha ^i_b$ 。满足上式，并从图b，看出所有的点 $z^i,i \in I$ 满足如下： \alpha^b_i = \frac{z^i_2}{z^1_1 + z_2^i}使用break-even权重，$\max\{ \alpha z^i_1, (1-\alpha) z^i_2 \}$ 对每一个非支配点都可以如下这样： \max\{ \alpha z^i_1, (1-\alpha) z^i_2 \} = \begin{cases} \alpha z_1^i &\alpha \geq \alpha_b^i\\ (1-\alpha_b^i)z_2^i &\alpha \leq \alpha_b^i \end{cases} 定理一：对于所有的不等式，均满足：$\alpha_b^1 &gt; \alpha_b^2&gt;…&gt;\alpha_b^n$ ，具体推导见原论文。 Step.3：对于每一个非支配解，获得一个上界，$\alpha_U^i$，获得一个下界，$\alpha_L^i$ 。 \alpha_U^1 = 1\\ \alpha_L^1 = \alpha_U^2 = \frac{z_2^1}{z_1^2 + z_2^1}\\ .\\ .\\ \alpha_L^i = \alpha_U^{i+1} = \frac{z_2^i}{z_1^{i+1} + z_2^i}\\ .\\ .\\ \alpha_L^n = 0 Step.4：在步骤3分解的最优权重区间上对加权Tchebycheff函数进行积分，对在 Z 中每一个点有如下： IPF(Z) = \int^1_0 h(\alpha) \min_{i \in I}[\max\{ \alpha z^i_1,(1-\alpha)z_2^i \}]d \alpha\\ =\sum_{i \in I} \left( \int_{\alpha^i_L}^{\alpha^i_b} h(\alpha)(1-\alpha)z_2^i d \alpha\\+ \int_{\alpha^i_b}^{\alpha^i_U} h(\alpha)\alpha z_1^i d \alpha \right) 下面为一个实例： R Family与IPF指标类似，R族[73]也将DM s偏好纳入评价。然而，与IPF不同的是，R质量指标中的集成是基于效用函数(而不是权重空间)的。给定两个解集A和B，一个效用函数空间R和一个效用密度函数(U)，可以定义为 R(A,B,U) = \int_{u \in U} h(u)x(A,B,u)du根据结果函数 $x(A,B,u)$，R家族有三个指标。R1考虑DM优先选择其中一个的概率，R2考虑效用函数的期望值(就像IPF指标)，R3引入了基于R2的比值。其中R2使用频率最高，可以表示为 R2(A,B,U) = \int_{u\in U}h(u)u^*(A)du - \int_{u \in U}h(u)u^*(B)du其中，$u^*(A)$ 表示A在此特定效用函数上所获得的最佳值。可以看出，两个集合的R2值可以单独计算。与IPF指标一样，当偏好信息不可用时，$h(u)$可以均匀分布在 $u$ 上。然而，计算中通常使用离散有限集 $U$，这与IPF中考虑的连续集$W$相反。这可以使R2的计算变得友好。特别地，如果效用函数 $u$ 的集合可以用权值 $W$ 的集合和这些权值上的参数化效用函数来表示，那么R2可以进一步计算为 R2(A) = \frac{1}{|W|}\sum_{w \in W} u^*(A,w)与IPF一样，$u(A,w)$ 的物化过程中也存在多项选择，如加权线性和函数和加权Tchebycheff函数，但后者在实践中应用较为广泛。 当h(w)设为1时，将式(13){R2(A)}与式(10)(IPF(A))进行比较，R2和IPF指标表现得非常相似。IPF指标考虑的是一个连续的权值空间，它需要相对于目标维数呈指数增长的计算时间，而R2指标考虑的是一组离散的权值，它的计算速度很快，但其精度自然低于IPF。]]></content>
      <categories>
        <category>indicators</category>
      </categories>
      <tags>
        <tag>MOEA</tag>
        <tag>indicator</tag>
        <tag>AllaspectsQI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[QIs for Spread and Uniformity]]></title>
    <url>%2F2019%2F02%2F06%2Fspreadanduniformity%2F</url>
    <content type="text"><![CDATA[过年期间，学习就更加懈怠了。。 前言spread和uniformity的品质方面是密切相关的，需要将它们放在一起考虑，以反映解决方案集的diversity。这激发了QIs去覆盖spread和uniformity的品质。这类QIs大多数可以分为两类，distance-based indicators and region division-based indicators，尽管也有其他的选择，如基于集群的指标和基于容量的指标。如图： Distance-based QIs(59~62)该类中的QIs(表中项目59-62)通常考虑解与其邻域之间的距离，然后将这些距离相加，从而估计整个集合的覆盖范围。沿着这个思路的是 $\Delta$ ,然后是sparsity index，extended spread，and $\Delta_{Line}$ 。然而，这样的评估只能在双目标问题中工作，如非支配解连续位于两个目标上。这些QIs的另一个问题是，它们需要帕累托前沿(例如边界)的信息作为参考，这在实践中往往是未知的 $\Delta$此论文来自于伟大的$NSGA-II$ ！ \Delta = \frac{d_f + d_l + \sum_{i=1}^{N-1}|d_i-\bar{d}|}{d_f + d_l + (N-1)\bar{d}}具体参数可看下图，一目了然。 值得注意的是，这并不是可能的解决方案的最坏情况。我们可以假设$d_i$有很大的方差。在这种情况下，度量可能大于1。因此，上述度量的最大值可以大于1。然而，一个好的分布会使所有的 $d_i$ 距离都等于 $\bar{d}$ 并且会$d_f=d_l=0$(在非支配集中存在极端解)。因此，对于最广泛且均匀分布的非支配解集，其分子为零，使得度规 $\Delta$ 取的值为零。对于任何其他分布，度规的值都大于零。对于两个具有相同$d_f$和$d_l$值的分布，度规$\Delta$取的值较高，而极值解的分布较差。请注意，上述多样性度量可用于任何非支配解集，包括非帕累托最优集的解集。利用三角化技术或Voronoi图方法[1]进行计算$d_i%=$，可以将上述过程推广到估计高维解的spread。 Extended spreadS 是一个解集，$S^*$ 是已知的Pareto-optimal solutions。 $\Delta(S,Q)$ : 原始度规计算两个连续解之间的距离，这只适用于2个目标问题。我们通过计算一个点到它最近的邻居的距离来进行扩展: \Delta(S,S^*) = \frac{\sum_{i=1}^m d(e_i,S) + \sum_{X \in S^*} |d(X,S)-\bar{d}|}{\sum_{i = 1} ^m d(e_i,S) + |S^*| \bar{d}}其中，$\{ e_1,…,e_m \}$ 是 $ S^*$ 中的 m 个极值解，并且： d(X,S) = \min_{Y \in S,Y \neq X}||F(X)-F(Y)||^2\\ \bar{d} = \frac{1}{|S^*|} \sum_{X \in S^*} d(X,S).如果解决的方案有很好的distribute 并且包括这些极值点，那么，$\Delta(S,S^*) = 0$。 $\Delta_{Line}$(不是很懂)The $\Delta_{Line}$ measures the diversity and spread of approximate solutions without the need for the $PF_{true}$ . Let $\beta$ be the mid-points of equally divided intervals in the range of [0, 1] $\left( [0,\frac{1}{N}],[\frac{1}{N},\frac{2}{N}],…,[\frac{N-1}{N},1] \right)$ where $N$ is the number of solutions in approximate the PF, then the objective line distribution ( $\Delta^i_{Line}$ ) is defined as:但是并不是很懂下标的规定。 \Delta^i_{Line}(S,\beta) = \frac{\sum_{j=1}^{|\beta|}\min_{s \in S}|\beta_j - F_i(s)| }{|\beta|}其中，$F_i(s)$ 是第 $i$ 个目标的归一化近似解，第i个目标线分布的零值表示近似PF沿第i个目标的均匀分布。$S$ 是一个粗略前沿PF。 整体线分布测度定义为: \Delta_{Line}(S,\beta) = \frac{\sum_{j=1}^{M} \Delta^i_{Line}(S,\beta)}{M}其中，$M$ 是目标函数的个数。 Region Division-based QIs (63~74)此分类的基本思想把一个特定的空间分割成许多细胞(重叠)，然后计算细胞的数量有解决方案集。这是基于一组更多元化的解决方案通常占据更多的细胞。考虑到细胞的不同形状，大多数用于扩散和均匀性的QIs都属于这一类。 它们中的一些考虑以解为中心的niche-like细胞，比如，Chi-square-like deviation, U-measure and sparsity。 有些则考虑gird-like的单元格将空间划分为多个超盒，比如，cover rate, number ofdistinct choices , diversity metric , entropy and diversity comparison indicator. 其余的考虑fan-shaped(扇形)细胞，它们用一组均匀分布的光线来分割空间(权重向量)，比如，Sigma diversity metric, M-DI and DIR. 除此之外，考虑最小能量点(s-energy)划分空间[74]也是一种潜在的方法，因为它们可以很好地表示各种形状的空间。 Chi-square-like deviation把search space (也就是自变量的空间)，分成几等分，每一个小区域叫做subregion。 v = \sqrt{\sum_{i=1}^{q+1} \left( \frac{n_i-\bar{n_i}}{\sigma_i } \right) } $q$ 是所期望得到最优解的个数。第$(q + 1)$个子区域是受支配的区域 $n_i$ 是第 $i $ 个非支配子区域实际的个数 $\bar{n}_i$ 是第 $i$ 个非支配子区域的期望个数 $\sigma^2_i$ 是第 $i$ 个非支配子区域的个数的方差 通过概率论，他可以由下面估计： \sigma_i^2=\bar{n}_i(1-\frac{\bar{n}_i}{P})$P$ 是种群尺寸 因为并不希望任何的子代落到非支配区域，因此 $\bar{n}_{q+1} = 0$。并且有，$\sigma^2_{q+1} = \sum_{i = 1}^q \sigma^2_i$ 。如果点的分布是理想的话，那么$v=0$。因此，具有良好分布能力的算法具有低偏差度量的特点。 Sparsity index好像没有公式，只有一段话。。。 大体意思就是：找到一个超平面，把每一个解映射过去，并且每一个解占有一定的大小(size=d 的 hyper-box) 越重合就越不稀疏，再把体积求和，当然体积越大越好。主要在于d的取值，不易太大，不易太小。 U-Measure(太多 再说)Cover rateCover rate is the index(指标) for the diversity of the Pareto optimum individuals. The cover rate is derived in the following steps. At first, one of the object functions is focused. Secondly, the distance between the individuals that have the maximum and the minimum values is divided into the certain number of the division. Thirdly, the division area that have the Pareto optimum individuals is counted. Fourthly, the counted number is divided by the number of division. When every divided area has at least one Pareto optimum individual, this number becomes 1. When there are no area that has the Pareto optimum individuals, this number becomes 0. Fifthly, these steps are treated for every objective function. Finally, the cover rate is determined to average the number of each objective function. When the cover rate is close to 1, it means that the Pareto optimum individuals are not concentrated on one point but they spreads. In Figure 4, the concept of the cover rate are shown, when there are two objective functions. 翻译一下就是：如上图，为一个目标函数(个人觉得如果对于一个目标，理应是在一维坐标上)，找到最大值最小值，分成确定的几份，在每个小间隔中，如果有点就为1，否则为0。依次遍历每一个函数，最后求平均值。 Number of Distinct Choices ($NDC_\mu$)从设计者的角度来看，所观察到的帕累托解集中包含的点越多，可供选择的设计选项就越多。然而，如果观测到的帕累托解在目标空间中过于接近，那么对于设计者来说，观测到的帕累托解之间的变化可能无法区分。换句话说，观察到的帕累托解的数量越多，并不一定意味着设计选择的数量越多。简而言之，对于一个观察到的帕累托解集$p=(p_1,…,p_{\bar{np}})$ ，只有那些彼此之间有足够差异的解决方案才应被视为有用的设计选项。 设数量$\mu , \ (0 &lt; \mu &lt;1)$为设计人员指定的数值，可将m维目标空间划分为$1/\mu^m$的小网格。为了简单起见，将$1/\mu$作为整数。每个网格都是指一个正方形(m维中的超立方体)，即无差异区域$T_{\mu(q)}$，其中区域内任意两个解点$p_i$和$p_j$都被认为是相似的，或者设计人员对这些解不感兴趣。下图给出了二维目标空间中的量$\mu$ 和 $T_{\mu(q)}$。 $T_{\mu(q)}(q,P)$ 表示是否有任何点$p_k \in P$属于区域$T_{\mu}(q)$。当至少有一个解点$p_k$落在无差异区域$T_{\mu}(q)$中时，$T_{\mu(q)}(q,P)$等于单元(或1)。$T_{\mu(q)}(q,P)$等于0(或0)只要$T_{\mu}(q)$区域没有解。一般来说，$T_{\mu(q)}(q,P)$可以表述为: T_{\mu(q)}(q,P) = \begin{cases} 1 & \exists p_k \in P \ p_k \in T_\mu(q)\\ 0 & \forall p_k \in P \ p_k \notin T_\mu(q) \end{cases}质量度量$NDC_{\mu}(q)$，即预先指定的m值的不同选择的数量，可以定义为: NDC_{\mu}(P)=\sum_{l_m=0}^{v-1}...\sum_{l_2=0}^{v-1}\sum_{l_1=0}^{v-1}NT_\mu(q,P)where $q = (q_1,q_2,…,q_m)$ with $q_i=\frac{l_i}{v} $ 其中，$v=1/\mu$ ，点 $q$ 位于目标空间m-网格线的任意交点上，坐标为$(q_1,q_2,…,q_m)$。如本节开头所示，，如果想让$NDC_{\mu}(P)$值较高的观察到的Pareto解集，对于预先指定的 $\mu$ 就要有相对于较低的值(网格越密，被删去的点就越少)。 $NDC_{\mu}$ 和 cover rate 是有区别的，前者是把目标空间看作整体，并分成了很多个hyper-box；后者是分析每一个维度，最后加权平均一下。 Diversity metric(DM)规定： $P^{(t)}$ 为每一代的种群。$\mathcal{F}^{(t)}$ 是 $P^{(t)}$ 的非支配解。目标(参考点集) $P^*$ 从 $P^{(t)}$ 中确定 $\mathcal{F}^{(t)}$ , 使 $\mathcal{F}^{(t)}$ 非支配于$P^*$ 对于网格的每一个索引 $(i,j,…)$ ，并计算下面两个： H(i,j,...)=\begin{cases} 1,& if \ the \ grid \ has \ a \ representative \ point \ in \ P^* \\ 0,& otherwise \end{cases} and h(i,j,...)=\begin{cases}1,& H(i,j,...)=1 \ and \ if \ the \ grid \ has \ a \ representative \ point \ in \ F^{(t)} \\0,& otherwise\end{cases} 给 $m(h(i,j,…))$ 赋值根据该索引本身与它邻居的$h()$。同样的，用 $H()$ ，来计算 $m(H(i,j,…))$ 计算多样性衡量标准 by averaging the individual $m()$ values for $h()$ with respect to that for $H()$: D(P^{(t)}) = \frac{ \sum_{i,j,...\\H(i,j,..) \ne 0} m(h(i,j,...)) }{\sum_{i,j,...\\H(i,j,..) \ne 0} m(H(i,j,...))}在这个简单的例子中，网格的值函数 $m()$ 可以通过使用它的 $h()$ 和相邻的两个 $h()$ 维度来计算。对于一组连续的三个二进制 $h()$ 值，总共有8种可能。任何值函数的赋值方法如下: 111 是最好的分布，000 是最坏的分布。 010 或 101表示具有良好扩展的周期模式，其值可能大于 110 或 011 。例如，上述估值将使网格覆盖率为50%的近似集具有更大的分布(如1010101010)，优于具有相同覆盖但分布较小的另一集(如1111100000)。 110 或 011 的值可能超过 001 或 100，因为有更多的网格覆盖。 h(…j-1…) h(…j…) h(…j+1…) m(h(…j…)) 0 0 0 0.00 0 0 1 0.50 1 0 0 0.50 0 1 1 0.67 1 1 0 0.67 0 1 0 0.75 1 0 1 0.75 1 1 1 1.00 对于 $H()$ 使用相同的值。在目前的研究中，通过计算上述度量维度来处理两个或多个维度的超平面，而通过考虑一组移动的超盒来非常谨慎设计地上述值函数的一个高维版本。对一个包含9个盒子的二维集合的考虑如下: 作为上述计算过程的说明，下图显示了一个两目标最小化问题的一组目标点(标记为填充圆$P^*$)和一组总体点(标记为阴影和打开的方框 $P^{(t)}$ )。用阴影框标记的点是相对于目标点的非支配点( $\mathcal{F}^{(t)}$ )，用于多样性计算(这是步骤1)。这里以f2 =0平面为参考平面，将 $f_1$ 值的完整范围划分为G=10个网格。下一步，计算每个网格的 $h()$ 和 $H()$ 值。对于边界网格(极端网格和网格$(…,j,…)$ 与 $H(…,j - 1 ….)= 0$ 。 在边界处的网格，假设一个假想的相邻网格的h()或h()值为1，例如上图的虚线格子。也注意到，有的格子里有不止一个点在其中，但也就算一个。移动的三个格子，确定中间位置的数值。为避免边界效应(使用虚网格的效应)，我们将上述度量归一化如下: \bar{D}(P^{(t)}) = \frac{ \sum_{i,j,...\\H(i,j,..) \ne 0} m(h(i,j,...)) -\sum_{i,j,...\\H(i,j,..) \ne 0} m(0)}{\sum_{i,j,...\\H(i,j,..) \ne 0} m(H(i,j,...))-\sum_{i,j,...\\H(i,j,..) \ne 0} m(0)}0 为值为零的数组。仔细想想就会发现，计算上述$\bar{D}(P^{(t)})$项和边界网格调整时$H(i,j…) \ne 0$ 允许使用一种通用方法来处理具有断开的pareto最优前端的问题。该度量不包括不存在参考解的网格的值函数。 如果不知道帕累托最优前沿(特别是对实际问题)，则可以用以下方法确定目标集。 首先，MOEA运行T代，并存储按代计算的总体($P^{(T)}， t = 0,1…T)$)。 然后,将每个种群的非支配成员 $\mathcal{F}^{(t)}$ 组合在一起，则target set 就是这些的总和。 P^*=Non-dominated(\cup^T_{t=0}\mathcal{F}^{(t)}) Diversity comparison indicator (DCI)很巧这里介绍了DM的缺点： a reference set，它要求是均匀分布在PF，这是必需的，以便准确反映分布的optimal front。也是要求，解决方案参考集近似近似的解决方案的数量以保证理想的分布近似可以达到最佳的DM值(一个)。这些要求在多目标优化问题中通常是不可用的。 DM需要访问网格中的每个hyperbox来估计分布，这对数据结构和计算成本都带来了很大的挑战。对于m个目标的优化问题，需要考虑 $r^{m-1}$ 超盒，其中r为每个维度的划分数。 在超盒的分布估计中，DM需要通过一个值函数给每个相邻的超盒分配一个合适的值，以区分其邻域内解的不同分布。由于超盒的邻居数量随着目标数量的增加呈指数增长(m维超盒最多有($3^m$-1)个邻居)，当涉及大量目标时，很难定义准确反映不同分布的值函数。 由于网格中解的邻域的指定，DM可能无法给出具有大量目标的近似的精确分集结果。DM中解的邻域的设置是基于解的网格坐标的曼哈顿距离，而不是它们的欧氏距离。它可能会误导性地消除相邻解，但将更远的解视为相邻解。 网格的位置和大小在该指标中具有重要意义。设置网格区域不应涉及整个目标空间，而应针对给定问题的帕累托前沿不远的区域，因为不同近似有意义的多样性比较的前提是它们已经接近最优前沿[50]。假设较高和较低的网格边界为：$LB=(lb_1,lb_2,…,lb_m)$ and $UB=(ub_1,ub_2,…ub_m)$ ,m 是目标函数的个数，如果一个解向量$(q_1,q_2,…,q_m)$ 在 $LB$ 与 $UB$ 之外，(也就是说 $k \in \{ 1,2,…,m \}:q_k ub_k$ ) 那么此解向量在indicator calculation 中会被忽略掉。 在将所提出的DCI应用于不同问题时，网格边界可以由用户定义的“满足区域”来确定，也可以由问题的理想点和最低点来设置。“满足区域”是用户的一种估计，即在该区域中所获得的解被认为满足收敛性的质量要求。当用户没有明确规定他/她“满意的地区,”网格边界可以通过给定问题的理想点和最低点(下图所示),理想点和最低点是两个重要的概念在多目标优化中,当PF是未知时他们可以通过一些有效的方法估计。在这里，将一个问题的理想点和最低点所构成的区域的轻微松弛看作网格环境： ub_k = np_k + \frac{np_k - ip_k}{2 \times div}\\ lb_k = ip_k其中，$ip_k$ 是第 $k$ 个目标的理想点，$np_k$ 是第 $k$ 个目标的最低点，$div$ 是一个常数(一个维度中目标空间的划分数，例如下图为5) 根据网格的边界和划分的数量，第 $k$ 个目标中的超盒大小 $d_k$ 可以形成如下图所示： d_k = \frac{ub_k-lb_k}{div}在这种情况下，通过下边界和超盒尺寸可以确定解在帕累托前近似中的网格位置如下(向下取整): G_k(q)=\lfloor (F_k(q)-lb_k)/d_k \rfloor其中$G_k (q)$ 表示第 $k$ 个目标中解 $q$ 的网格坐标。$F_k(q)$ 是 $q$ 在第 $k$ 个目标中的真实值。上图中，A，B，C，D 的坐标一次为 (0,4)，(0,3)，(2,2)，(4,0)。以下在引入关于距离的两个概念 $h_1,h_2$ 是网格中的两个超立盒子，那么两个网格的距离为： GD(h_1,h_2)=\sqrt{\sum_{k=1}^m (h_1^k - h_2^k)^2}$h_1^k，h_2^k$ 是 $h_1,h_2$ 的在第 $k$ 个目标函数的坐标。$m$ 是目标函数总数。例如 B 与 C 距离为 $\sqrt{(0-2)^2 + (3-2)^2} = \sqrt{5}$ . P 是也该粗略解集， h是一个超方体盒，从 P 到 h的最短格距离为： D(P,h) = \min_{p \in P} \{ GD(h,G(p)) \}例如，上图中 在粗略解集A，B，C，D中距坐标为(1,3)的超方体盒子的距离为 $GD(h^{(1,3)},G(B)) = 1$ 。显然，在网格环境中解分布均匀且分布广泛的近似，其到所有超盒的平均距离值较低。 不同的帕累托前近似解可能位于不同的超盒中。在这里，我们只考虑在混合逼近集中非支配解所在的超盒，因为受支配解的多样性对用户来说可能毫无意义。对于一个近似解，如果它的解覆盖或接近所有被考虑的超盒，那么与其他近似相比，它将获得一个相对较好的多样性;另一方面，如果它的解决方案远离大多数这些超盒，则会获得相对较差的多样性。算法1给出了计算待比较近似的DCI值的主要步骤。 贡献度(算法1的第6行)反映了近似对超盒的贡献，并由它们之间的距离决定。对于近似，如果所考虑的超盒中至少存在一个解，则可获得该近似对超盒的最大贡献程度。如果从近似值到超框的距离大于指定的阈值即，则贡献度为0。具体地说，近似P对超盒h的贡献程度定义为： CD(P,h) = \begin{cases} 1 - D(P,h)^2 / (m + 1) &d(P,h) < \sqrt{m+1}\\ 0 &d(P,h) \geq \sqrt{m+1} \end{cases}值得指出的是，我们将网格距离的阈值设置为$\sqrt{m+1}$，是为了保证相邻的两个个体始终能够交互(即，它们所在的超盒总是相邻的)。直观地说，如果两个超盒的个体可以任意接近，那么它们应该被视为邻居(在个体之间没有另一个超盒)。显然，满足上述条件的最远的两个超盒是网格距离为$\sqrt{m}$的对角超盒。由于超盒之间的网格距离始终为离散值$\sqrt{0},\sqrt{1},…,\sqrt{m},\sqrt{m+1}…$，将阈值设置为$\sqrt{m+1}$，只是使这些超盒对角相邻，在计算贡献度时可以相互作用。 图3为不同目标数下贡献度函数曲线。注意，贡献度取一个离散值，因为$D(P,h) \in \{\sqrt{0},\sqrt{1},…,\sqrt{m},\sqrt{m+1}…\}$。从图中可以看出，一些观察结果如下: 贡献度取0到1之间的值。在一定范围内，从近似到超盒在一定范围内，它单调地减小。 hyperbox的邻域半径随着目标数量的增加而增加。这表明，当目标数量增加时，可以考虑更大范围的个体进行交互。 当距离变量D(P, h)相等时，贡献度随着目标个数的增加而增加。这种增加似乎是合理的，因为随着网格中超盒总数的增长，超盒之间的相对距离变得更小。 总体而言，贡献度函数不仅考虑了近似到超盒的距离信息，还考虑了目标个数不同的网格环境的性质，对目标个数的变化具有良好的适应性。实际上，任何形式的函数都可以通过记住上述性质来赋值为贡献度函数。为了简单起见，这里使用二次函数。 根据贡献度函数，近似的DCI值是[0,1]区间内的一个数值。需要重申的是，DCI只是评估不同的帕累托前近似的相对分布质量，而不是为单个近似提供分布的绝对度量。最佳价值(即由近似得到的DCI = 1)不能反映其在整个帕累托前缘的均匀分布。相反，它表明该近似比其他近似有一个完美的优势。 上图展示了DCI的计算过程，有三个二元目标问题的pareto approximation $P_1,P_2,P_3$ ，并放在了网格环境中，有11个超方盒(灰色)被决定，其中解A，B并没有考虑其中，因为他们在混合解中被支配了。然后，对于每个超盒，根据前面提到的公式式计算三种近似的贡献度。比如，当考虑$h^{0,7}$ 时，$P_2$ 的贡献值为1，因为它在超方盒中。对于$P_1$ 来说：$1-1^2/3=2/3$ 作为$D(P_1,h^{0,7}) = 2/3$ ，对于$P_3$ 为0，因为$\sqrt{10} &gt; \sqrt{3}$ 。最后，根据算法1(第10行)求出各近似对这些超盒的平均贡献度，分别为：0.848，0.606，0.515。 M-DIM-DI 是在 DCI 的基础上修改的。 在DCI方法中，将各种算法的NDFs(non-dominated fronts)集合在一起，识别出一组帕累托最优解。使用由网格划分参数定义的网格，将每个算法的贡献与组合的帕累托最优解进行比较。 假设有两组帕累托前近似 $P_1$ 和 $P_2$ ，如下图所示。在这种情况下，$P_2$ 是组合的Pareto front，它的DCI度量是最高的(值1)，但是我们可以看到，这个值并没有反映出在front的极限之间的目标空间中解的均匀分布。在没有关于POF(Pareto Optimal Front)的任何资料的情况下，如果假定有一个连续的front，$RTF$ 很可能提供尽可能最好的解决办法。 在M-DI中，多样化是相对于RPF(Reference Pareto Front：单位截距在超平面上均匀分布的一组点)计算的。Nadir and Ideal point 计算方式与 DCI 相同。在RPF上的reference的数量 $W$ ，与在优化进程期间的人口尺寸 $N$ 有关 。For example, a population of 90 used for a 3-objective optimization problem would mean use of 91 reference points on the RPF. 其中 $CD(P,h)$ 仍不变，$h$ 是被RPF所占据的hyper-boxes。而不是在DCI 中的把所有解集合在一起，取出非支配解所占的hyper-boxes，因此： M-DI = \frac{\sum_{i=1}^{|h|}CD(P,h_i)}{|h|}EntropyIdeal/good points： 将理想点定义为目标空间中的一个点，该点的分量分别由目标函数的约束最小化得到： Minimize \ f_i(x) \quad s.t.:x \in DNadir/bad points： 在此论文中是，在本文中，我们任意地高估了目标的范围，以至于没有遇到违反估计上限的设计点。 Influence Function： 在决策空间中，第 i 个解的影响函数$\Omega_i:F^m \rightarrow R$ ，$\Omega_i$ 是随第 i 个解而下降的函数，种类很多，本轮中选择 Gaussian influence function。 \Omega(r) = \frac{1}{ \sigma \sqrt{2 \pi} } e^{-r^2/2\sigma^2}Density Function： 将可行目标空间各点的密度函数定义为各解点影响函数的集合，设共有 N 个解点，可行目标空间 $F_m$ 中任意点 $y$ 处的密度函数可得： D(y) = \sum_{i=1}^{N} \Omega_i(r_{i \rightarrow y})$r_{i \rightarrow y}$ 是一个标量，它展示了 $y$ 与 第 $i$ 个解点的欧式距离。$\Omega_i( . ) $ 是 第 $i$ 个点的影响函数，下图展示了在一维里一些点的影响距离。 Entropy： Claude Shannon 引入信息论熵来测量随机过程的信息含量，从而建立了信息论领域。从那时起，熵的许多不同的应用在不同的领域有他们自己的解释和定义。假设一个随机过程有n个可能的结果第i个结果的概率是。这个过程的概率分布可以表示为： P = [p_1,...,p_i,...,p_n];\sum_{i=i}^{n}p_i=1; p_i \geq0这个概率向量有一个相关的Shannon s熵，H的形式这个概率向量有一个相关的Shannon s熵，H的形式： H(P) = - \sum_{i=1}^n p_i \ ln(p_i)其中， 当 $p_i = 0$ 时，$p_i \ ln(p_i)=0$。最大值为 $H_{max}=ln(n)$ 当所有的值都相同的，最小值为0，当一个为1，其他的所有均为0。事实上，香农熵衡量的是 $P$ 的平整度，即。，如果向量中各分量的值近似相等，则熵值很大，但如果各分量的值相差很大~概率分布不均匀!，对应的熵值较低。 如下图所示 网格的尺寸是 $a_1 \times a_2$ 在feasible domain。对每一个密度函数，$D_{ij} = D(y_{ij})$，$a_1$ 和 $a_2$ 的数量确定为每个单元格的大小小于或等于无差异区域(无差异区域定义为任意两个解点被认为是相同的单元格大小，或决策者对这些解不感兴趣)。$a_1$ 和 $a_2$ 的数量可以根据设计者的经验或对类似问题的认识主观确定；或者客观地基于可用的计算能力和期望的精度。假设非常小的网格大小有助于提高准确性，但它也增加了计算熵的计算负担，这反过来可能使质量评估过程非常缓慢，甚至在计算上不可行。显然，适当的网格大小取决于问题，并且在不同的情况下有所不同。因为这些项的和。在香农熵的定义中，熵是1，我们定义一个归一化密度，$\rho_{ij}$ ，为: \rho_{ij} = \frac{D_{ij}}{\sum_{k_1=1}^{a_1}\sum_{k_2=1}^{a_2} D_{k_1k_2}}实际上，上述归一化密度的定义对于空解集的定义并不好，这就是为什么在密度函数的定义中假设解集是非空的原因。我们将给空解集的熵赋值为0来表示最坏的情况，即0的多样性。现在我们有: \sum_{k_1=1}^{a_1}\sum_{k_2=1}^{a_2} \rho_{k_1k_2} = 1\\ \rho_{k_1k_2} \geq 0,\forall k_1,k_2这样一个分布的熵可以定义为: H = -\sum_{k_1=1}^{a_1}\sum_{k_2=1}^{a_2} \rho_{k_1k_2}ln(\rho_{k_1k_2})并且，对于m维目标空间，将目标空间中的可行域划分为a13a23。3am细胞，熵定义为: H = -\sum_{k_1=1}^{a_1}\sum_{k_2=1}^{a_2}...\sum_{k_2=1}^{a_m} \rho_{k_1k_2...k_m}ln(\rho_{k_1k_2...k_m})熵值越大的解集在目标空间的可行域内分布越均匀，覆盖范围越广。 Sigma diversity metric提出了计算目标空间中解的位置的Sigma多样性度量。 如下图： 上左图，对于每一个线，都有$f_2 = af_1$，因此，$\sigma $ 便为： \sigma = \frac{ f_1^2 - f_2^2 }{f_1^2 + f_2^2}所有的在此线上的点都满足 $f_2 = af_1$ ，也就都有相同的 $\sigma = \frac{1-a^2}{1 + a ^2}$ 在一般情况下，$\sigma$ 被定义为 $ C_m^2$ 个元素的向量，其中m是目标空间的维数。在这种情况下，$\sigma$的每个元素都是上式中两个坐标的组合。例如f1、f2、f3三个坐标，定义如下:(如上又图) \sigma =\begin{pmatrix} f_1^2 - f_2^2 \\ f_2^2 - f_3^2 \\ f_3^2 - f_1^2 \end{pmatrix} /(f_1^2 + f_2^2 +f_3^2)例，$\sigma = (0 \ 0.5 \ -0.5)$ 时，$f_1 = 1,f_2 = 1,f_3 = 0$ 带入上面即可。 这意味着目标空间中的每个点都可以用向量来描述。直线上的所有点都有相同的向量在非常接近的直线上的解都有相似的向量。这是用来构造多样性度量的思想。 在计算近似集的多样性之前，必须先计算一组reference lines(参考线)。参考线数必须等于近似解的个数。必须强调的是，每个目标的参考线必须计算一次，并且可以存储在一个表中。那么Sigma多样性度量可以计算如下: 计算参考线 计算每条参考线的向量(参考向量 reference sigma vector)。 在每个参考向量旁边保留一个初始值为零的二进制标记。每个引用的旗帜 $\sigma$ 向量为 1,当至少有一个解决方案有一个向量 $\sigma$ 等于它或在一个距离(欧式距离)低于d。d的值取决于测试函数,但是它应该减少当有大量的参考线时。 计数器C对标记为1的引用行进行计数，多样性度量D变为： D = \frac{C}{number \ of \ reference \ lines}Sigma多样性度量表示的是在目标空间中非支配解的分布百分比 在极值解位于坐标轴上的情况下，我们可以得到D的一个高值，即,100%。对于离散解集或不连通解集，D的值永远达不到最大值。 由上式中的D可知，如果D的值很高，就意味着解的分布很好。但当D很小时，它意味着解是： 集中在空间的一部分 分布在前沿的小群体中 的确，这两种解决方案之间存在差异。下图显示了具有相同D值的两组解之间的差异。这两组解有不同的扩展，Sigma多样性度量无法区分它们。 红线是红点所占的reference lines；黑线是红黑点所占的reference lines。可以看到都是6条！ $\mathcal{M} ^* _2$Analogously, we define one metric $\mathcal{M}_2^*$ and on the objective space. Let $Y’,\bar{Y} \subseteq Y$ be the sets of objective vectors that correspond $X’$ to $\bar{X}$ and , respectively, and $\sigma ^* &gt; 0$ and $|| \cdot ||^*$ as before: 公式： \mathcal{M}^*_2({Y'}):=\frac{1}{|Y'-1|}\sum _{p'\in Y'} \{q' \in Y'; ||p'- q'||^* > \sigma ^*\}]]></content>
      <categories>
        <category>indicators</category>
      </categories>
      <tags>
        <tag>MOEA</tag>
        <tag>indicator</tag>
        <tag>diversity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[QIs for Cardinality]]></title>
    <url>%2F2019%2F01%2F28%2Fcardinality%2F</url>
    <content type="text"><![CDATA[这部分要么太难，要么太简单。。。。怀疑自己智商 介绍基数的QIs可以归结为一个简单的概念——计算非支配解决方案的数量。基于基数的QIs所具有的一个可取(必要)的属性是，在考虑的集合中添加一个不同的非支配解决方案应该能够改进(而不是降低)评估结果。这(弱)单调的概念是一致的。下面列出了10个基数QIs(项目45-54)： 根据Pareto最优解的参与程度，基于基数的QIs可以分为两类(项目45-48和项目49-54)。 一种是直接考虑集合中的非支配解，例如 the indicators cardinality 𝐷 number of unique nondominated solutions overall nondominated vector generation (ONVG) ratio of nondominated individuals 另一类是比较解集中的非支配解(nondominated solutions)和问题的帕累托最优解(Pareto optimal solutions)，该类中的QIs通常返回属于帕累托最优集的非支配解与最优集大小的比值，(例如：C1，ONVG ratio）,或者或者与解集本身的比值(例如，C2，error ratio) 除此之外，还有其他一些指标，它们只是简单地计算属于最优集的解决方案的数量。 虽然这里描述的是对最终MOEA性能的度量，但是其中许多度量也可以用于跟踪世代总体的性能。然后，除了一个总体性能度量之外，它还指示执行期间的性能(例如，到MOEA optimu的收敛速度)。虽然使用了两个目标的例子，但是这些指标可以扩展到具有任意数量的目标维度的PF。 由于解决方案集的基数通常几乎没有与帕累托前沿的代表性相关的信息，因此通常认为它不如其他三个质量方面重要。然而，如果优化器能够找到问题的很大一部分帕累托最优解决方案，那么评估基数质量可能会变得更加合理。这对于一些组合多目标优化问题尤其适用，其中帕累托最优解的总数很小。在这类问题中，计算得到的帕累托最优解的个数是反映解集质量的可靠指标。事实上，这种评价在一些组合问题的早期研究中经常使用。 Error ratio此indicator与onvg与onvg ratio 出自同一本书，并且有如下定于，为了方便引用原文： 简而言之：$P$ (也就是 pareto optimal set 包含于solution set) 是针对自变量来说的 也就是decision space。 $PF$ (也就是 Pareto Front ) 是针对目标函数值来说的，也就是objective space An MOEA reports a finite mumber of vectors in $PF_{known}$ which are or are not members of $PF_{true}$. If they are not members of $PF_{true}$ the MOEA has erred or perhaps not converged. This metric is mathematically represented by: E=\frac{\sum_{i=1}^{n}}{n}e_iwhere n is the number pf vectors in $PF_{known}$ and e_i = \begin{cases} 0 & if \ vector \ i,i=(1,...,n) \in PF_{true},\\ 1 & otherwise \end{cases}$E=0$，表明$PF_{known}$都在 $PF_{true}$。 $E=1$，表明$PF_{known}$中一个都不在 $PF_{true}$。 上图的值：$E=\frac{2}{3}$ 。 我们还注意到一个类似的度量，它度量由另一个 $P_{true}$ 支配的$P_{known}$ 中的解决方案的百分比。 然而，由于ER只在帕累托最优解中起作用，它可能会带来一些反直觉的情况。例如，在一个集合中添加更多的非支配解决方案可能会导致更差的分数。因此，考虑比较集本身中的非支配解可能是更好的选择，而且也不需要帕累托前沿。 Overall Nondominated Vector Generation and Ratio(ONVG)测试的MOEAs 每一代把 $P_{current}$ 添加到 $P_{known}$ 中，可能导致不同的数量的$P_{known}$ 。这个测量度计算的是在MOEA期间所找到的所有非支配解的数量，定义如下： ONVG = |PF_{known}|Schott 使用这个测量标准(尽管是在帕累托最优集上定义的，例如$|P_{known}|$ ) 。基因型或表现型地的定义这个测量标准可能是偏好问题，但是我们再一次注意到多个解可以映射到相同的向量上，或者换句话说，$|P_{known}| \geq |PF_{known}|$ (多对一)。尽管计算非支配解的数量可以让我们了解MOEA在生成所需解方面的有效性，但它并没有反映出$|P_{known}|$中的向量与$|PF_{known}|$ 之间的“距离”有多“远”。此外，太少的向量和$|PF_{known}|$的代表性可能很差;太多的向量可能会压倒DM。 ONVG Ratio很难确定$|ONVG|$的最佳值是多少。$PF_{known}$ 的基数可能在不同的计算分辨率下发生变化，也可能在拖把之间存在差异(可能是根本的)。报告$PF_{known}$的基数与离散$P_{true}$的比值可以让我们对找到的非支配向量的数量与要找到的存在向量的数量有一定的感觉。然后将这个度量定义为: ONVGR = \frac{|PF_{known}|}{|PF_{true}|}上图中，可知 $ONVG=3$，$ONVGR=0.75$。 C1如果已知由所有有效解组成的参考集R，那么看起来最自然的质量度量就是找到的参考点的比例。度量可以用以下方式定义： C1_R(A)=\frac{|A \cap R| }{ |R| }C2如果参考集不包含所有的非支配点，那么A中的被R所非支配的点集也许是属于非支配解集上的，这种情况，使用下列方法也许更可行： C2_R(A)=\frac{ | \{ u \in A | \ \nexists r \in R , r \succ u \}| }{|A|}然而，这些主要措施也有一些明显的缺点。他们对近似值的改进无动于衷。例如，考虑图11中所示的两个近似参考集，这两个近似是针对一个双目标背包问题得到的。显然，近似1比近似2好得多。近似1中的所有点都非常接近参考集，它们覆盖了参考集的大部分区域。然而，这两种近似的测度值都是相同的C1和C2。 图12中的示例说明了主要度量的另一个缺点。这两个近似由5个不占主导地位的点组成，所以它们的基数测度是相等的。然而，构成逼近3的所有点在目标空间中都是非常接近的，即它们代表了非支配前沿的同一区域。另一方面，近似值4的点分散在整个参考集合中。它们携带着丰富得多的信息，例如关于可能的目标范围的信息。这个例子表明，对于基本测度，无论它们的接近程度和关于非支配集形状的信息如何，逼近中的每个点都具有相同的权重。 Ratio of non-dominated individuals (RNI)这个绩效指标被定义为非主导个体的比率(RNI)对于给定的总体X， RNI(X)=\frac{nondom\_indiv}{P}nondom_indiv是种群X中非支配的个体数量，P是种群X的大小。因此，RNI = 1的值表示种群中所有的个体都是不受支配的，RNI = 0表示种群中没有一个个体是非支配的。由于通常需要大于零的总体大小，所以在$0 \leq RNI \leq 1$的范围内总有至少一个非支配个体。]]></content>
      <categories>
        <category>indicators</category>
      </categories>
      <tags>
        <tag>MOEA</tag>
        <tag>indicator</tag>
        <tag>CardinalityQI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[QIs for Uniformity]]></title>
    <url>%2F2019%2F01%2F26%2Funiformity%2F</url>
    <content type="text"><![CDATA[又看了好几天的剧。。。罪恶感啊 介绍均匀性的质量指标衡量集的解分布的均匀程度。由于解集的质量可以看作是其表示PF的能力，所以一个均匀分布的解集比一个非均匀分布的解集提供更好的帕累托前沿表示，可以认为它具有更好的质量。理想的均匀性QI应该排在由完全相等的解组成的集合的最高位置，对这个集合的一点干扰会导致更糟糕的评估结果。具体的indicators如下: 通常可以通过测量解之间距离的变化来评价解集的均匀性。这个类中的许多QIs都是按照这些思路设计的，例如，$spacing(SP)$[39],$deviation \ measure \Delta$[35] , $ uniformity \ distribution$[43], $\ minimal \ spacing$[38], $ spacing \ measure$[37] 和$uniformity$[41]。 其他则考虑解之间的最大最小距离[40 36 44]，和构建集群[34]或最小生成树[42]。 Minimal spacing前言先介绍spacing： S=\sqrt{\frac{1}{|Q|} \sum_{i=1}^{|Q|}(d_i-d)^2 } $d_i=min_{k\in Q\ and\ k \ne i}\sum_{m=1}^M|f_m^i-f_m^k|$ 。离$Q_i$最近的点的距离，距离公式每一维度(目标函数)的差值的平均值。 $f_m^i$：在最后的非支配解$Q$中第$i$个解的第$m$个目标函数值。 $d$：所有$d_i$的平均值。 $S$越接近0越说明解集是更加的均匀分布的帕累托最优前沿。 但此算法在上图所示中便展现出缺点： 可以直观的看出fig(b)的一致性比fig(a)要好，但通过公式却体现出相反的结论。 原因：离a最近的是b，离b最近的a，离c最近的是d，离d最近的是c。那么S值一定比fig(b)的低。而忽略了fig(a)中b与c之间很大的距离。 正文此算法更像是一个流程，总结下来就是把每个解看成一个点，每一个点只访问一次，求把所有点连起来的距离总和的最小值。 把所有点设为unmarked状态，随机找一个解，作为seed，此点变为marked。 在所有的unmarked点中，找到离刚刚设为marked/seed点最近的点。此点设为marked， 依次循环(2)，直至所有点均是marked，并记录路径的距离和。 把每个点都作为seed，取路径和最小。最后再处以$|Q|-1$ 其中，由于每个目标函数的性质可能不同，他们的取值范围也就可能不同，距离公式归一化修改为： d_i=\frac{1}{|F^{max}_m-F^{min}_m|}min_{k\in Q\ and\ k \ne i}\sum_{m=1}^M|f_m^i-f_m^k|$F^{max}_m$，$F^{min}_m$第m个目标的最大值和最小值。 如此算法,易得fig(b)的值会比fig(a)更小，更有效！ Spacing(SP)SP 测量一组解集之间解的距离变化。特别的，$A = \{a_1,a_2,…,a_N \}$, SP(A)=\sqrt{\frac{1}{N-1} \sum^N_{i=1} (\bar{d} - d_1(a_i,A/a_i))^2 }其中： $\bar{d}$ 是所有 $d_1(a_1,A/a_1)$ $d_1(a_2,A/a_2)$ $d_1(a_2,A/a_2)$,…, $d_1(a_N,A/a_N)$ 的平均值，$d_1(a_i,A/a_i)$ 是 $a_i$ 对 $A/a_i$ 的一范数(Manhattan distance)， d_1(a_i,A/a_i)=\min_{a \in A/a_i} \sum_{j=1}^m|a_{ij}-a_j|$m$ 是目标函数的个数，$a_{ij}$ 是第 $a_i$ 的解的第 $j$ 个目标的值。SP被最小化;数值越低，均匀性越好。SP值为0表示解集的所有成员在曼哈顿距离的基础上间距相等。请注意，SP仅测量解决方案的“邻域”分布。即使与MS一起工作，SP也不能涵盖集合的多样性质量，尽管这两个指标在文献中经常一起使用来达到这一目的。以下图为例，图2(b)和(c)中的解集均采用SP和MS满分;然而，它们分别位于帕累托前沿的边界和极端点。 Spacing metric假设有两个目标函数， spacing = \left[ \frac{1}{N-1}\sum_{i=1}^{N-1}(1 - \frac{d_i}{\bar{d}}) \right]为了计算$d_i$，我们考虑第一个目标，将$PPF$中的所有点按升序排序。接下来，为了计算$d_i$，我们使用下面的公式: d_i = \sqrt{(f_1(\vec{x_i} )-f_1(\vec{x_i+1}) )^2+((f_2(\vec{x_j} )-f_2(\vec{x_j+1}) )^2}$\bar{d}$ 便为 $d_i$ 的和的平均值。 Deviation measure $\Delta$由于优化解的多样性是多目标优化中的一个重要问题，我们设计了一种基于最终总体中最优非支配前沿解之间连续距离的度量方法。将得到的第一组非优解与均匀分布进行比较，计算偏差如下:(这个有特殊的背景才可适用) \Delta = \sum_{i=1}^{|\mathcal{F}_1|}\frac{|d_i-\bar{d}|}{|\mathcal{F}_1|}$\mathcal{F} = \{ \mathcal{F}_1,\mathcal{F}_2,… \}$ 是所有的非支配前沿。 为了确保这种计算考虑到解在真实前沿的整个区域的扩散，我们将边界解包含在非主导锋$\mathcal{F}_1$中。对于离散的帕累托最优前沿，我们为每个离散区域计算上述度量的加权平均值。在上式中，$d_i$是目标函数空间中最终总体的第一非支配前沿上两个连续解之间的欧式距离。参数$\bar{d}$是这些距离的平均值。 Cluster ($CL_\mu$)需要先介绍 Number of Distinct Choices ($NDC_\mu$). $NDC_\mu$从设计者的角度来看，所观察到的帕累托解集中包含的点越多，可供选择的设计选项就越多。然而，如果观测到的帕累托解在目标空间中过于接近，那么对于设计者来说，观测到的帕累托解之间的变化可能无法区分。换句话说，观察到的帕累托解的数量越多，并不一定意味着设计选择的数量越多。简而言之，对于一个观察到的帕累托解集$p=(p_1,…,p_{\bar{np}})$ ，只有那些彼此之间有足够差异的解决方案才应被视为有用的设计选项。 设数量$\mu , \ (0 &lt; \mu &lt;1)$为设计人员指定的数值，可将m维目标空间划分为$1/\mu^m$的小网格。为了简单起见，将$1/\mu$作为整数。每个网格都是指一个正方形(m维中的超立方体)，即无差异区域$T_{\mu(q)}$，其中区域内任意两个解点$p_i$和$p_j$都被认为是相似的，或者设计人员对这些解不感兴趣。下图给出了二维目标空间中的量$\mu$ 和 $T_{\mu(q)}$。 $T_{\mu(q)}(q,P)$ 表示是否有任何点$p_k \in P$属于区域$T_{\mu}(q)$。当至少有一个解点$p_k$落在无差异区域$T_{\mu}(q)$中时，$T_{\mu(q)}(q,P)$等于单元(或1)。$T_{\mu(q)}(q,P)$等于0(或0)只要$T_{\mu}(q)$区域没有解。一般来说，$T_{\mu(q)}(q,P)$可以表述为: T_{\mu(q)}(q,P) = \begin{cases} 1 & \exists p_k \in P \ p_k \in T_\mu(q)\\ 0 & \forall p_k \in P \ p_k \notin T_\mu(q) \end{cases}质量度量$NDC_{\mu}(q)$，即预先指定的m值的不同选择的数量，可以定义为: NDC_{\mu}(P)=\sum_{l_m=0}^{v-1}...\sum_{l_2=0}^{v-1}\sum_{l_1=0}^{v-1}NT_\mu(q,P)where $q = (q_1,q_2,…,q_m)$ with $q_i=\frac{l_i}{v} $ 其中，$v=1/\mu$ ，点 $q$ 位于目标空间m-网格线的任意交点上，坐标为$(q_1,q_2,…,q_m)$。如本节开头所示，，如果想让$NDC_{\mu}(P)$值较高的观察到的Pareto解集，对于预先指定的 $\mu$ 就要有相对于较低的值(网格越密，被删去的点就越少)。 正文上一节的质量度量，即 $NDC_{\mu}(P)$。然而，仅使用这个质量度量，无法正确解释集群现象。例如，假设有一个预先指定的m值，观察到的Pareto解集$P_1$提供了10个不同的解，有$NDC_{\mu}= 10$。现在假设，这里有另一组解$P_2$ 它提供了100个解，$NDC_{\mu}=10$ 。可以看出，设计人员并不希望看到解决方案集P2，因为该集中的许多解决方案可能是集群的。因此，引入了质量度量集群$CL_\mu(P)$: CL_\mu(p)=\frac{N(P)}{NDC_\mu(P)}其中$N(P)$为观察到的帕累托解的个数。在理想情况下，得到的每一个帕累托解都是distinct的，那么数量$CL_\mu(p)$的值等于1。在所有其他情况下，$CL_\mu(p)$都大于1。此外，集群数量$CL_\mu(p)$的值越高，解决方案集的集群化程度就越高，因此解决方案集的受欢迎程度就越低。 Hole relative size当我们看到这组度量标准，特别是间距度量(spacing metric)标准时，我们意识到它们有时在显示沿帕累托边界(帕累托边界上的一个洞)的点分布的不连续时是不准确的。因此，为了克服这个缺点，我们设计了一种新的度量，称为孔相对大小(hr)。 HRS度量允许计算沿帕累托边界分布的点的最大孔的大小。然后用孔的大小除以点与点之间的平均间距进行归一化。如下所示： HRS = \frac{\max_i d_i}{\bar{d}}$d_i$ 两个相邻解的距离。 $\bar{d}$ 点间的平均距离。 这个度量比间距度量提供的信息更多，但是，在尝试规避间距度量中的一个缺点时，我们在HRS度量中引入了另一个缺点:它不能在不连续的帕累托边界上工作。事实上，不连续的帕累托边界有天然的漏洞。因此，对于帕累托边界上的固定数量的解，HRS度规总是以高概率测量相同的值。因此，我们建议在不连续测试问题中不要使用这个度量。 Uniformity assessment(没看懂，心力憔悴)]]></content>
      <categories>
        <category>indicators</category>
      </categories>
      <tags>
        <tag>MOEA</tag>
        <tag>indicator</tag>
        <tag>UniformityQI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[QIs for Spread]]></title>
    <url>%2F2019%2F01%2F23%2Fspread%2F</url>
    <content type="text"><![CDATA[玩了好几天，看了好多剧，所以这几天的进度稍微有点慢，另外，《一起同过窗》真香！ 延展特性涉及解集覆盖的区域。一个具有良好分布的解集应该包含来自PF每个部分的解集，而不遗漏任何区域。然而，大多数扩展的QIs只度量解决方案集的范围(extent)。下表为总结： 这些QIs通常考虑the range formed by the extreme solutions of the set(由集合的极值解构成的范围)，例如maximum spread，和它的变体[25] [27] [28] [29] [30] [33]，或者 考虑the range enclosed by the boundary solutions of the set(集合的边界解所围成的范围)，实例如下图： 只考虑这些解的QIs可能会忽略PF的内部区域。 幸运的是，确实存在一些为解决方案集的整个覆盖范围设计的QIs。 例如，[23]测量解集的支持点的面积和长度；[24]计算解集在PF的最大不相似度；[31]将每个解与解集的其余解的不同之处相加。 Maximum Spread (MS)$MS(or \ \mathcal{M}_3^*)$ 被广泛的使用于延展性indicator。它通过考虑每个目标的最大范围来度量解决方案集的范围，公式为： MS(A) = \sqrt{\sum^m_{j=1} \max_{a,a' \in A} (a_j-a_j')^2 }m 是目标函数的个数。MS应求极大值。值越高，说明的可延展性越好，在二元目标情形下，非支配解集的MS值为其两个极值解的欧氏距离。 但是，如前所述，MS只考虑集合的极值解，不能反映扩散的特性。此外，由于它不涉及集合的收敛性，远离PF的解通常对MS值有很大贡献。这很容易引起误导性的评价。例如，一个解集集中于PF的一小部分，但有一个离PF很远的离群值，那么它的MS值就很好。为了解决这一问题，引入帕累托前缘的范围作为评价的参考，例如[27] [28]。 Extension规定： \min_{x \in X} F(x) = (f_1(x),f_2(x),...,f_l(x))\\ U_i = \max_{x \in Pareto(U)}f_i(x)\\ L_i = \min_{x \in Pareto(U)}f_i(x)\\ i=1,...,l令：$P_r = \{ F_1^1,…,F_l^1 \}$，其中，$F_i^1=(L_1,…,L_{i-1},U_i,L_{i+1},…,L_l),[i=1,…,l]$ 规定： d_r^p=\min\{ d(p_r,p)|p \in P \},p_r \in P_r因此，得表达式： EX=\sqrt{\sum(d_r^p)^2 }/l易知，$d_r^p$ 越小，说明有更好的延展性。 如果是三维图的话，$P_r$ 分别如下： Modified MS(勿看，瞎记的)只有知道正常和期望的条件，才能定义和避免异常和不期望的条件，例如解在目标空间的次优区域的分散，或者收敛到感兴趣区域之外的次优解。换句话说，为了克服收敛性和多样性的矛盾要求，需要一个应用相关的尺度来定义低、理想和高多样性的近似概念，这在高维问题中尤为明显。在所提议的机制的上下文中，决策人员DM1(通常，最好是领域专家)只需要对所需折衷表面的定义极值提出近似估计。这些极值将作为包含理想的PF的超立方体的顶点。 I_s = D / \left[ \sum_{m=1}^M \left( \max_{z_* \in Z_*}\{z_{*_m}\} - \min_{z_* \in Z_*} \{z_{*_m} \} \right)^2 \right]^{1/2}$z_t \in Z_t$ 可以表示PF的目标集。$I_s$ 能取任何正的实数值。理想情况下，要找到一个接近统一($I_S = 1$)的指标值(理想的多样性)。小于1 ($I_S &lt; 1$)的指示值表示与期望的解决方案的扩展相比，操作的解决方案之间的多样性较低。另一方面，指示符值大于1($I_S &gt; 1$)突出了目标空间中解的过度分散(高多样性)。这种超空间的过度分散很可能导致解与PF的发散，并通过引入循环行为，迫使MOEA反复探索空间中以前访问过的区域，从而阻碍了优化过程。 第二个多样性管理机制是DM2，它预测NSGA-II中使用的多项式突变算子可能会使潜在的解点广泛分散。DM2试图通过引入自适应突变算子，以一种可控的方式控制这种离散。这个新的变异算子试图定义组决策变量的变异范围在每一代的基础上的多样性程度的局部non-dominated集解决方案,为每个单独的决策变量中设置,在当地的多样性以NSGA-II年代拥挤的措施。 计算第i代近似集的扩展指标。 if $I_s&lt;1$ 在变异选择和生存选择过程中激活多样性促进机制。 Else If $I_s \geq 1$ 在变异选择和生存选择过程中，失活多样性促进机制。 Coverage error $\epsilon$$\epsilon$ 的概念： 解释一下就是：有两个集合$D,Z$，$D$ 是 $Z$ 的一部分，如果想要用 $D$ 代表 $Z$，那么就要用符号 $d_{\epsilon}$ 表示。并规定，遍历 $Z$ 中的每一个点，画一个圆，半径是 $\epsilon$ ，都要有 $D$ 中的解存在，并且找最小的 $\epsilon$。 $\delta$ 的概念： 翻译一下：这个是单对 $D$ 集合来说的，$D$ 中两两点的最小距离。 例子如下：实心 + 空心 = Z；实心 = D 因此 $\epsilon$ 要尽可能的小，$ \delta$ 尽可能的大。 \epsilon = \max_{z \in Z} \min_{x \in D} d(z,x)For a fixed element $z$ of $Z$, how well it is covered is determined by the closest point to $z$ in the representation $D$. How well the entire set $Z$ is covered depends on how well an arbitrary element of $Z$ is covered, and thus the coverage error \epsilon$ is equal to the maximum of coverage error quantities for individual points in Z. Similarly, the uniformity level $\delta$ is determined by the quantity. \delta=\min_{x,y \in D,x \ne y}d(x,y)the fact that $D$ is of finite cardinality, computing the uniformity level $\delta$ is simple as long as the metric $d$ is computable. PD PD(X) = \max_{s_i \in X}(PD(X-s_i)+d(s_i,X-s_i))where d(s,X)=\min_{s_i \in X}(dissimilarity(s,s_i))$d(s_i,X-s_i)$ 是从一个物种 $s_i$ 到另一个种群 $X$ 的相异度。 下图提供了一个方式展示了PD是如何计算的，在左图,解$s_i$和其他方案 $X−si$ 视为两个社区，他们的多样性之和是 $X−si$ (black dots)的和 与 $si$ 到 $X−si$ 的相异值的和组成： 每个解与整个总体的不同之处是可以计算的，每个解都与其最近的未复制邻居相关联。然后，这些差异的和导致了整个种群的多样性，可以看作是X的结构，上右图所示，(其中较暗的线比较亮的线连接得早)。具体算法如下： 其中： $d$ 是n*n的矩阵，例如(i,j)就是 第i个解与第j个解的p范数距离($L_p-norm$)，因此是对称矩阵。 $min(d,[],2)$ 出自于matlab语法，对每一行取最小值，因此输出是一列。 另外，这位老师居然还是我们学校的老师，在电院，好奇翻了一下个人主页，居然有代码！我会附录在本博客最后，其中中文为我注释。 不同的相异评价在计算PD占很重要的作用。通常采用两个解之间的距离作为它们的相异之处。但是请注意，欧几里得距离不太适合在高维空间中测量邻域。由于MaOPs的解分布在高维目标空间中，基于$L_2$范数的欧氏距离不适用于PD中的不相似度计算。 从下图中我们可以清楚地看到，p越小，各维$L_p$对0越敏感。相反，基于$L_p-norm-based$的距离测度不适用于测量p&gt;1的高维数据的差异性。因此，为了测量MaOPs的多样性，需要将p设置为p &lt; 1。已有研究表明，只要p&lt; 1，该测度的有效性对p不敏感。因此，p在PD中不是一个参数，本文将p设为0.1。 指示器使用单个标量值来描述m维分布。因此，无论哪个指标，都会丢失一些信息。因此，尽管不同的指标可能捕获不同的信息，但希望捕获一些关键信息。当得到PF f1 +f2 +f3 = 1的三个极值点时，在这三个极值点的集合中加入不同的解，多样性度量的值是不同的。下图为在三个极值点集合中加入PF的另一个解时PD、MS、NDC (b =4)、熵(b =4)的变化值，其中颜色表示矩阵的大小(颜色较深的点值小于颜色较浅的点值)。如果根据这些指标选择一个解决方案以增加多样性，下图中较亮的部分优先于较暗的部分。一旦得到极值点。MS值达到最大值。因此，没有任何解决方案能够改进MS。虽然中间部分是由NDC和熵推动的，但解在网格内是无法区分的。对于PD，中间部分提升，值不断变化。从图4可以看出，PD通常可以促进不同的解决方案。 Overall Pareto Spread当设计的目标函数都被考虑时，总体的PF延展性度量量化了所观测的目标在目标空间中的延展能力。这个度量被定义为两个超矩形的体积比，其中一个是 $HR_{gb}$ ，它对于每一个所设计的目标的好点与坏点。类似地， $HR_{ex}$ 定义了所观察到的Pareto解集的极值点。整个PF的延展性变为$HR_{gb}$与 $HR_{ex}$ 之比： OS(P)=\frac{HR_{ex}(P)}{HR_{gb}}$P$ 是所观测的Pareto解，$m$ 为目标函数个数，其中： OS(P)= \frac{\prod_{i=1}^{m}|\max_{k=1}^{\bar{np}} (p_k)_i -\min_{k=1}^{\bar{np}}(p_k)_i |}{\prod_{i=1}^{m}|(p_b)_i-(p_g)_i|}\\ =\prod_{i=1}^{m}| \max_{k=1}^{\bar{np}}[\bar{f_i}(x_k)] -\min_{k=1}^{\bar{np}}[\bar{f_i}(x_k)] | 例如，在图4所示的两个目标空间中，PF-spread的计算公式为: OC(P) = \frac{h_1h_2}{H_1H_2}其中： $P_1,P_2$ 是两个Pareto solution sets。if $OS(P_1)&gt;OS(P_2)$, then the solution set P1 is preferred to P2 . h_1=|\bar{f_1}_{max}-\bar{f_1}_{min}|\\ h_2=|\bar{f_2}_{max}-\bar{f_2}_{min}|\\ H_1=|(p_g)_1-(p_b)_1|\\ H_2=|(p_g)_2-(p_b)_2|PD’s code123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990% Authors: Handing Wang, Yaochu Jin, Xin Yao% University of Surrey, UK, and University of Birmingham, UK% EMAIL: wanghanding.patch@gmail.com, yaochu.jin@surrey.ac.uk, X.Yao@cs.bham.ac.uk% WEBSITE: http://www.surrey.ac.uk/cs/people/handing_wang/% DATE: March 2016% ------------------------------------------------------------------------% This code is part of the program that produces the results in the following paper:% Handing Wang, Yaochu Jin, Xin Yao, Diversity Assessment in Many-Objective Optimization, Cybernetics, IEEE Transactions on, Accepted, 10.1109/TCYB.2016.2550502.% You are free to use it for non-commercial purposes. However, we do not offer any forms of guanrantee or warranty associated with the code. We would appreciate your acknowledgement.% ------------------------------------------------------------------------function [ pd ] = PD( X )% Usage: [ pd ] = PD( X )%% Input:% X -Objective values of the population n*m (n solutions with m objectives)%% Output: % pd -PD value of population X%p=2;%lp norm setting0.1C=zeros(size(X,1),size(X,1));%connection arrayD=zeros(size(X,1),size(X,1));%dissimilarity array%Calculate the dissimilarity between each two solutionsfor i=1:size(X,1)-1 for j=i+1:size(X,1) d=sum(abs(X(j,:)-X(i,:)).^p,2).^(1/p); D(i,j)=d; D(j,i)=d; endendDMAX=max(max(D))+1;D(logical(eye(size(D))))=DMAX;n=size(X,1);pd=0;for k=1:n-1 %Find the nearest neighbor to each solution according to D in each row. [d,J]=min(D,[],2); %Find solution i with the maximal di to its neighbor j [dmx,i]=max(d); while liantong(C,i,J(i))==1 %i and j are connected by previous assessed solutions if D(J(i),i)~=-1 D(J(i),i)=DMAX; %Mark the connected subgraph end if D(i,J(i))~=-1 D(i,J(i))=DMAX; end [d,J]=min(D,[],2); %Find solution i with the maximal di to its neighbor j [dmx,i]=max(d); end C(J(i),i)=1; C(i,J(i))=1; pd=pd+dmx; if D(J(i),i)~=-1 D(J(i),i)=DMAX;%Mark the used dissimilarity di. end D(i,:)=-1;%Mark the chosen solution iendendfunction [w]=liantong(C,I,J)% Usage: [w]=liantong(C,I,J)%% Input:% C -Connection array% I -index I% J -index J%% Output: % w -1 if solutions I and J are connected, 0 if solutions I and J are not connected.%V=I;Child=find(C(V,:)==1);if isempty(find(Child==J))==0 % 直接连接 w=1; returnelse C(V,:)=0; % 删掉点I C(:,V)=0; for i=1:size(Child,2) % 遍历连接点I的其他点 w=liantong(C,Child(i),J); % 进行递归 if w==1 return end endendw=0;end]]></content>
      <categories>
        <category>indicators</category>
      </categories>
      <tags>
        <tag>MOEA</tag>
        <tag>indicator</tag>
        <tag>SpreadQI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Convergence--Distance-based QIs]]></title>
    <url>%2F2019%2F01%2F21%2Fdistancebased%2F</url>
    <content type="text"><![CDATA[可谓呕心沥血，翻译的累死我了，这篇是关于收敛性的indicators的《Distance-based QIs》。 分类可以进一步分为两类： 测量所考虑的解集到从帕累托前缘导出的一个或多个特定点的距离：the ideal point, knee point(s) , the Zeleny point and the seven particular points。 the ideal point是由帕累托前缘各目标的最优值所构造的点。 knee point(s)是帕累托前缘上的点，它具有从相邻点计算出的最大反射角。 the Zeleny point是通过分别最小化每个目标得到的点。 the seven particular points是由二元多目标问题的帕累托前缘的理想点和极值点导出的7个特殊点 测量到一个很好地表示帕累托前沿的reference set的距离。在这一组中，最常用的指标是GD。GD首先计算解集中每个解到参考集中最近点的欧氏距离，然后求所有这些距离的二次平均值。这一组中的其他QIs可以看作是GD的变体，例如taking the arithmetic mean of the distances，the powermean，considering the Tchebycheff distance，introducing the dominance relation between solutions and points in the reference set。 measure the distance of the considered solution set to one or several particular points derived from the PFTchebycheff distance to the knee point d(z,z^*,\lambda)=\max_{1 \leq j \leq k}\{ \lambda_j |z_j^* - z_j| \}其中： k：目标函数的数量。 $\lambda_i=\frac{1}{R_i}$，$R_i$是第i个目标函数的范围(range)。 Defined this way, the knee of the Pareto front is the point in the feasible objectivespace, $ \Lambda$, which corresponds to $ \min_{z∈\Lambda} d(z, z^∗, \lambda)$. 如果一个偏好关系的$PF_{approx}$集合比另一个关系的$PF_{approx}$集合包含更多的膝关节周围的解，则该偏好关系优于其他关系。 Seven point average distance该问题用于二元目标优化。 如果有效集的先验知识是可用的，MCGA完全解析E的能力可以很精确的理解为它与个体的标准和其他(已决定的)点有多接近。由于E对于任何一个测试问题都是未知的，因此为每个问题生成7点法，以衡量算法的有效性。个体准则最优约束了两个标准问题的有效集，但也可通过单独优化每一个准则而不考虑另一个准则来求出个体准则最优。有了这两点，七点法再$J_1-J_2$被定义如下原点[0,1]，最大点(在E范围内)[0,$J_2^{worst}$]和[$J_1^{worst}$,0]，和在原点与最大值之间的每个轴上的两个点。 原文： With the resulting two points at hand, the seven comparison points are denned on $J_1-J_2$as the origin [0,0], the maximum (within the range of E) of each criterion [0, $J_2^{worst}$] and [$J_1^{worst}$, 0], and two points on each axis between the origin and the maximum value. 全距离测量是通过距离处以7，该距离是从七个点中每一个点到离此点最近的MCGA种群的点的距离和。因此，每次创建距离度量时，使用总体中的7个成员。他的优点是比较不同人群在某一特定问题上的相对优势的准确方法。对于给定的问题，距离度量值最小的总体将是最接近E的总体。 这七个点具体是什么我实在没有翻译出来，在查找文献时《Evolutionary Algorithms for Solving Multi-Objective Problems 》作者：Carlos Coello Coello， David A. Van Veldhuizen， Gary B. Lamont时，有如下叙述： measure the distance to a reference setGenerational Distance (GD)GD首先计算解集中每个解到参考集中最近点的欧氏距离，然后取所有这些距离的二次平均。 公式： GD(A)=\frac{1}{N} ( \sum_{i=1}^{N} (d_2(a_i,PF)^2)^{1/2}a solution set $A=\{ a_1,a_2…,a_N\}$ $d_2(a_i,PF)$是$a_i$到PF的2范式距离(欧几里距离) 在实际应用中使用了一个很好地表示PF的参考集R。 d_2(a_i,PF)=\min_{r \in R}d_2(a_i,r)$d_2(a_i,r)$是$a_i$与$r$的欧几里距离。如果前端的几何性质是已知的，GD不一定需要一个表示PF的引用集。 GD的值理应是要极小的。如果值为0表明该集合位于Pareto front /reference set中。作为为后代间的代际评估而设计时，GD通常用于度量solution set 向PF的演化过程。然而，由于GD考虑的是二次平均值(quadratic mean)，因此它对异常值非常敏感，无论其他解的表现如何，它都会返回一个异常值得分很低的解集。当$ N \rightarrow \infty, \ GD \rightarrow 0 $，尽管这个集合远离PF。因此，只有当考虑的集合具有相同/或非常相似的大小时，GD才可靠地可用。幸运的是，公式中的算术平均数代替二次平均数，这个问题可以解决。事实上,在一些最近的研究，GD指标的一般形式的指数“p”和“1 /p”而不是“2”和“1/2”。设置p = 1现在已经被普遍接受，并与它的反转版本IGD一起使用(度量从帕累托前的点到所考虑集合中最近解的距离的算术平均值)。 来自“Measuring the Averaged Hausdorff Distance to the Pareto Front of a Multi-Objective Optimization Problem”的下文： 虽然在许多研究中使用了GD，但并不是EMO社区的所有研究人员都接受GD。我们推测一个可能的原因(可能是主要的原因)是它的归一化策略，如下面的例子所示:假设我们有一个(任意的)点$a \in Q$，在不丧失通用性的情况下，让图像F(a)到PF的距离为1。现在将 archive $A_n$定义为由a的n个副本给出的multisets，即$A= {a,…,a}$。“平均”距离的F(A)向PF，有: GD(F(A_n),F(P_Q))=\frac{||(1,...,1)^T||_p}{n}=\frac{\sqrt[p]{n}}{n}我们可以看到，随着n的增加，近似质量就会变得越来越“好”，尽管估计值并没有怎么变，archives $A_n$甚至收敛到“完美”估计： \lim_{x \to \infty}{GD(F(A_n),F(P_Q))=0}由上述的结果可以推广:例如，我们可以考虑a的小扰动，而不是multisets。或者，如果$F(A)$是有界的，不管$A_n$的a是否被支配，也不管$F(a)$离PF有多远，甚至满足$|A_n|=n$的任意archive序列任何$A_n$都能被选择。因此，在EMO上下文中，从这个角度来看，用进一步的、甚至占主导地位的解决方案“填充”归档文件是有好处的，因为通常较大的集合会产生更好的GD值。在社区中，它的建立是为了固定种群大小，以便对不同的算法进行比较(例如，N = 100)。然而，这给基于不受先验定义值限制的存档的MOEAs带来了麻烦。因此，“完美的”归档器(关于GD)可以接受所有(或至少是尽可能多的)候选解决方案。这当然不是我们想要的效果。 为解决以上问题，便提出了$GD_p$： $GD_p$ GD_p(X,Y)=\left(\frac{1}{N} \sum_{i=1}^{N}dist(x_i,Y)^p\right)^{1/p}$dist(x_i,Y)=\inf_{v \in Y}||x_i,v||$，$\inf$ 为下界(最小值)。 公式上的区别：把$\frac{1}{N}$在$()^{1/p}$从放括号外变为括号里。 我们把这个新指标命名为$GD_p$(索引p)只区分经典版本，这是需要在这项工作中进一步比较。“新”指标不具有上述讨论的不需要的特征，因此在比较具有不同大小的集合时似乎更为公平。特别是，大型候选集不再必须是“好”的。例如上例中$GD(F(A_n),F(P_Q))=1$ 对于所有的$n \in \mathbb{N}$ 。 \min_{x \in Q}{F(x)}\\ F(x) = (f_1(x),...,f_k(x)),the \ vector \ of \ the \ objective \ functions命题1：令$k=2​$(二元目标优化问题)，$F(P_Q)​$是连接的，有$a,b\in Q​$，有： a \prec b \ \Rightarrow \ dist(F(a),F(P_Q)) 0$dist(F(b),F(P_Q))$是固定值 r($r \ne 0$)，以$F(b)$为圆心，r为半径画一个圆，交点便是$p_b$(有点圆与$P_Q$相切的感觉)。分情况讨论： 当 $a \in P_Q$ 时，那么$dist(F(a),F(P_Q))=0$ ，以此得结论结果。 当 $a \notin P_Q $ 时 当 $ p_b \prec a$ 时 因为$a \prec b$ dist(F(a),F(P_Q)) \leq||F(a)-F(p_b)|| < ||F(b)-F(p_b)||=dist(F(b),F(P_Q)) 当 $p_b \nprec a$ 时，也就是 $p_b$ 和 $a$ 互相非支配，那么应该存在$i,j \in \{1,2\}, i \ne j$ f_i(p_b) < f_i(a) \ \ and \ \ f_j(p_b) > f_j(a） ​ 因为$a \notin P_Q$，那么也会存在$p_a \in P_Q$ 令 $p_a \prec a$(满足上面两个都是小于号) ，因为$F(P_Q)$ 是 ​ 连贯的( index from &gt; to &lt; 一定有一个=)，这存在一条$F(p_a)$到$F(p_b)$ 的路径， ​ 那么一定存在 $\bar{p} \in P_Q \ let: \ f_j(\bar{p})=f_j(a)$ ，又因为 $\bar{p}$ 和 $p_b$ 互相不支配(同在$P_Q$)， ​ 那么有： dist(F(a),F(P_Q)) \ \leq \ ||F(a)-F(\bar{p})|| \ = |f_i(a)-f_i(\bar{p})| \ < \ |f_i(b)-f_i(p_b) | \\ \ \leq \ ||F(b)-F(p_b)|| \ = \ dist(F(b),F(P_Q))证明完毕。其中要解释一下，为何： |f_i(a)-f_i(\bar{p})| \ < \ |f_i(b)-f_i(p_b) | $f_i(b) &gt; f_i(a)$ ，这是因为 $ a \prec b$ $f_i(p_b) &lt; f_i(\bar{p})$，这个比较麻烦QWQ $\bar{p} \ and \ a $ = $\begin{cases} f_j(\bar{p})=f_j(a) &amp; (1 \\ f_i(\bar{p}) &lt; f_i(a) &amp; (2 \end{cases}$ $ p_b \ and \ a $= $\begin{cases} f_j(p_b) &gt; f_j(a) &amp;(3 \\ f_i(p_b ) &lt; f_i(a) &amp;(4 \end{cases}$ ​ $ (1,(2 \Rightarrow f_j(p_b) &gt; f_j(\bar{p}) $ ，又因为 $\bar{p}$ 和 $p_b$ 互相不支配，那么$for \ i \ must \ be:f_i(p_b) &lt; f_i(\bar{p})$ 一个有趣的问题当然是如果拖把涉及两个以上的目标会发生什么。但是，我们不得不把这个问题留到以后调查。 当帕累托前缘断开时，上述结果不成立。然而，如果一个元素足够接近帕累托集合，这种“单调行为”仍然成立。下面的例子和命题分别给出了反例和证明。 例如：$F(P_Q)=\{(10,0)^T,(0,1)^T \}$ , $F(a)=(11,3)^T,F(b)=(5,2)^T \ so \ a \prec b, but$ $dist(F(b),F(P_Q)) = \sqrt{1^2 + 3^2}=\sqrt{10} &lt; \sqrt{29}=\sqrt{5^2 + 2^2} = dist(F(a),F(P_Q))$ 命题2： 翻译一下就是：对于一个$k$个目标的问题，任何一个维度$i$，存在$y(a,i)$的目标值向量属于$F(P_Q)$，并且满足$y(a,i)$在除了第$i$维度上的值与 $F(a)$ 相同,（第$i$维任意）。【其中与命题1的差别是，在1中$k = 2$，但在此命题中，并没有这个限制】 证明：推到与前一个类似，只是推广到高纬度上了$k&gt;2$。 因为$P_Q$是紧凑的，所以一定存在 $p_b\in P_Q$，满足： dist(F(b),F(P_Q)) =||F(b)-F(p_b)|| 当 $ p_b \prec a$ 时 因为$a \prec b$ dist(F(a),F(P_Q)) \leq||F(a)-F(p_b)|| < ||F(b)-F(p_b)|| 当 $ p_b \nprec a$ 时，存在$i \in \{1,…k\}$，满足$f_j(p_b) &gt; y(a,i)_i$ (翻译一下：一个解y(ami)，它的第i维满足$f_j(p_b)$ 与，其他维度的数值与$a$相同)并且： dist(F(a),F(P_Q)) \ \leq \ ||F(a)-y(a,i)|| \ = f_i(a)-y(a,i)_i \ < \ f_i(b)-f_i(p_b) \\ \ \leq \ ||F(b)-F(p_b)|| \ = \ dist(F(b),F(P_Q)) 这个结果的关键是投影$y(a, i)$的存在性，$F(a)$足够接近帕累托前沿，在这种情况下不需要$F(P_Q)$的连通性。如下图： 总结，假使PF是连贯的(至少对于k = 2)，主导解(dominating solutions) $a$ 产生更好的 $dist$ 值比其被支配解(dominated points)$b$。此外，这个依然保留的话，要么当F (a)是“足够远”帕累托前面(在这种情况下，声明：$dist(F(b),F(P_Q))=||F(b)-F(p_b)|| &gt; 0$，则必须 $p_b$ 支配 $a$ )，要么就足够接近(命题2)。 从GDp的角度来看，这些结果可以解释为:如果新的归档结果来自于前一个归档，用一个支配解替代了一个被支配解，那么$GD_p$值就会下降。对于$A1 = \{b, x_2，…， x_n\}$， $A2 = \{a, x_2，…， x_n\}$，其中$a$和$b$为上式，则为: GD_p(F(A_2),F(P_Q)) < GD_p(F(A_1),F(P_Q))然而，下面的结果更为普遍，则需要进一步的假设： 命题3： $A,B \subset \mathbb{R}^n \ be \ finite \ sets \ such \ that​$ $ \forall a \in A \ \exists b \in B:F(b) \leq_p F(a) $ $ \forall b \in A \ \exists a \in B:F(b) \leq_p F(a) $ $ \exists b \in B \backslash A ,\ \exists a \in A\backslash B:b \prec a$ $ \forall a \in A \ \forall b \in B:if \ a \prec b \Rightarrow dist(F(a),F(P_Q))&lt;dist(F(b),F(P_Q)) $ 那么： GD_p(F(B),F(P_Q))]]></content>
      <categories>
        <category>indicators</category>
      </categories>
      <tags>
        <tag>MOEA</tag>
        <tag>indicator</tag>
        <tag>ConvergenceQI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Convergence--Dominance-based QIs]]></title>
    <url>%2F2019%2F01%2F14%2Fdominancebased%2F</url>
    <content type="text"><![CDATA[此篇介绍的是QIs for Convergence的第一部分《Dominance-based QIs》。看了一部分方法的论文，剩下一部分实在看不下去了，想继续看看别的，有时间有精神回来补一下~ QIs用于收敛性收敛性作为解集质量的一个重要方面，在集的评价中受到了广泛的关注。文献中存在两类收敛QIs。一是考虑解或集之间的帕累托支配关系(表2项目1-9);另一种方法是考虑解集到帕累托前的距离，或者从帕累托前导出的一个/多个点(项目10 -22)。 Dominance-based QIsA type of frequently-used dominance-based QIs is to consider the dominance relation between solutions of two sets , such as the C indicator , $\widetilde{C}$ indicator, $\sigma- \tau- and \ \kappa-$ metrics , and contribution indicator.Other QIs concerning solutions’ dominance include wave metric, purity, Pareto dominance indicator, and dominance-based quality. The wave metric crunches the number of the nondominated fronts in a solution set. The purity indicator counts nondominated solutions of the considered set over the combined collection of all the candidate sets. The Pareto dominance indicator measures the ratio of the combined set’s nondominated solutions that are contributed by a particular set. The dominance-based quality considers the dominance relation between a solution and its neighbours in the set. $C-metric$定义为： C(A,B)=\frac{|\{b\in B:\exists a \in A,a \preceq b \}|}{|B|}$C$一方面可以计算出$B$中的解被$A$中解所支配的比例部分，另一方面也可以计算出$A$相对于$B$的性能。 当$C(A,B)=1$时，意味着$B$中的所有解都被$A$中的所$\preceq$。 当$C(A,B)=0​$时，意味着$B​$中的所有解都无法被$A​$中的$\preceq​$。 注意：$C(A,B) \ne 1-C(B,A)$ $ C(A,A) \ne 0$ 如果$W$是一个非支配解集，$A,B$满足$A \subseteq W$，$B \subseteq W$，但$C(A,B)$可为[0,1]中的任意一个值。 $\widetilde{C}-metric$多目标优化环境下的性能度量是评价优化器定量性能的数学工具，它通过单独考虑优化器或与其他优化器进行比较来评价的。这种方法可以与优化器在线评估和性能改进的优化器结合使用，也可以离线应用于两个或两个以上优化器的最终结果，以比较它们的性能、产生的结果的质量和/或要求的计算努力。 性能指标可以大致分为两类： 基本度量:一个标准度量满足一定要求的解决方案的数量或比例，比如度量关系。 序数或几何度量:这些方法不度量数量，而是通过考虑几何位置来度量。 \widetilde{C}(A,B)=\frac{|\{b\in B:\exists a \in A,a \prec b \}|}{|B|}$ C(A,A) = 0$ ，因为$A$是非支配解集。 对于$\widetilde{C}(A,B)$、$C(A,B)$，值越高说明B中的解受A所$\preceq$的比例越多。 如果$W$是一个非支配解集，$A,B$满足$A \subseteq W$，$B \subseteq W$，但$C(A,B)=0$。 $\widetilde{C}(A,B)$与$C(A,B)$都没有考虑到前沿的延展性(extent)与一致性(uniformity)。 上图可以看出(minimise)：A的一致性(uniformity)更好，而B集中聚到了一个区域。 但有：$ C(A,B) = C(B,A) =\widetilde{C}(A,B) =\widetilde{C}(B,A) =\frac{4}{12}$，即使A的元素在B的大部分区段上占主导地位。 上图，尽管B有很好的延展性(extent)， 但是：$ C(A,B)=\widetilde{C}(A,B) =\frac{2}{12}$ ， $C(B,A)=\widetilde{C}(B,A) =\frac{0}{12}$ ，从$C$、$\widetilde{C}$中的值看出$A$优于$B$。 Contribution indicatorThe contribution of algorithm $PO_2$ relatively to $PO_2$ is roughly the ratio of non dominated solutions produced by $PO_2$. 规定： $C = PO_1 \cap PO_2$ 集合$W_1$为$PO_1$中支配$PO_2$的解集，集合$W_2$为$PO_2$中支配$PO_1$的解集。 集合$L_1$为$PO_1$中被$PO_2$支配的解集，集合$L_2$为$PO_2$中被$PO_1$支配的解集， 集合$N_1$为$PO_1$中不可与$PO_2$构成不可比较的解集，即$PO_1 \backslash (C \cup W_1 \cup L_1) $ 集合$N_2$为$PO_2$中不可与$PO_1$构成不可比较的解集，即$PO_2 \backslash (C \cup W_2 \cup L_2) $ 表达式为： CONT(PO_1 / PO_2) = \frac{\frac{|C|}{2}+|W_1|+|N_1|}{|C|+|W_1|+|N_1|+|W_2|+|N_2|}可知： ​ 如果$PO_1$与$PO_2$是相同的解集，那么$CONT(PO_1 / PO_2)=CONT(PO_2 / PO_1)=1/2$ ​ 如果$PO_2$中的所有解都被$PO_1$所支配，那么，$CONT(PO_2 / PO_1)=0$。 我的理解： CONT(PO_1 / PO_2) = \frac{\frac{|C|}{2}+|W_1|+|N_1|}{|C|+|W_1|+|N_1|+|W_2|+|N_2|}\\ =\frac{\frac{|C|}{2}+\frac{|W_1|+|W_1|}{2}+\frac{|N_1|+|N_1|}{2}}{|C|+|W_1|+|W_2|+|N_1|+|N_2|}\\ =\frac{1}{2}\frac{|C|+|W_1|+|W_1|+|N_1|+|N_1|}{|C|+|W_1|+|W_2|+|N_1|+|N_2|}也就是说：对于$CONT(PO_1 / PO_2)$，如果$|W_1|+|N_1| &gt; |W_2|+|N_2|$，则大于0.5。 也就是说：$PO_1$中支配$PO_2$的解和不能与$PO_2$比较的解越多，$CONT(PO_1 / PO_2)$越大。 $\sigma-\ \ \tau- \ \ \kappa- \ metric$前言对于一个评价指标，无论是类别如何，想要使他可用，都要满足以下五个特征： Monotonicity/compatibility(单调性/兼容性)：对于两个PFs的支配关系，度量标准应该满足单调性/兼容性，例如，设度量标准为$\xi$，如果A支配B，A就应该比B好或至少不能差于B。因此 $A \succeq B \Rightarrow \xi (A) \geq \xi(B)$或严格单调$A \succ B \Rightarrow \xi (A) &gt; \xi(B)$ 。 Transitivity(传递性)：在所比较的所有PFs的完全顺序中，一个度量应该是可传递的。如果A优于B，B优于C，那么通过$\xi()$也应得出，A优于C。直接比较度量通常会在被比较的不同PFs之间产生不可传递关系。传递性通常只在引用度量和独立度量中得到保证。这是因为这两种方法都为每个PF分配一个数字，并且实数之间的比较是可传递的。 Scaling/meaningfulness(缩放性/有意义性)：目标函数通常需要进行缩放，例如进行单调变换以映射给定范围内的目标值，例如在[0,1]中。在这种情况下，一个度量应该是缩放不变的或有意义的，即，该度量不应受任何缩放的影响。尺度不变度量通常只利用解之间的优势关系，而不是它们的绝对客观值。 Computational effort(计算工作量)：此属性用于计算给定pf的度量值所需的计算资源。为了比较不同度量的性能，通常只考虑运行时复杂性作为所需的计算工作。 Additional information(附加信息)：许多指标依赖于不同类型的附加问题信息。一些假设问题的POF是已知的，而另一些则依赖于一些用户定义的依赖于问题的引用目标向量或引用PFs。因此，希望一个度量具有尽可能少的参数。 $\sigma-metric$规定：a dominates b is $a \succ b$ 原文： Sigma-metric($\sigma $-metric): The performance value, $\sigma_{ij} $, assigned to the j-th PF of the i-th optimizeris the number of solutions of the r-th optimizer which are strictly dominated by at least one solution of that PF of the i-th optimizer,where $i,r \in {1,2}$ and $i \ne r$. 公式： \sigma_{ij}=\sum_{s=1}^{F_r}\sum_{t=1}^{L_{rs}}\max_{k\in \{1,...L_{ij} \}}I(p_{ijk}\succ \succ p_{rst})具体规定如下： optimizer\ i_{th}=\begin{cases} PF_1 & |PF_1|=L_{i1} \\ PF_2 & |PF_2|=L_{i3} \\ ...\\ PF_j & |PF_j|=L_{ij}\\ ...\\ PF_{F_i} & |PF_{F_i}|=L_{i{F_i}} \\ \end{cases}\\ optimizer\ r_{th}=\begin{cases} PF_1 & |PF_1|=L_{r1} \\ PF_2 & |PF_2|=L_{r3} \\ ...\\ PF_j & |PF_j|=L_{rj}\\ ...\\ PF_{F_r} & |PF_{F_{r}}|=L_{rF_r} \end{cases}有两个优化器(optimizer)，每个优化器都$F_i$个$PFs$，对于第$i$个优化器，第$j$个$PF$，它有$L_{ij}$个解(solutions)。而$p_{ijk}$则为第$i$个优化器，第$j$个$PF$的第$k$个解。 $I(\bullet)$如果内部true则返回1，否则返回0。 \max_{k\in \{1,...L_{ij} \}}I(p_{ijk}\succ \succ p_{rst})翻译为：对于指定的解 $p_{rst}$ 如果在第$i$个优化器，第$j$个$PF$中有$\succ \succ p_{rst} $关系的解，就为1，都没有则为0。 整体来看：对于第$r$个优化器的所有解中，被第$i$个优化器的第$j$个$PF$的所有$L_{ij}$个解所支配的个数。 因此，最大值为$optimizer\ r_{th}$的所有解的个数。 ps.原论文写的是$F_rL_{rs}$,但是我不赞同…..我认为是$\sum_{s=1}^{F_r}{L_{rs}}$，当$L_{r1}=L_{r2}=…=L_{F_r}$时与原论文一致。 $\tau-metric$原文： Tau-metric ($\tau -metric$): The performance value, $\tau_{ij}$, assigned to the j-th PF of the i-th optimizer is the number of solutions of the r-th optimizer which are weakly dominated by at least one solution of that PF of the i-th optimizer,where $i,r \in \{1,2\}$ and $i \ne r$. Further, $\tau_{ij} $may also be rewarded if the j-th PF of the i-th optimizer weakly outperforms a PF of the r-th optimizer. Since the metricis based on the concept of weak dominance,it may be done just as an attempt to take into account the compatibility of the metric with the ‘‘weak outperformance relation’’ given indefinition (8). However, it would be a new dimension of research in order to generalize the outperformance relations in terms of multiple(more than two) PFs.​ 公式： \tau_{ij}=\sum_{s=1}^{F_r}\{ [\sum_{t=1}^{L_{rs}}\max_{k\in \{1,...L_{ij} \}}I(p_{ijk}\succeq p_{rst})] + I(A_{ij} \ \vartheta_w \ A_{rs} ) \}规定： $\vartheta_w$ (weakly outperform): $A \ \vartheta_w \ B$ means $ A \succeq B $ and $\exists c \in A \ but \ c \notin B $。 ​ A不会比B差，并且A有B不存在的解。 在遍历$r_{th}\ optimizer$的$PF_s$时，如果与第$i$个优化器，第$j$个$PF$ 满足 ： $A_{ij} \ \vartheta_w \ A_{rs} $，再加1。 因此，相对于$\sigma-metric$最大值再加上$F_r$即$F_r(L_{rs}+1)$。 $\kappa-metric$原文： Kappa-metric ($ \kappa-metric$): The performance value, $\kappa_{ij}$ , assigned to the j-th PF of the i-th optimizer is the number of solutions of the r-th optimizer which cannot weakly dominate a given solution of that PF of the i-th optimizer,where $i,r \in \{1,2\}$; and $i \ne r$. For the same reason as in the case of the $\tau-metric$, $k_{ij}$ may also be rewarded if the j-th PF of the i-th optimizer weakly outperforms a PF of the r-th optimizer. 公式： \kappa_{ij}=\sum_{s=1}^{F_r}\{ \sum_{l=1}^{L_{ij}} \sum_{t=1}^{L_{rs}} I(p_{rst}\nsucceq p_{ijl}) + I(A_{ij} \ \vartheta_w \ A_{rs} ) \}遍历$r_{th}\ optimizer$的所有解，对于每一个解$p_{rst}$，如果$p_{rst} \nsucceq p_{ijl} (l \in [1,…,L_{ij}])$，则加1。 如果与第$i$个优化器，第$j$个$PF$ 满足 ： $A_{ij} \ \vartheta_w \ A_{rs} $，再加1。 因此，最大值为 $F_r(L_{ij}L_{rs}+1)$。 至此三种indicator已介绍完毕。 再分析当初说的五个特点，探究是否满足： Monotonicity/compatibility(单调性/兼容性)：对于两个PFs的支配关系，度量标准应该满足单调性/兼容性。如果A支配B，通过度量标准得出的结果，A就应该比B好或至少不能差于B，这个概念可应用与两个PF之间，但并不能应用于M-ary度量标准，M-ary它是和很多个PFs进行比较的而不是仅仅和另一个PF比较。如果$A$与$\{ B_1,B_2,…B_m\}$进行比较，这是不可能的说A的分数和$B_i’s$的总分数有什么样的关系，尤其在$A$支配一些$B_i’s$ 或/和 $A$被一些$B_i’s$支配 或/和 $A$和一些/全部$B_i’s$交叉。在一些特殊的情况，比如当$A$支配所有的$B_i’s$时，$A$相对于与其他的所有$B_i’s$比较时，一定比任何$B_i$分数高。另一方面，当仅仅比较两个PFs时来作为简化的例子，M-ary度量标准遵守单调/兼容性，只要一个PF支配另一个PF而不是部分PF。 Transitivity(传递性)：就像刚刚谈及Monotonicity时解释的一样，当前的概念并不适用于M-ary度量指标。在对某些PFs进行成对比较简化的情况下，在提出的基于基数的M-ary度量中，并不能保证传递性。例如$\sigma(A,B) &gt; \sigma(B,A) \ and \ \sigma(B,C) &gt; \sigma(C,B)$并不能得出$\sigma(A,C) &gt; \sigma(C,A)$。正如Knowlesand Corne所观察到的，直接的比较指标往往会在被比较的不同PFs之间产生这种不可传递关系。这种情况在Noilublao and Bureerat被称为“剪刀-纸-石头”的情况。 Scaling/meaningfulness(缩放性/有意义性)：所提出的度量标准是基于解决方案之间不同形式的优势关系设计的。由于两个解之间的优势关系是基于它们在目标空间中的相对位置，所以这些关系不会因为它们的双射值的缩放而改变(例如在给定范围内的单调变换)。因此，所提出的度量是缩放不变的。 Computational effort(计算工作量)：因为一个优化器的PF与其它优化器相比,提出的每一个最糟糕的复杂性度量是$O(dFL^2)$,d是目标的数量,F是PFs的数量与一个给定的PF相比,和L的最大尺寸是比较PFs。 Additional information(附加信息)：除了比较优化器的PFs之外，所提出的度量中不需要其他信息。 实例讨论这些测试首先在一组基准实例上进行，这些基准实例包含不同共拓扑的PFs，并且知道PFs之间的确切关系。最后。这些指标应用于另一组实例，并与三个已知指标的结果进行比较。在这个集合中，每个优化器都涉及从多次运行中获得的多个PF，并且不知道PFs之间的确切关系。 izarraga等人提出了8个测试用例来评估指标的性能。测试用例是这样构造的:考虑的PFs之间的确切关系是已知的。每个测试用例包含五个PFs (A, B, C, D和E),除了第六测试此用例只包含两个PFs (A和B)。三维版本中也是如此创建的模式和关系,每个测试用例的PFs是类似的。 假设每一个优化器只有一个PF，并且也已知与其他优化器的PFs的关系如何。 a：此测试样例是关于PFs收敛性分析，$AO_cB; BO_cC;CO_cD;DO_cE$，除此之外，所有的PFs都有相同数量的解集，多样性，延展性。 b：此测试样例是关于收敛性与多样性分析，$AO_cB,C; B,CO_cD,E$。$B$与$C$，$D$与$E$之间没有任何关系。所有的PFs有相同数量的解集，相同的多样性，但不同的延展性。 c：此测试样例中，所有的PFs有相同数量的解集，相同的收敛性，但是每一个PF都有一个洞，每个洞的大小不一。 d：此测试样例仅关于多样性。所有PFs有相同的收敛性和延展性但多样性不同。A是一致性分布，剩余的PFs都添加了一致性噪音(uniform noise)，但并没有影响其收敛性与延展性。 e：此测试样例用来独立评估收敛性和多样性的用例。A有三个均匀分布的解。B是通过给A添加一个新的非支配解来构造的，C是通过给B添加一个新的非支配解来构造的，以此类推，从而得到$EO_wDO_wCO_wBO_wA$。PFs也是这样构造的，E相对于D有一个更好的多样性，D相对于C有一个更好的多样性，依此类推。 f：此测试样例用于检测是否受到PF的凸性影响，所考虑的PFs具有相同的收敛性、多样性、扩散性和solu离子个数，但它们具有不同的凸性。 g：此测试样例是检查一个度量是否受到PF位置的影响，所有设计的PFs都具有相同的收敛性、多样性、扩张性和解的个数，但是它们都位于POF的不同位置。 h：最后一个测试样例被设计来研究具有多个解决方案的度量的行为。所考虑的五种PFs具有相同的收敛性、相同的扩散性和均匀的多样性，但解的个数不同。 最终实验结果如下： 请注意，测试用例5、7和8的PFs(图2(e)、g)和(h)由于以下原因不能正确区分。在测试用例5中，通过向A添加一个新的非支配解来构造B，通过向B添加一个新的非支配解来构造C，以此类推。因此，A完全被B重叠，B完全被C重叠，以此类推。因此使PFs不可区分。同样的，由于测试用例8的PFs具有相同的收敛性、相同的发散性和一致的多样性，所以它们之间是重叠的。另一方面，虽然测试用例7的每个PF在一个唯一的位置上都有一个曲线的模式，但是由于PF中有大量的高密度的解，所以PFs的指示符号并不能被清晰地识别出来。 论文中也介绍了一个optimizer with multiple PFs的情况。 但是实在不想翻译了。。。。。累死人 Purity原文： 其中的rank one可难倒我了，以为要看前文才能理解，结果看完了还是不懂，直到我查阅材料时发现以下这段话： an iterative ranking procedure: First all non-dominated individuals are assigned rank one and temporarily removed from the population. Then, the next nondominated individuals are assigned rank two and so forth. Finally, the rank of an individual determines its fitness value. 我才恍然大悟，原文里说的是$r_i$be the number of rank one solutions obtained from each MOO strategy.注意是solutions而不是nondominated solutions ，所以就会分等级制度，rank one、rank two。。。具体分法那段话就是步骤。 规定： 有N个MOO策略，$\{R^1_1,…R_1^N\} \ N &gt; 2$ ，下标是rank，上标是第几个策略。 $r_i$ 是第i个策略 $R_i$的等级1(rank one)的个数。 $R^* = \bigcup^N_{i=1}\{R^i_1\}$ 是所有集合的等级1集合的并集。 $r_i^*=|\{\gamma| \gamma \in R_1^i and \ \gamma \in R_1^*\}|$ 是在$R^i_1$与$R^*$的交集。 表达式为： P_i = \frac{r_i^*}{r_i}, i = 1,2,...,N该值是在[0,1]区间，并且越接近1越有良好的性能，纯度越高。 现在想想纯度的的命名还是很形象的。 Wave metric这个度量标准允许我们从这个解集中提取的以帕累托边界的个数来计算解集的深度。我们应该说“pareto layers”，但是下面的算法解释了为什么“pareto frontier”更适合这种情况。Wave metric只能应用于有限尺寸的解集。要计算wave，通常是这样进行的： set i=1 compute the Pareto frontier using solutions set points. Remove Pareto frontier points from the solutions set if the result set is empty, Wave = i else i = i + 1 and go to step 2 一个好的方法必须产生低wave的结果集。当wave = 1时，解集中的所有解都属于帕累托边界。在下图中，我们可以看到波度规在一个简单集合上的结果。对于这个集合，wave = 4： 实际上，我们可以从这个集合中提取4个帕累托边界。 wave metric有两个严重的缺点:它不能在两个解集之间进行区分，而且不可能在两个不同的解集上比较波度量计算的相同结果。 例如,如果我们计算解决方案上图的wave metric，,我们有wave = 4因为我们可以从这个集合中提取四个帕累托前沿。如果我们再加10分的Pareto frontier和计算wave metric,度量的值还是一样的。所以这个度规不能在这两个集合之间进行区分。第二，如果我们没有任何关于解集的先验信息，我们就不能说4是好是坏。 Dominance-based quality（有时间再说）Dominance ranking(太长了再说)Pareto dominance indicator(有时间再说)总结然而，所有dominance-based QIs都有一些弱点。它们提供的信息很少，不知道一组在多大程度上优于另一组。更重要的是，如果集的所有解互不支配，它们可能会使解集变得不可比较，这在多目标优化中经常发生。此外，值得注意的是，一些dominance-based QIs可能部分表示着解集的基数(cardinality)，因为一组尺寸大一点的解可能会导致更多的非支配解。]]></content>
      <categories>
        <category>indicators</category>
      </categories>
      <tags>
        <tag>MOEA</tag>
        <tag>indicator</tag>
        <tag>ConvergenceQI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[毕设]]></title>
    <url>%2F2019%2F01%2F12%2Findicator%2F</url>
    <content type="text"><![CDATA[放假回家了也要准备准备我的毕业设计，题目是《基于自适应的indicators的多目标优化算法》，如题古老的多目标优化的题目，首先当然是要先了解了解indicators，老师就把他最近写好的关于indicators的综述发给了我，真可谓综述啊！足足100个indicators，路漫漫。。。。。 概念介绍以下是解与解、集合与集合之间的关系： 把解与解的总结到表格里： 一般来说，解集的质量可以解释为它如何很好地表示帕累托前沿，可以分为四个方面:收敛性(convergence)、扩散性(spread)、一致性(uniformity)和基数性(cardinality)。 解集的收敛性(convergence)是指解集与帕累托前缘的距离。解集的扩展考虑集覆盖的区域。它涉及到集合的外部和内部部分。这不同于只考虑集合的边界的质量的广泛性(extensity)。注意，在存在问题帕累托前沿的情况下，解集的扩展也称为集的覆盖(coverage)。集的均匀性(uniformity)是指解分布在集中的均匀程度;解决方案之间的等距间距是所希望的。传播和均匀性是密切相关的,他们共同被称为一组的多样性(diversity)。解集的基数(cardinality)是指解决方案集的数量。总的来说,我们的期望足够的解决方案明确地描述集,但不是太多,可能会损害DM与选择。然而，如果使用相同数量的计算资源生成两个集，则认为具有更多解决方案的集是首选的。 比较解决方案集的质量的一种直接方法是将这些集可视化，并直观地判断一个集相对于另一个集的优越性。这种目视比较是最常用的方法之一，非常适用于双目标拖把或三目标拖把。当目标个数大于3时，解决方案集的直接观察不可用时(散点图),人们可能会求助于从数据分析领域的工具。然而，这些可视化方法可能无法清晰地反映解决方案集质量的所有方面;例如，常用的平行坐标只能部分反映收敛性、扩散性和均匀性。此外，可视化比较不能量化解决方案集之间的差异，因此不能用于指导最优化。 质量指标(Quality indicators, QIs)通过将解决方案集映射为实数来克服可视化比较的问题，从而提供解决方案集之间的数量差异。QIs能够提供解决方案集质量的精确表述，例如，在这些表述中，一个集的质量优于另一个集，以及一个集在某些方面比另一个集好多少。原则上，将一组向量映射成标量值的任何函数都可以看作是一个潜在的质量指示器，但通常它可能需要反映集合质量的一个或多个方面:收敛性、扩展性、一致性和基数性。注意，当比较由精确方法生成的解集时，由于生成的解集是问题的帕累托前沿的子集，所以不考虑解集的收敛性评价。 本节根据Qls主要捕获的质量方面来审查Qls。一般来说，QIs可分为六类:1)QIs用于收敛，2)QIs用于扩展，3)QIs用于均匀性，1)QIs用于基数性，5)QIs用于扩展和均匀性，6)Qls用于四个质量方面的组合质量。在每个类别中，我们还详细介绍了一个或几个示例指示器。这些QIs通常在文献中使用，并且/或在它们的类别中具有代表性。表2总结了所有100篇文献。请注意，它不包括由多个QIs组合而成的度量。 当当当！！！这是论文中总结的100个indicators！！WTF！！！老师让了解了解的时候我是崩溃的。我慢慢来… 加黑加粗的是我已经整理好的~ 安排： QIs for Convergence Dominance-based QIs Dominance-based QIs QIs for Spread]]></content>
      <categories>
        <category>indicators</category>
      </categories>
      <tags>
        <tag>MOEA</tag>
        <tag>indicators</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[matlab]]></title>
    <url>%2F2019%2F01%2F02%2Fmatlab%2F</url>
    <content type="text"><![CDATA[此文会持续更新，记录一些在matlab中的一些常用函数。 repmat123456&gt;&gt; a = [1 2 3];&gt;&gt; repmat(a,2,3) %把矩阵整体堆叠成新矩阵ans = 1 2 3 1 2 3 1 2 3 1 2 3 1 2 3 1 2 3 sort12345678910&gt;&gt; a = [6 3 2 1 4 5];&gt;&gt; [~,ans] = sort(a) % 默认从小到大的索引值ans = 4 3 2 5 6 1&gt;&gt; a(ans)ans = 1 2 3 4 5 6 尺寸扩展12345678&gt;&gt; a = ones(3);&gt;&gt; a(1,(4:5)) = 10a = 1 1 1 10 10 1 1 1 0 0 1 1 1 0 0]]></content>
      <categories>
        <category>matlab</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>matlab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MOEA/D算法(三)]]></title>
    <url>%2F2019%2F01%2F02%2Fmoead3%2F</url>
    <content type="text"><![CDATA[“MOEA/D: A Multiobjective Evolutionary Algorithm Based on Decomposition”第三部分，论文中一些具体的细节。 测试函数以下为具体函数，和所给定的前端解 ZDT1 f_1(1)=x_1 \\f_2=g(x)[1-\sqrt{\frac{f_1(x)}{g(x)}}] \\where \quad g(x)=1 + \frac{9(\sum_{i=2}^{n}{x_i})}{n-1} \\x=(x_1,...x_n) ，x_1\in [0,1]^n,n=30 ZDT2 f_1(x) = x_1 \\f_2=g(x)[1-(\frac{f_1(x)}{g(x)})^2] \\where \quad g(x)=1 + \frac{9(\sum_{i=2}^{n}{x_i)}}{n-1} \\x=(x_1,...x_n) ，x_1\in [0,1]^n,n=30 ZDT3 f_1(x) = x_1 \\f_2=g(x)[1-\sqrt{\frac{f_1(x)}{g(x)}}-\frac{f_1(x)}{g(x)}sin(10\pi x_1)] \\where \quad g(x)=1 + \frac{9(\sum_{i=2}^{n}{x_i)}}{n-1} \\x=(x_1,...x_n) ，x_1\in [0,1]^n,n=30 ZDT4 f_1(x) = x_1 \\f_2=g(x)[1-\sqrt{\frac{f_1(x)}{g(x)}}] \\where\quad g(x)=1 + 10(n-1)+\sum_{i=2}^{n}[x_i^2-10cos(4\pi x_i)] \\x=(x_1,...x_n) ，x_1\in [0,1] \times [-5,5]^{n-1},n=10 ZDT6 f_1(x)=1-exp(-4x_1)sin^6(6\pi x_1) \\f_2=g(x)[1-(\frac{f_1(x)}{g(x)})^2] \\g(x)=1 + 9[\frac{\sum_{i=2}^{n}{x_i}}{n-1}]^{0.25} \\x=(x_1,...x_n) ，x_1\in [0,1]^n,n=10 DTLZ1 f_1(x)=(1+g(x))x_1x_2 \\f_2(x)=(1+g(x))x_1(1-x_2) \\f_3(x)=(1+g(x))(1-x_1) \\where\quad g(x)=100(n-2)+100\sum_{i=3}^{n}{\{(x_i-0.5)^2-cos[20\pi (x_i-0.5)]\}} \\x=(x_1,...,x_n)^T \in [0,1]^n,n=10The function value of a Pareto optimal solution satisfies$\sum_{i=1}^{3}{f_i}=1,f_i \geq0$ DTLZ2 f_1(x)=(1+g(x))cos(\frac{x_1\pi}{2})cos(\frac{x_2\pi}{2}) \\f_2(x)=(1+g(x))cos(\frac{x_1\pi}{2})sin(\frac{x_2\pi}{2}) \\f_3(x)=(1+g(x))sin(\frac{x_1\pi}{2}) \\where\quad g(x)=\sum_{i=3}^{n}{x_i^2}, \\x=(x_1,...x_n)^T\in [0,1]^2\times [-1,1]^{n-2},n=10The function value of a Pareto optimal solution satisfies$\sum_{i=1}^{3}{f_i}^2=1,f_i \geq0$ 基本参数设置12345678910N=300;%种群大小T=20;%邻居规模大小max_gen=250;%进化代数pc=1;%交叉概率pm=1/x_num;%变异概率fun='DTLZ2';%有 ZDT1 ZDT2 ZDT3 ZDT4 ZDT6 DTLZ1 DTLZ2yita1=2;%模拟二进制交叉参数2yita2=5;%多项式变异参数5x_num = ;%根据以上每一个函数的定义f_num = ;%根据以上每一个函数的定义 权值向量初始化1234567891011121314151617181920212223242526272829303132function lamda = genrate_lamda( N,f_num )%产生初始化向量lamdalamda2=zeros(N+1,f_num);%初始化if f_num==2 array=(0:N)/N;%均匀分布的值 for i=1:N+1 lamda2(i,1)=array(i); lamda2(i,2)=1-array(i); end len = size(lamda2,1); index = randperm(len); index = sort(index(1:N)); lamda = lamda2(index,:);elseif f_num==3 k = 1; array = (0:25)/25;%产生均匀分布的值 for i=1:26 for j = 1:26 if i+j&lt;28 lamda3(k,1) = array(i); lamda3(k,2) = array(j); lamda3(k,3) = array(28-i-j); k=k+1; end end end len = size(lamda3,1); index = randperm(len); index = sort(index(1:N)); lamda = lamda3(index,:);endend 建立权值向量的邻域1B=look_neighbor(lamda,T); 其中look_neighbor.m为： 12345678910111213141516function B = look_neighbor( lamda,T )%计算任意两个权重向量间的欧式距离N =size(lamda,1);B=zeros(N,T);distance=zeros(N,N);for i=1:N for j=1:N l=lamda(i,:)-lamda(j,:); distance(i,j)=sqrt(l*l'); endend%查找每个权向量最近的T个权重向量的索引for i=1:N [~,index]=sort(distance(i,:)); B(i,:)=index(1:T);end 种群初始化1234567function X = initialize( N,f_num,x_num,x_min,x_max,fun )% 种群初始化X = repmat(x_min,N,1)+rand(N,x_num).*repmat(x_max-x_min,N,1); for i=1:N X(i,(x_num+1:(x_num+f_num))) = object_fun(X(i,:),f_num,x_num,fun); X(i,(x_num+f_num+1)) = 0;end 其中object_fun.m: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485function f = object_fun( x,f_num,x_num,fun )% 测试函数的设置%--------------------ZDT1--------------------if strcmp(fun,'ZDT1') f=[]; f(1)=x(1); sum=0; for i=2:x_num sum = sum+x(i); end g=1+9*(sum/(x_num-1)); f(2)=g*(1-(f(1)/g)^0.5);end%--------------------ZDT2--------------------if strcmp(fun,'ZDT2') f=[]; f(1)=x(1); sum=0; for i=2:x_num sum = sum+x(i); end g=1+9*(sum/(x_num-1)); f(2)=g*(1-(f(1)/g)^2);end%--------------------ZDT3--------------------if strcmp(fun,'ZDT3') f=[]; f(1)=x(1); sum=0; for i=2:x_num sum = sum+x(i); end g=1+9*(sum/(x_num-1)); f(2)=g*(1-(f(1)/g)^0.5-(f(1)/g)*sin(10*pi*f(1)));end%--------------------ZDT4--------------------if strcmp(fun,'ZDT4') f=[]; f(1)=x(1); sum=0; for i=2:x_num sum = sum+(x(i)^2-10*cos(4*pi*x(i))); end g=1+9*10+sum; f(2)=g*(1-(f(1)/g)^0.5);end%--------------------ZDT6--------------------if strcmp(fun,'ZDT6') f=[]; f(1)=1-(exp(-4*x(1)))*((sin(6*pi*x(1)))^6); sum=0; for i=2:x_num sum = sum+x(i); end g=1+9*((sum/(x_num-1))^0.25); f(2)=g*(1-(f(1)/g)^2);end%--------------------------------------------%--------------------DTLZ1-------------------if strcmp(fun,'DTLZ1') f=[]; sum=0; for i=3:x_num sum = sum+((x(i)-0.5)^2-cos(20*pi*(x(i)-0.5))); end g=100*(x_num-2)+100*sum; f(1)=(1+g)*x(1)*x(2); f(2)=(1+g)*x(1)*(1-x(2)); f(3)=(1+g)*(1-x(1));end%--------------------------------------------%--------------------DTLZ2-------------------if strcmp(fun,'DTLZ2') f=[]; sum=0; for i=3:x_num sum = sum+(x(i))^2; end g=sum; f(1)=(1+g)*cos(x(1)*pi*0.5)*cos(x(2)*pi*0.5); f(2)=(1+g)*cos(x(1)*pi*0.5)*sin(x(2)*pi*0.5); f(3)=(1+g)*sin(x(1)*pi*0.5);end%--------------------------------------------end 交叉变异操作模拟二进制交叉(SBX)for j = 1.....x_num x'_{1j}(t)=0.5\times[(1+\lambda_j)x_{1j}+(1-\lambda_j)x_{2j}(t)] \\x'_{2j}(t)=0.5\times[(1-\lambda_j)x_{1j}+(1+\lambda_j)x_{2j}(t)]其中： \lambda_j=\begin{cases} (2u_i)^{\frac{1}{\eta+1}}, & u_j < 0.5\\ \frac{1}{2(1-u_i)}^{\frac{1}{\eta+1}}, & other \end{cases}随机$u_j$，使$0 \leq u_j \leq 1$. endfor 多项式变异for j = 1.....x_num x_{1j}(t)=x_{1j}(t) + \Delta_j其中： \Delta_j=\begin{cases} (2u_i)^{\frac{1}{\eta+1}}-1, & u_j < 0.5\\ 1-(2(1-u_i))^{\frac{1}{\eta+1}}, & other \end{cases}随机$u_j$，使$0 \leq u_j \leq 1$. endfor 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273function chromo_offspring = cross_mutation( chromo_parent_1,chromo_parent_2,f_num,x_num,x_min,x_max,pc,pm,yita1,yita2,fun )%模拟二进制交叉与多项式变异%%%模拟二进制交叉if(rand(1)&lt;pc) %初始化子代种群 off_1=zeros(1,x_num+f_num); %进行模拟二进制交叉 u1=zeros(1,x_num); gama=zeros(1,x_num); for ind=1:x_num u1(ind)=rand(1); if u1(ind)&lt;=0.5 gama(ind)=(2*u1(ind))^(1/(yita1+1)); else gama(ind)=(1/(2*(1-u1(ind))))^(1/(yita1+1)); end off_1(ind)=0.5*((1-gama(ind))*chromo_parent_1(ind)+(1+gama(ind))*chromo_parent_2(ind)); %使子代在定义域内 if(off_1(ind)&gt;x_max(ind)) off_1(ind)=x_max(ind); elseif(off_1(ind)&lt;x_min(ind)) off_1(ind)=x_min(ind); end end %计算子代个体的目标函数值 off_1(1,(x_num+1):(x_num+f_num))=object_fun(off_1,f_num,x_num,fun);end% %%%多项式变异 注释这种方法为上方公式代码，但在ZDT4，DTLZ1中效果不好，% if(rand(1)&lt;pm) 因此换成下方代码，效果甚好！% u2=zeros(1,x_num);% delta=zeros(1,x_num);% for j=1:x_num% u2(j)=rand(1);% if(u2(j)&lt;0.5)% delta(j)=(2*u2(j))^(1/(yita2+1))-1;% else% delta(j)=1-(2*(1-u2(j)))^(1/(yita2+1));% end% off_1(j)=off_1(j)+delta(j);% %使子代在定义域内% if(off_1(j)&gt;x_max(j))% off_1(j)=x_max(j);% elseif(off_1(j)&lt;x_min(j))% off_1(j)=x_min(j);% end% end% %计算子代个体的目标函数值% off_1(1,(x_num+1):(x_num+f_num))=object_fun(off_1,f_num,x_num,fun);% end% chromo_offspring=off_1;% end%%%多项式变异 具体改变：一次变异只改变一个位置，并不是像之前那样都要变异if(rand &lt; pm) r=randperm(x_num); ind=r(1); u2=rand; if(u2 &lt; 0.5) delta=(2*u2)^(1/(yita2+1))-1; else delta=1-(2*(1-u2))^(1/(yita2+1)); end off_1(ind)=off_1(ind)+delta*(x_max(ind)-x_min(ind)); %使子代在定义域内 if(off_1(ind)&gt;x_max(ind)) off_1(ind)=x_max(ind); elseif(off_1(ind)&lt;x_min(ind)) off_1(ind)=x_min(ind); end %计算子代个体的目标函数值 off_1(1,(x_num+1):(x_num+f_num))=object_fun(off_1,f_num,x_num,fun);endchromo_offspring=off_1;end 更新领域解1X=updateNeighbor(lamda,z,X,B(i,:),off,x_num,f_num); 其中updateNeighbor.m： 1234567891011function X = updateNeighbor( lamda,z,X,Bi,off,x_num,f_num )%更新领域解for i=1:length(Bi) gte_xi=tchebycheff_approach(lamda,z,X(Bi(i),(x_num+1):(x_num+f_num)),Bi(i)); gte_off=tchebycheff_approach(lamda,z,off(:,(x_num+1):(x_num+f_num)),Bi(i));% gte_xi=ws_approach(lamda,X(Bi(i),(x_num+1):(x_num+f_num)),Bi(i));% gte_off=ws_approach(lamda,off(:,(x_num+1):(x_num+f_num)),Bi(i)); if gte_off &lt;= gte_xi X(Bi(i),:)=off; endend 其中tchebycheff_approach.m： 123456789function fs = tchebycheff_approach( lamda,z,f,i)%tchebycheff_approachfor j=1:length(lamda(i,:)) if(lamda(i,j)==0) lamda(i,j)=0.00001; endendfs=max(lamda(i,:).*abs(f-z));end 评价指标C-metric令 A和 B是一个 MOP中两个接近PF的集合，定义 C(A,B)如： C(A,B)=\frac{\{u\in B|\exists v\in A:v\quad dominates\quad u\}}{|B|}C(A,B)不等于 1-C(B,A)。C(A,B)=1意味着 B中所有的解都被 A中的某些解支配了， C(A,B)=0意味着 B中没有解被 A中的解支配。 1234567891011121314151617181920212223242526function C_AB = cal_c(A,B,f_num)[temp_A,~]=size(A);[temp_B,~]=size(B);number=0;for i=1:temp_B nn=0; for j=1:temp_A less=0;%当前个体的目标函数值小于多少个体的数目 equal=0;%当前个体的目标函数值等于多少个体的数目 for k=1:f_num if(B(i,k)&lt;A(j,k)) less=less+1; elseif(B(i,k)==A(j,k)) equal=equal+1; end end if(less==0 &amp;&amp; equal~=f_num) nn=nn+1;%被支配个体数目n+1 end end if(nn~=0) number=number+1; endendC_AB=number/temp_B;end D-metric令 $P^*$为一组均匀分布在 PF上的点集合。 A是一个接近 PF的集合。 的集合。 $P^*$到 A的平均距离定义为： D(A,P)=\frac{\sum_{v\in P^*}d(v,A)}{|P^*|}这里 $𝑑(𝑣,𝐴)$是v和A中的点最小欧式距离。如果 $P^*$足够大,说明其可以很好的代表PF。$D(A,P^*)$可以从某种意义上评估A的收敛性和多样。为了让$D(A,P^*)$的值很低，必须设置 A非常接近PF，并且不能缺失整个PF的任何部分。 12345678910function D_AP = cal_d(A,P)[temp_A,~]=size(A);[temp_P,~]=size(P);min_d=0;for v=1:temp_P d_va=(A-repmat(P(v,:),temp_A,1)).^2; min_d=min_d+min(sqrt(sum(d_va,2)));endD_AP=(min_d/temp_P);end ‘]]></content>
      <categories>
        <category>MOEA</category>
      </categories>
      <tags>
        <tag>MOEA</tag>
        <tag>MOEA\D</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MOEA/D算法(二)]]></title>
    <url>%2F2019%2F01%2F01%2Fmoead2%2F</url>
    <content type="text"><![CDATA[“MOEA/D: A Multiobjective Evolutionary Algorithm Based on Decomposition”第二部分，算法的流程框架。 规定本文提出的基于分解的多目标进化算法(MOEA/D)需要对MOPs进行分解。任何分解方法都可以达到这个目的。在下面的描述中，我们假设使用了Tchebycheff方法。在使用其他分解方法时，修改下面的MOEA/D也非常简单。 $\lambda^1​$,…$\lambda^N​$ 是均匀分布的权值向量 $z^*$ 是reference point 选用Tchebycheff Approach把多目标问题拆成N个标量优化子问题，表达式如下: g^{te}(x|\lambda^j,z^*)=\max\limits_{1\leq i \leq m}\{\lambda_i^j|f_i(x)-z_i^*|\} 其中 $\lambda ^j=(\lambda_1^j,…\lambda_m^j)^T$. $\lambda=(\lambda^1,…,\lambda^N)$ 可知$g^{te}$是关于$\lambda$连续的，当$\lambda^i$与$\lambda^j$彼此接近，那么接近$\lambda ^i$向量的$g^{te}$权向量的信息也对最优解$g^{te}(x|\lambda^j,z^*)$有一定的作用。这也是MOEA/D的理论基础。 在MOEA/D中，权向量的邻域被定义为它的几个最近的权向量的集合。第$i$个子问题的邻域由所有的子问题组成，这些子问题的权向量来自于第$i$个子问题的邻域。在MOEA/D中，只有相邻子问题的当前解被用来优化子问题。 切比雪夫法的MOEA/D算法中，有以下规定： $x^1,…x^N \in \Omega$ $x^i$是当前的第i个子问题 $FV^1,…,FV^N$ ，其中 $FV^i = F(x^i)$ $ x \in [1,N]$ $z=(z_1,…z_m)^T $ ，$z_i$ 是目前对目标$f_i$所找到的最好的点。 Input MOP(1) 一个终止准则 N：子问题的个数 N 个均匀分布的权值向量$\lambda_1,…\lambda_N$ T 每一个权值向量的邻居的数量Output: EP STEP 1) Initialization:Step 1.1) 使EP为空集 Step 1.2) 计算任意两个权值向量间的欧式距离，并找到离每个权值距离最近的T个点 ​ $B(i)=\{i_i,…i_T\}$ ，其中，$\lambda^{i_1},…\lambda^{i_T}$就是T个最近的权值向量 Step 1.3) 随机产生初始化种群 $x^1,…,x^N$ ，规定$FV^i=F(x^i).$ Step 1.4) 初始化 $z=(z_1,…z_m)^T $ STEP 2) Update:for i=1,…N Step 2.1) 复制 ：从$B(i)$随机产生两个索引$k,l$ ，然后通过遗传算子从$x_k,x_l$ 中产生新的子代$y$ Step 2.2) 提升 ：通过提升或者修理来启发式的由$y$产生$y’$ Step 2.3) 更新$z$：if $z_j &lt; f_j(y’)$ then $z_j = f_j(y’)$ Step 2.4) 更新相邻解：对于$j \in B(i)$,if $g^{te}(y’|\lambda^j,z)\leq g^{te}(x^j|\lambda^j,z)$ then $x^j=y’, FV^j=F(y’)$ Step 2.5) 更新EP：​ — 从 EP中移除被 $F(y’)$支配的所有向量​ — 如果 EP中没有向量支配 $F(y’)$，就将 F(y’)加入到EP中 STEP 3) Stopping Criteria 如果停止准则满足，并输出EP。否则，转向 STEP 2)。]]></content>
      <categories>
        <category>MOEA</category>
      </categories>
      <tags>
        <tag>MOEA</tag>
        <tag>MOEA\D</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MOEA/D算法(一)]]></title>
    <url>%2F2018%2F12%2F31%2Fmoead1%2F</url>
    <content type="text"><![CDATA[最近在复现“MOEA/D: A Multiobjective Evolutionary Algorithm Based on Decomposition”这篇论文，但多目标优化门都没入，所以作为复现的第一篇MOEA算法，我要趁此好好肢解这篇论文，尽量理解。 在Weighted Sum Approach表达式为： min\quad g^{ws}(x|\lambda)=\sum_{i=0}^{m}\lambda_if_i(x)m：m个优化目标， $\sum_{i=1}^{m}\lambda_i = 1$ $\lambda​$ 被称为权重向量。 通过公式，把算法求出的一个目标点和原点相连构造成一个向量与对应权重向量点乘，由向量点乘的几何意义可知，所得的数为该向量在权重向量方向上的投影长度，因为权重向量不变，最大/小化该长度值其实就是在优化该向量。可知若要增大该向量在权重向量上投影的长度，一方面可以增大/减小与权重向量的夹角，另一方面可以增大/减小该向量的长度。样例图如下： 红色权重向量，因为是最小化问题，所以减小长度，增大夹角都是可行的方案，绿色为等高线，垂直于权重向量。阴影部分为所有解，因此，在每一个绿色的等高线上找角度最大的即为边界。 Tchebycheff Approach表达式为： minimize\quad g^{te}(x|\lambda,z^*)=\max \limits_{1\leq i \leq m}\{\lambda_i|f_i(x)-z^*|\}注意该方法中不再含有$\sum$符号，故不能再从向量点乘的角度理解。该方法大致思想是减少最大差距从而将个体逼近PF。 首先解释等高线为什么是这样的。单看$f_1$函数，即只考虑纵坐标，若两点等值，必然是$\lambda_i|f_i(x)-z^*|$式中$f_1$的函数值相等（因为另外两个量是不变的），即纵坐标相等，所以$f_1$函数的等高线是一组平行于横轴的直线。$f_2$类似，为一组平行于纵轴的直线。第一次相比较的是m个维度中最大的$max ( \lambda _1(y-z_1),\lambda _2(x-z_2))$，所以等高线便是一个点之内各个维度的比较。那么，图中的等高线是横竖相交且刚好交在权重向量的方向上的，证明：可知，对于任何一个可行的解，我们从$f_1$的角度上可以得到一个$f_1$的值y，从$f_2$的角度上可以得到一个$f_2$ 的值x，他们的切比雪夫值是相等的，自然想到：点(x,y)（图中紫色点）为该切比雪夫值得横纵两条等值线的交点，那么有：$\lambda _1(y-z_1)=\lambda_2(x-z_2)$，化简的$(y-z_1)/(x-z_2)=\lambda_2/\lambda_1$，可知该交点位于权重向量的方向上。需要注意一点，这里的权重向量起点是$z^*$，不再是原点。此时可知，若某个个体位于其($\lambda -z^*$)向量方向的上部，则max得到的一定是其$f_1$部分，故优化也需要减小其$f_1$的值，即个体向下移动，相反，若在($\lambda -z^*$)向量方向的下部，则应像左移动。以此来保证个体目标值落在黄点附近。 一种可能的个体运动路线如下图，橘色—&gt;黄色所示： Boundary IntersectionApproach表达式为： minimize\quad g^{bi}(x|\lambda,z^*)=d \\subject\quad to\quad z^*-F(x)=d\lambda \\x \in \Omega参数含义如下如所示： 式子中等式约束其目的是为了保证F(x)位于权重向量λ的方向上，通过减小d来使算法求出的解逼近PF。但该条件不太容易实现，故将其改进为下边这种方法。 Penalty-based Boundary Intersection Approach minimize\quad g^{bip}(x|\lambda,z^*)=d_1 + \theta d_2 \\subject \quad to \quad x \in \Omega \\where \quad \quad d_1 =\frac{||(z_*-F(x))^T\lambda||}{||\lambda||} \\and \quad d_2 = ||F(x)-(z^*-d_1\lambda)||参数含义如下如所示： 可知算法放宽了对算法求出的解得要求，但加入了一个惩罚措施：你可以不把解生成在权重向量的方向上，但如果不在权重向量方向上，你就必须要接收惩罚，你距离权重向量越远，受的惩罚越厉害，以此来约束算法向权重向量的方向生成解。 接下来是关于$d_1$和$d_2$两个参数的计算表达式的含义说明，我依然是从几何角度理解的。 $d_1$——观察$d_1$的计算表达式，$Z^*-F(x)$可以看做原点到$Z^*$点的向量减去原点到$F(x)$的向量，得到的是从$F(x)$出发指向$Z^*$的一个向量，暂且命名为$\mu$，之后$\mu$与$\lambda$相乘得到$\mu$在方向上的投影，这$\lambda$个长度值与λ的长度值之比为$d_1$。$d_2$——其表达式的含义其实也无非就是利用向量运算构造出$d_2$所表示的向量，取模即可得到$d_2$.构造过程如下： $Z^*$表红色向量，$d_1\lambda$表蓝色向量（因为减法，所以方向取反），红色减蓝色得紫色向量，$F(x)$表绿色向量，绿色减紫色得黄色向量，即$d_2$表黄色向量的长度 引自]]></content>
      <categories>
        <category>MOEA</category>
      </categories>
      <tags>
        <tag>MOEA</tag>
        <tag>MOEA\D</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MOEA/D算法(0)]]></title>
    <url>%2F2018%2F12%2F30%2Fmoead0%2F</url>
    <content type="text"><![CDATA[最近在复现“MOEA/D: A Multiobjective Evolutionary Algorithm Based on Decomposition”这篇论文这是一个后补上的文章，几乎是翻译的原论文呢】，因为课程设计凑字数，也为了省事，就干脆发在我的小博客上了。 多目标优化问题可以表示如下： maximize \quad F(x)=(f_1(x),...,f_m(x))^T \\subject \ to \ x \in \Omega其中，$\Omega$是决策空间，$F$：$\Omega \rightarrow R^m$是m个实数目标函数，$R^m$叫做目标空间，可实现的目标定义如下： \Omega=\{x \in R^n|h_j(x)\leq 0,j=1,...,m\}$h_j$是连续的函数，因此，我们也称$F(x)$是连续的MOP问题。 在现实生活中，大多数的目标函数却是相互矛盾的，并不存在$\Omega$可以同时放大所有的目标值。因此需要找相应的方法去平衡这些目标。目标之间的最佳权衡可以用帕累托(Pareto)最优性来定义。 定义$u,v\in R^m$,如果对于$\forall i \in \{1,…,m\}$，使得$u_i\geq v_i$，并且$\exists j \in \{1,…,m\} $，使得$u_i &gt; v_i$，则称$u$支配$v$。如果存在这种点$x^\in \Omega$，不存在点$x$，使$F(x)$支配$F(x^)$，那么称$F(x^*）$为帕累托最优目标向量。换言之，一个目标中帕累托最优点的任何改进都必须导致至少另一个目标的恶化。所有帕累托最优点的集合称为帕累托集合(PS)，所有帕累托最优目标向量的集合称为帕累托阵(PF)。 在多目标优化的许多实际应用中，决策者需要近似于PF来选择最终的首选解决方案。大多数MOPs可能有许多甚至无限帕累托最优向量。获取完整的PF是非常耗时的。另一方面，由于信息的溢出，决策者可能对拥有过多的帕累托最优向量不感兴趣。因此，许多多目标优化算法都是为了找到一个可管理的帕累托最优向量。一些研究者也尝试用数学模型来近似PF。 目前没有涉及到分解的大部分多目标进化算法，将MOP视为一个整体。它们不会将每个单独的解决方案与任何特定的标量优化问题关联起来。在标量目标优化问题，所有的解决方案都可以在它们目标函数值的基础上进行比较，标量目标的任务进化算法(EA)往往是寻找一个单一的最优的解决方案。然而，在MOPs中，支配并非定义目标函数中解的完整顺序空间，MOEAs旨在产生一些帕累托最优尽可能多样化的解决方案来代表整体PF。 因此，最初设计用于标量优化的传统选择算子不能直接用于非分解MOEAs。那么可以说，如果有一种适合度分配方案，用于为单个解决方案分配一个相对适合度值，以反映其选择的实用价值，那么标量优化EAs可以很容易地扩展到处理MOPs。因此，适应度分配一直是当前的一个主要问题MOEA研究。目前流行的适应度分配策略包括基于交互目标的适应度分配，如向量评价遗传算法(VEGA);基于优势的适应度分配，如帕累托存档进化策略（PAES）。 分解的思想在一些针对MOPs的元启发式中得到了一定程度的应用。例如，两阶段局部搜索(TPLS)考虑了一组标量优化问题，其中目标是所考虑的MOP中的目标的集合，基于集合系数的序列将标量优化算法应用于这些标量优化问题中，将前一个问题得到的解作为下一个问题求解的起点，因为它的集合目标与前一个问题的集合目标略有不同。多目标遗传局部搜索(MOGLS)旨在同时优化加权和方法或Tchebycheff方法构建的所有聚合。在每次迭代中，它优化随机生成的聚合目标。]]></content>
      <categories>
        <category>MOEA</category>
      </categories>
      <tags>
        <tag>MOEA</tag>
        <tag>MOEA\D</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vscode配置c环境]]></title>
    <url>%2F2018%2F12%2F22%2Fvscode%E9%85%8D%E7%BD%AEc%2F</url>
    <content type="text"><![CDATA[在sublime和vscode的权衡下，选择了vscode，毕竟之前一直用的是sublime，想换一换了。于是就遇到一个老问题，配环境！ 此内容几乎完全来自于某乎 安装 vscode LLVM 选Pre-Built Binaries中的Clang for Windows (64-bit)，不需要下.sig文件 添加环境变量：Add LLVM to the system PATH for all users 安装路径推荐：C:\LLVM 工具链：MinGW 其他默认 MinGW-w64 - for 32 and 64 bit Windows 链接，提取码：dclo 下好后，把x86_64-7.2.0-posix-seh-rt_v5-rev0.7z\mingw64 中所有的文件都复制到 C:\LLVM中 检验：打开cmd 输入gcc，如果为no input files而不是其他，即为成功。 ​ 输入clang，如果为no input files而不是其他，即为成功。 ​ 插件一定要下： C/C++ C/C++ Clang Command Adapter Code Runner 自由推荐： Bracket Pair Colorizer：彩虹花括号 Include Autocomplete：提供头文件名字的补全 One Dark Pro：VS Code安装量最高的主题 环境配置打开vscode，一定要选 open folder 选择刚才那个文件夹，点VS Code上的新建文件夹，名称为.vscode（这样做的原因是Windows的Explorer不允许创建的文件夹第一个字符是点），然后创建 launch.json，tasks.json，settings.json，c_cpp_properties.json放到.vscode文件夹下 launch.json:12345678910111213141516171819202122232425262728// https://github.com/Microsoft/vscode-cpptools/blob/master/launch.md&#123; &quot;version&quot;: &quot;0.2.0&quot;, &quot;configurations&quot;: [ &#123; &quot;name&quot;: &quot;(gdb) Launch&quot;, // 配置名称，将会在启动配置的下拉菜单中显示 &quot;type&quot;: &quot;cppdbg&quot;, // 配置类型，这里只能为cppdbg &quot;request&quot;: &quot;launch&quot;, // 请求配置类型，可以为launch（启动）或attach（附加） &quot;program&quot;: &quot;$&#123;fileDirname&#125;/$&#123;fileBasenameNoExtension&#125;.exe&quot;, // 将要进行调试的程序的路径 &quot;args&quot;: [], // 程序调试时传递给程序的命令行参数，一般设为空即可 &quot;stopAtEntry&quot;: false, // 设为true时程序将暂停在程序入口处，我一般设置为true &quot;cwd&quot;: &quot;$&#123;workspaceFolder&#125;&quot;, // 调试程序时的工作目录 &quot;environment&quot;: [], // （环境变量？） &quot;externalConsole&quot;: true, // 调试时是否显示控制台窗口，一般设置为true显示控制台 &quot;internalConsoleOptions&quot;: &quot;neverOpen&quot;, // 如果不设为neverOpen，调试时会跳到“调试控制台”选项卡，你应该不需要对gdb手动输命令吧？ &quot;MIMode&quot;: &quot;gdb&quot;, // 指定连接的调试器，可以为gdb或lldb。但目前lldb在windows下没有预编译好的版本。 &quot;miDebuggerPath&quot;: &quot;gdb.exe&quot;, // 调试器路径，Windows下后缀不能省略，Linux下则去掉 &quot;setupCommands&quot;: [ // 用处未知，模板如此 &#123; &quot;description&quot;: &quot;Enable pretty-printing for gdb&quot;, &quot;text&quot;: &quot;-enable-pretty-printing&quot;, &quot;ignoreFailures&quot;: false &#125; ], &quot;preLaunchTask&quot;: &quot;Compile&quot; // 调试会话开始前执行的任务，一般为编译程序。与tasks.json的label相对应 &#125; ]&#125; tasks.json:命令行参数方面，-std根据自己的需要修改。如果使用Clang编写C语言，把command的值改成clang。如果使用MinGW，编译C用gcc，编译c++用g++，并把-target和-fcolor那两条删去。 123456789101112131415161718192021222324252627282930313233// https://code.visualstudio.com/docs/editor/tasks&#123; &quot;version&quot;: &quot;2.0.0&quot;, &quot;tasks&quot;: [ &#123; &quot;label&quot;: &quot;Compile&quot;, // 任务名称，与launch.json的preLaunchTask相对应 &quot;command&quot;: &quot;clang++&quot;, // 要使用的编译器 &quot;args&quot;: [ &quot;$&#123;file&#125;&quot;, &quot;-o&quot;, // 指定输出文件名，不加该参数则默认输出a.exe，Linux下默认a.out &quot;$&#123;fileDirname&#125;/$&#123;fileBasenameNoExtension&#125;.exe&quot;, &quot;-g&quot;, // 生成和调试有关的信息 &quot;-Wall&quot;, // 开启额外警告 &quot;-static-libgcc&quot;, // 静态链接 &quot;-fcolor-diagnostics&quot;, // 彩色的错误信息？但貌似clang默认开启而gcc不接受此参数 &quot;--target=x86_64-w64-mingw&quot;, // clang的默认target为msvc，不加这一条就会找不到头文件；Linux下去掉这一条 &quot;-std=c++17&quot; // C语言最新标准为c11，或根据自己的需要进行修改 ], // 编译命令参数 &quot;type&quot;: &quot;shell&quot;, // 可以为shell或process，前者相当于先打开shell再输入命令，后者是直接运行命令 &quot;group&quot;: &#123; &quot;kind&quot;: &quot;build&quot;, &quot;isDefault&quot;: true // 设为false可做到一个tasks.json配置多个编译指令，需要自己修改本文件，我这里不多提 &#125;, &quot;presentation&quot;: &#123; &quot;echo&quot;: true, &quot;reveal&quot;: &quot;always&quot;, // 在“终端”中显示编译信息的策略，可以为always，silent，never。具体参见VSC的文档 &quot;focus&quot;: false, // 设为true后可以使执行task时焦点聚集在终端，但对编译c和c++来说，设为true没有意义 &quot;panel&quot;: &quot;shared&quot; // 不同的文件的编译信息共享一个终端面板 &#125; // &quot;problemMatcher&quot;:&quot;$gcc&quot; // 如果你不使用clang，去掉前面的注释符，并在上一条之后加个逗号。照着我的教程做的不需要改（也可以把这行删去) &#125; ]&#125; settings.json: Code Runner的命令行和某些选项可以根据自己的需要在此处修改，用法还是参见此扩展的文档和百度gcc使用教程。如果你要使用其他地方的头文件和库文件，可能要往clang.cflags和clang.cxxflags里加-I和-L，用法百度gcc使用教程。12345678910111213141516171819202122232425262728293031&#123; &quot;files.defaultLanguage&quot;: &quot;cpp&quot;, // ctrl+N新建文件后默认的语言 &quot;editor.formatOnType&quot;: true, // 输入时就进行格式化，默认触发字符较少，分号可以触发 &quot;editor.snippetSuggestions&quot;: &quot;top&quot;, // snippets代码优先显示补全 &quot;code-runner.runInTerminal&quot;: true, // 设置成false会在“输出”中输出，无法输入 &quot;code-runner.executorMap&quot;: &#123; &quot;c&quot;: &quot;cd $dir &amp;&amp; clang $fileName -o $fileNameWithoutExt.exe -Wall -g -Og -static-libgcc -fcolor-diagnostics --target=x86_64-w64-mingw -std=c11 &amp;&amp; $dir$fileNameWithoutExt&quot;, &quot;cpp&quot;: &quot;cd $dir &amp;&amp; clang++ $fileName -o $fileNameWithoutExt.exe -Wall -g -Og -static-libgcc -fcolor-diagnostics --target=x86_64-w64-mingw -std=c++17 &amp;&amp; $dir$fileNameWithoutExt&quot; &#125;, // 设置code runner的命令行 &quot;code-runner.saveFileBeforeRun&quot;: true, // run code前保存 &quot;code-runner.preserveFocus&quot;: true, // 若为false，run code后光标会聚焦到终端上。如果需要频繁输入数据可设为false &quot;code-runner.clearPreviousOutput&quot;: false, // 每次run code前清空属于code runner的终端消息 &quot;C_Cpp.clang_format_sortIncludes&quot;: true, // 格式化时调整include的顺序（按字母排序） &quot;C_Cpp.intelliSenseEngine&quot;: &quot;Default&quot;, // 可以为Default或Tag Parser，后者较老，功能较简单。具体差别参考cpptools扩展文档 &quot;C_Cpp.errorSquiggles&quot;: &quot;Disabled&quot;, // 因为有clang的lint，所以关掉 &quot;C_Cpp.autocomplete&quot;: &quot;Disabled&quot;, // 因为有clang的补全，所以关掉 &quot;clang.cflags&quot;: [ // 控制c语言静态检测的参数 &quot;--target=x86_64-w64-mingw&quot;, &quot;-std=c11&quot;, &quot;-Wall&quot; ], &quot;clang.cxxflags&quot;: [ // 控制c++静态检测时的参数 &quot;--target=x86_64-w64-mingw&quot;, &quot;-std=c++17&quot;, &quot;-Wall&quot; ], &quot;clang.completion.enable&quot;:true // 效果效果比cpptools要好&#125; c_cpp_properties.json: 1234567891011121314151617181920212223&#123; &quot;configurations&quot;: [ &#123; &quot;name&quot;: &quot;MinGW&quot;, &quot;intelliSenseMode&quot;: &quot;clang-x64&quot;, &quot;compilerPath&quot;: &quot;C:/LLVM/bin/gcc.exe&quot;, &quot;includePath&quot;: [ &quot;$&#123;workspaceFolder&#125;&quot; ], &quot;defines&quot;: [], &quot;browse&quot;: &#123; &quot;path&quot;: [ &quot;$&#123;workspaceFolder&#125;&quot; ], &quot;limitSymbolsToIncludedHeaders&quot;: true, &quot;databaseFilename&quot;: &quot;&quot; &#125;, &quot;cStandard&quot;: &quot;c11&quot;, &quot;cppStandard&quot;: &quot;c++17&quot; &#125; ], &quot;version&quot;: 4&#125; 编译技巧 ctrl+shift+B单纯编译 按F5为运行并调试（运行前会自动编译） 加断点在列号前面点一下就行，如果想从一开始就停下来，可以加在main函数那里，或者launch.json中设置&quot;stopAtEntry&quot;: true。 按f11可以一步一步进行，箭头所指的那行代码就是下一步要运行的代码。 左边有个调试栏，可以看到变量的值,自动栏没有的可以手动添加表达式 把鼠标放到变量上可以看到变量的值，但是只能识别简单的表达式 栈帧对于递归很有用；在某些时候还可以抓取“异常”。 如果你不需要调试，可以直接右键选run code。 输出端可以输入，在settings.json中添加&quot;code-runner.runInTerminal&quot;: true]]></content>
      <categories>
        <category>vscode</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>vscode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo恢复]]></title>
    <url>%2F2018%2F12%2F22%2Fhexo%E6%81%A2%E5%A4%8D%2F</url>
    <content type="text"><![CDATA[想重新开始写博客，第一件事当然是恢复博客的正常使用啦！搜了小半天终于找到了符合我条件的教程。 背景：起初已配置好，但之后从未使用，期间重新做了一次系统。待我有时间再查询一下如何备份至云端。(已完成) 恢复安装git、node.js在原来储存博客的文件夹中(blog)`右键`-&gt;`选择`-&gt;`Git Bash Here` 再输入：1npm install hexo -g 因为重装系统有可能删除了配置文件包括环境变量里面的，没有配置 name 和 email 的话，git 是无法正常工作的。所以首先得重新配置name跟email在git bash里面输入下面两行 12git config --global user.name &quot;你的名字&quot;git config --global user.email &quot;你的邮箱&quot; 如果上面两条命令fail了的话，记得先用命令git init再输入上面两条命令 创建SSH输入 ssh-keygen -t rsa -C &quot;myemail@example.com&quot; 再按两次回车输入 cd ~/.ssh 再输入 cat id_rsa.pub会输出 12ssh-rsa xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxmyemail@example.com 登陆我的Github在settings中找到ssh and GPG keys点击new ssh key，title随意 把ssh-rsa xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx输入到key位置在git bash输入ssh -T git@github.com 可验证时候正确 修改blog目录下_config.yml如果执行hexo deploy提示 123Logon failed, use ctrl+c to cancel basic credential prompt.bash: /dev/tty: No such device or addressINFO Catch you later 则需要把下方的 1234deploy: type: git repo: https://github.com/mygithubName/mygithubName.github.io.git branch: master 修改成： 1234deploy: type: git repo: ssh://git@github.com/mygithubName/mygithubName.github.io.git branch: master 执行 hexo g -d 大功告成 常规操作： 1234hexo cleanhexo generatehexo server(本地测试用)hexo deploy 至此，网站已基本恢复。 云备份至Github为了以后更方便的从云端备份下来，我又查了一些教程，下面便是详细步骤 基本原理网站的部署其实就是生成静态文件，hexo下所有生成的静态文件会放在public/文件夹中，所谓部署deploy其实就是 将public/文件夹中内容上传到git仓库myname.github.io中。也就是说，你的仓库myname.github.io中的文件只是blog（或者命名为hexo）文件夹下的public/下的文件。本背景下，方便放在myname.github.io的repository下创建一个分支来管理 建立分支hexo 在本地磁盘下（位置任意）右键 -&gt; Git bash here，执行以下指令将myname.github.io项目文件克隆到本地： 1git clone git@github.com:myname/myname.github.io.git 此目录下便有myname.github.io文件夹，把此文件夹中除了.git之外的所有文件删掉 把blog中所有文件复制到myname.github.io 文件夹中，其中会提示是否替换，选择跳过。 如果有.gitignore文件，把里面的内容修改成 1234567.DS_StoreThumbs.dbdb.json*.lognode_modules/public/.deploy*/ 如果没有此文件，便在git bash中输入touch .gitignore 在myname.github.io 文件夹中右键 -&gt; Git bash here 创建一个叫hexo的分支并切换到这个分支上 git checkout -b hexo 提交复制过来的文件到暂存区git add --all 提交git commit -m &quot;&quot; 推送分支到githubgit push --set-upstream origin hexo在github上可以看到 branch中有master和hexo，至此，已经成功。并且hexo中的文件便在.gitirnore所忽略而剩下需要备份的文件， 更新文章，修改主题等步骤 在github中myname.github.io中，找到settings -&gt; Branches 将hexo设为默认 从此更新文章，修改主题等操作一直都在myname.github.io了 执行如下 123456hexo cleanhexo generatehexo deploygit add .git commit -m &quot;&quot;git push origin hexo 注意 -m “要写一点东西” 从github上还原此部分完全摘抄自网站，我并非试过，并不知道是否可行。 克隆项目 1git clone -b hexo git@github.com:myname/myname.github.io.git 进入博客目录 1cd myname.github.io.git 切换到博客文件分支 1git checkout -b hexo origin/hexo 安装hexo 1nmp install hexo --save 编辑，查看 12hexo ghexo s 提交git若提交过程中出现ERROR Deployer not found: git,可执行以下代码，然后重新提交 1npm install hexo-deployer-git --save 新的文章等更新 123git add .git commit -m &quot;新增博客&quot;git push origin hexo END]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>教程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[小小念]]></title>
    <url>%2F2018%2F12%2F22%2F%E5%B0%8F%E5%B0%8F%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[​ 啊啊啊啊啊啊，当时心一热搭建了一个博客，时隔四个月一直却没有更新博客善哉善哉，但期间也经历了好多，从准备保研的焦头烂额，到现在天天看剧打游戏的糜烂生活，落差之大，以至于日日积累的罪恶感促使我又有好好学习之意，遂重新在网上找了小半天的教程，把静静躺在H盘的blog文件夹重新唤醒。​ 当时心心念的保研，经历了很多很多次的失败，多方权衡下，最后以去南方科技大学而告终，毕业设计的题目也基本确定，很经典的问题——多目标优化，这也可能是我研究生研究的方向了。 ​ 从今天开始，可能就要持续更新我的小博客，记录一下~~]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>感慨</tag>
        <tag>随想</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[markdown语法]]></title>
    <url>%2F2018%2F08%2F23%2Fmarkdown%2F</url>
    <content type="text"><![CDATA[Typora For Markdown 语法，才刚刚学习，用着可能不熟练，先自行收藏一下~ 数学表达式要启用这个功能，首先到Preference-&gt;Editor中启用。然后使用`符号包裹Tex命令，例如：`$lim_{x \to \infty} \ exp(-x)=0将产生如下的数学表达式： $\lim_{x \to \infty} \exp(-x)=0$ 下标下标使用~包裹，例如：H~2~O将产生H~2~O, 即水的分子式。 上标上标使用^包裹，例如：y^2^=4将产生表达式y^2^ = 4 插入表情:happy:使用:happy:输入表情:happy:,使用:sad:输入表情:sad:,使用:cry:输入表情:cry:等。以此类推！ 下划线用HTML的语法&lt;u&gt;Underline&lt;/u&gt;将产生下划线Underline. 删除线GFM添加了删除文本的语法，这是标准的Markdown语法木有的。使用~~包裹的文本将会具有删除的样式，例如~删除文本~将产生删除文本的样式。 代码 使用`包裹的内容将会以代码样式显示，例如 1使用`printf()` 则会产生printf()样式。 输入`12* ​1234public Class HelloWorld&#123; System.out.println("Hello World!");&#125;​ 1234567将会产生~~~javapublic Class HelloWorld&#123; System.out.println(&quot;Hello World!&quot;);&#125; 强调使用两个*号或者两个_包裹的内容将会被强调。例如 12**使用两个*号强调内容**__使用两个下划线强调内容__ 将会输出 使用两个*号强调内容使用两个下划线强调内容Typroa 推荐使用两个*号。 斜体在标准的Markdown语法中，*和_包裹的内容会是斜体显示，但是GFM下划线一般用来分隔人名和代码变量名，因此我们推荐是用星号来包裹斜体内容。如果要显示星号，则使用转义： 1\* 插入图片我们可以通过拖拉的方式，将本地文件夹中的图片或者网络上的图片插入。 ​ ​ 插入URL连接使用尖括号包裹的url将产生一个连接，例如：&lt;www.baidu.com&gt;将产生连接:. 如果是标准的url，则会自动产生连接，例如:www.google.com 目录列表Table of Contents（TOC）输入[toc]然后回车，将会产生一个目录，这个目录抽取了文章的所有标题，自动更新内容。 水平分割线使用***或者---，然后回车，来产生水平分割线。 标注我们可以对某一个词语进行标注。例如 12某些人用过了才知道[^注释][^注释]:Somebody that I used to know. 将产生： 某些人用过了才知道注释注释: Somebody that I used to know. 把鼠标放在注释上，将会有提示内容。 表格12345|姓名|性别|毕业学校|工资||:---|:---:|:---:|---:||杨洋|男|重庆交通大学|3200||峰哥|男|贵州大学|5000||坑货|女|北京大学|2000| 将产生: 姓名 性别 毕业学校 工资 杨洋 男 重庆交通大学 3200 峰哥 男 贵州大学 5000 坑货 女 北京大学 2000 其中代码的第二行指定对齐的方式，第一个是左对齐，第二个和第三个是居中，最后一个是右对齐。 数学表达式块输入两个美元符号，然后回车，就可以输入数学表达式块了。例如： 1$$\mathbf&#123;V&#125;_1 \times \mathbf&#123;V&#125;_2 = \begin&#123;vmatrix&#125; \mathbf&#123;i&#125; &amp; \mathbf&#123;j&#125; &amp; \mathbf&#123;k&#125; \\\frac&#123;\partial X&#125;&#123;\partial u&#125; &amp; \frac&#123;\partial Y&#125;&#123;\partial u&#125; &amp; 0 \\\frac&#123;\partial X&#125;&#123;\partial v&#125; &amp; \frac&#123;\partial Y&#125;&#123;\partial v&#125; &amp; 0 \\\end&#123;vmatrix&#125;$$ 将会产生: \mathbf{V}_1 \times \mathbf{V}_2 = \begin{vmatrix} \mathbf{i} & \mathbf{j} & \mathbf{k} \\\frac{\partial X}{\partial u} & \frac{\partial Y}{\partial u} & 0 \\\frac{\partial X}{\partial v} & \frac{\partial Y}{\partial v} & 0 \\\end{vmatrix}任务列表使用如下的代码创建任务列表，在[]中输入x表示完成，也可以通过点击选择完成或者没完成。 1234- [ ] 吃饭- [ ] 逛街- [ ] 看电影- [ ] 约泡 [x] 吃饭 ​ [x] 逛街 ​ [x] 看电影 ​ [x] 约泡 列表输入+, -, *,创建无序的列表，使用任意数字开头，创建有序列表，例如： 1234**无序的列表*** tfboys* 杨洋* 我爱你 无序的列表 tfboys 杨洋 我爱你 1234**有序的列表**1. 苹果6. 香蕉10. 我都不喜欢 有序的列表 苹果 香蕉 我都不喜欢 块引用使用&gt;来插入块引用。例如： 1&gt;这是一个块引用！ 将产生： 这是一个块引用！ 标题使用#表示一级标题，##表示二级标题，以此类推，有6个标题。]]></content>
      <categories>
        <category>markdown</category>
      </categories>
      <tags>
        <tag>markdown</tag>
        <tag>语法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello]]></title>
    <url>%2F2018%2F08%2F22%2FHello%2F</url>
    <content type="text"><![CDATA[大学已然过三年，也浑浑噩噩过了三年。一时兴起，想搞一个属于自己的博客，把未来生活与学习路上的点点滴滴记录下来，万事开头难，于是偷个懒，就把建这个网站的过程来作为我的第一篇博客吧，记录一下，哈哈哈哈哈 安装安装git、node.js新建一个储存博客的文件夹(blogblog)打开后右键-选择-Git Bash Here输入12npm install hexo -g hexo init -g表示全局安装, npm默认为当前项目安装 node_modules：是依赖包 public：存放的是生成的页面 source：用命令创建的各种文章 themes：主题 _config.yml：整个博客的配置 db.json：source解析所得到的 package.json：项目所需模块项目的配置信息 输入123hexo cleanhexo generatehexo server 游览器打开 http://localhost:4000 但是只能在本地登录，下一步便是可以从其他地点登录 搭桥到github 选择New repository/myname.github.iomyname 必须为github的账号名 输入 12git config --global user.name &quot;my name&quot;git config --global user.email &quot;my email&quot; 创建SSH输入 ssh-keygen -t rsa -C &quot;myemail@example.com&quot; 再按两次回车输入 cd ~/.ssh 再输入 cat id_rsa.pub会输出 12ssh-rsa xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxmyemail@example.com 把ssh-rsa xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx输入到key位置输入ssh -T git@github.com 可验证时候正确 打开在blogblog目录下的_config.yml 注意冒号后有一个空格 1234deploy: type: git repo: https://github.com/mygithubName/mygithubName.github.io.git branch: master 注意：如果同一个电脑建第二个hexo需要如下： 1234deploy: type: git repo: git@github.com:mygithubName/mygithubName.github.io.git branch: master 在blogblog目录中打开 gitbash执行npm i hexo-server再执行npm install hexo-deployer-git --save执行 123hexo cleanhexo generatehexo deploy 打开 myname.github.io 就可以看到了~ 绑定域名 买一个域名，我是在阿里云买的 在项目的source文件夹中新建一个名为CNAME的文件(不需要文件后缀)，编辑文档时把所购 买的域名添加其中，注意，只可添加一个 在DNS中添加一条记录，也可以直接通过新手引导设置，其中所需的地址只需在cmd中执行 ping myname.github.io 再执行一次 123hexo cleanhexo generatehexo deploy 更换主题可以访问hexo的主题官网，我选择的是NexT主题，一来好看实用；二来很多功能都已经写好，添加功能时会更方便一些(渣渣没办法…)，因此以下为安装NexT主题为例。 执行$ git clone https://github.com/theme-next/hexo-theme-next-themes/next 打开blogblog目录的_config.yml ,其中，修改为 theme: next emmmmm…. 没错 主题就换完了，打开试试，突然就高大上了~ 修改blogblog下_config.yml的:1234567title: 清 泉subtitle:description:keywords:author: springlanguage: zh-CNtimezone: 修改blogblog/themes/next/_config.yml: 123456789menu: home: / || home #about: /about/ || user #tags: /tags/ || tags #categories: /categories/ || th archives: /archives/ || archive #schedule: /schedule/ || calendar #sitemap: /sitemap.xml || sitemap #commonweal: /404/ || heartbeat 我习惯修改为 123456789menu: home: / || home #about: /about/ || user tags: /tags/ || tags categories: /categories/ || th archives: /archives/ || archive #schedule: /schedule/ || calendar #sitemap: /sitemap.xml || sitemap #commonweal: /404/ || heartbeat 想要选择哪个把前面的#去掉即可 对于tags项： 执行hexo new page &quot;tags&quot;打开\source\tags\index.md 123456---title:date: 2018-08-21 14:56:51type: &quot;tags&quot;comments: false--- 对于categories项： 执行hexo new page &quot;categories&quot; 打开\source\categories\index.md 123456--- title: date: 2018-08-21 14:57:23 type: &quot;categories&quot; comments: false --- Next主题 又分为四种形式，可自选： 12345# Schemesscheme: Muse#scheme: Mist#scheme: Pisces#scheme: Gemini 头像12345678avatar: url: #/images/avatar.gif 你的头像图片的路径 # If true, the avatar would be dispalyed in circle. rounded: false # The value of opacity should be choose from 0 to 1 to set the opacity of the avatar. opacity: 1 # If true, the avatar would be rotated with the cursor. rotated: false 删除底部隐藏由Hexo强力驱动、主题—NexT.Mist 打开blogblog/themes/next/layout/_partials/footer.swig，注释掉相应代码 1234567891011121314151617181920212223242526//用下面的符号注释，注释代码用下面括号括起来 &lt;!-- --&gt; &lt;!-- &lt;span class=&quot;post-meta-divider&quot;&gt;|&lt;/span&gt; &#123;% if theme.footer.powered %&#125; &lt;div class=&quot;powered-by&quot;&gt;&#123;# #&#125;&#123;&#123; __(&apos;footer.powered&apos;, &apos;&lt;a class=&quot;theme-link&quot; target=&quot;_blank&quot; href=&quot;https://hexo.io&quot;&gt;Hexo&lt;/a&gt;&apos;) &#125;&#125;&#123;##&#125;&lt;/div&gt;&#123;% endif %&#125;&#123;% if theme.footer.powered and theme.footer.theme.enable %&#125; &lt;span class=&quot;post-meta-divider&quot;&gt;|&lt;/span&gt;&#123;% endif %&#125;&#123;% if theme.footer.theme.enable %&#125; &lt;div class=&quot;theme-info&quot;&gt;&#123;# #&#125;&#123;&#123; __(&apos;footer.theme&apos;) &#125;&#125; &amp;mdash; &#123;# #&#125;&lt;a class=&quot;theme-link&quot; target=&quot;_blank&quot; href=&quot;https://github.com/iissnan/hexo-theme-next&quot;&gt;&#123;# #&#125;NexT.&#123;&#123; theme.scheme &#125;&#125;&#123;# #&#125;&lt;/a&gt;&#123;% if theme.footer.theme.version %&#125; v&#123;&#123; theme.version &#125;&#125;&#123;% endif %&#125;&#123;##&#125;&lt;/div&gt; &#123;% endif %&#125; &#123;% if theme.footer.custom_text %&#125; &lt;div class=&quot;footer-custom&quot;&gt;&#123;# #&#125;&#123;&#123; theme.footer.custom_text &#125;&#125;&#123;##&#125;&lt;/div&gt;&#123;% endif %&#125;--&gt; 背景动态 canvas_nest git clone https://github.com/theme-next/theme-next-canvas-nest source/lib/canvas-nest 把&lt;script type=&quot;text/javascript&quot; src=&quot;//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js&quot;&gt;&lt;/script&gt; 插入至\blogblog\themes\next\layout\_layout.swig如下： 1234567891011&lt;html&gt;&lt;head&gt; ...&lt;/head&gt;&lt;body&gt; ... ... ... 插入到这里&lt;/body&gt;&lt;/html&gt; 再修改主题配置文件 打开/next/_config.yml,修改如下： 123# Canvas-nest# Dependencies: https://github.com/theme-next/theme-next-canvas-nestcanvas_nest: true 添加DaoVoice在线联系 首先到DaoVoice注册账号，邀请码是0f81ff2f ，登录成过后，进入到后台管理，点击应用设置——&gt;安装到网站查看安装代码和AppID。 找到app_id ，在主题配置文件中找到(没有的话添加) 123# Online contact daovoice: truedaovoice_app_id: 这里填你的刚才获得的 app_id 打开/themes/next/layout/_partials/head.swig ,代码放进去，哪行都可以 123456789&#123;% if theme.daovoice %&#125; &lt;script&gt; (function(i,s,o,g,r,a,m)&#123;i[&quot;DaoVoiceObject&quot;]=r;i[r]=i[r]||function()&#123;(i[r].q=i[r].q||[]).push(arguments)&#125;,i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;a.charset=&quot;utf-8&quot;;m.parentNode.insertBefore(a,m)&#125;)(window,document,&quot;script&quot;,(&apos;https:&apos; == document.location.protocol ? &apos;https:&apos; : &apos;http:&apos;) + &quot;//widget.daovoice.io/widget/0f81ff2f.js&quot;,&quot;daovoice&quot;) daovoice(&apos;init&apos;, &#123; app_id: &quot;&#123;&#123;theme.daovoice_app_id&#125;&#125;&quot; &#125;); daovoice(&apos;update&apos;); &lt;/script&gt;&#123;% endif %&#125; 在DaoVoice中找到聊天设置调节窗口的颜色以及位置我的参数：右侧像素20.0，下侧像素：80.0 在右上角或者左上角实现fork me on github 点击这里 或者 这里挑选自己喜欢的样式，并复制代码。 然后粘贴刚才复制的代码到themes/next/layout/_layout.swig文件中(放在&lt;div class=&quot;headband&quot;&gt;&lt;/div&gt;的下面)，并把href改为你的github地址 。 添加RSS 在blogblog中打开githash 执行 npm install --save hexo-generator-feed 在blogblog/_config.yml中添加 123# Extensions## Plugins: http://hexo.io/plugins/plugins: hexo-generate-feed 在主题配置文件中修改为： 1234# Set rss to false to disable feed link.# Leave rss as empty to use site&apos;s feed link.# Set rss to specific value if you have burned your feed already.rss: /atom.xml 添加音乐 在博客配置文件中执行npm install hexo-tag-aplayer@2.0.1 新建themes\next\source\dist\music.js ,添加内容： 12345678910111213141516171819202122232425const ap = new APlayer(&#123; container: document.getElementById(&apos;aplayer&apos;), fixed: true, autoplay: false, audio: [ &#123; name: &quot;Dream It Possible&quot;, artist: &apos;Delacey&apos;, url: &apos;http://www.ytmp3.cn/down/47868.mp3&apos;, cover: &apos;http://oeff2vktt.bkt.clouddn.com/image/84.jpg&apos;, &#125;, &#123; name: &apos;いとしすぎて&apos;, artist: &apos;KG&apos;, url: &apos;http://www.ytmp3.cn/down/35726.mp3&apos;, cover: &apos;http://oeff2vktt.bkt.clouddn.com/image/8.jpg&apos;, &#125;, &#123; name: &apos;茜さす&apos;, artist: &apos;Aimer&apos;, url: &apos;http://www.ytmp3.cn/down/44578.mp3&apos;, cover: &apos;http://oeff2vktt.bkt.clouddn.com/image/96.jpg&apos;, &#125; ]&#125;); 修改网站主题字体大小在主题配置文件中123456789101112131415161718192021222324252627282930313233font: enable: true # Uri of fonts host. E.g. //fonts.googleapis.com (Default) # 亲测这个可用，如果不可用，自己搜索 [Google 字体 国内镜像]，找个能用的就行 host: https://fonts.cat.net # Global font settings used on &lt;body&gt; element. # 全局字体，应用在 body 元素上 global: external: true family: Lato size: 16 #csdn上就是16看着舒服多了 # 标题字体 (h1, h2, h3, h4, h5, h6) headings: external: true family: Roboto Slab # 文章字体 posts: external: true family: # Logo 字体 logo: external: true family: Lobster Two size: 24 # 代码字体，应用于 code 以及代码块 codes: external: true family: Roboto Mono 站点收录百度收录在主题配置文件中修改成： 1baidu_site_verification: true 进入百度站点检验网站 ，选择http:// ,purespring.top 信息技术 由于前两个验证一直通过不了，所以我选择了CNAME验证 进入阿里云 我是在阿里云买的域名，所以进入那里。 进入解析设置 添加记录 类型： CNAME 主机记录： xxxxx.purespring.top(这个会告诉你) 记录值：zz.baidu(这个会告诉你) 就可以完成确认 更改细节主题在文件\themes\next\source\css\_custom\custom.styl中，放入如下代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600// Custom styles//首页头部样式.header &#123; background: url("/images/header-bk.jpg");&#125;.site-meta &#123; margin-left: 0px; text-align: center;&#125;.site-meta .site-title &#123; font-size: 20px; font-family: 'Comic Sans MS', sans-serif; color: #fff; letter-spacing: 1px; width: 81%;&#125;// 点文章进去的页面背景色.container &#123; background-color: rgba(255, 255, 255, 0.747);&#125;// 页面留白更改.header-inner &#123; padding-top: 0px; padding-bottom: 0px;&#125;.posts-expand &#123; padding-top: 80px;&#125;.posts-expand .post-meta &#123; margin: 5px 0px 0px 0px;&#125;.post-button &#123; margin-top: 0px;&#125;// 顶栏宽度.container .header-inner &#123; width: 100%;&#125;// 站点名背景.brand&#123; background-color: rgb(56, 53, 53); margin-top: 15px; padding: 0px;&#125;// 站点名字体.site-title &#123; line-height: 35px; letter-spacing: 3px;&#125;// 站点子标题.site-subtitle&#123; margin: 0px; font-size: 16px; letter-spacing: 1px; padding-bottom: 3px; font-weight: bold; color: rgb(219, 95, 95); border-bottom-width: 3px; border-bottom-style: solid; border-bottom-color: rgb(161, 102, 171);&#125;.logo-line-after &#123; display: none;&#125;.logo-line-before &#123; display: none;&#125;// 菜单.menu &#123; float: none;&#125;// 菜单超链接字体大小.menu .menu-item a &#123; font-size: 14px; color: rgb(15, 46, 65); border-radius: 4px;&#125;// 菜单各项边距.menu .menu-item &#123; margin: 5px 15px;&#125;// 菜单超链接样式.menu .menu-item a:hover &#123; border-bottom-color: rgba(161, 102, 171, 0);&#125;// 文章.post &#123; margin-bottom: 50px; padding: 45px 36px 36px 36px; box-shadow: 0px 0px 10px 0px rgba(0, 0, 0, 0.5); background-color: rgb(255, 255, 255);&#125;// 文章标题字体.posts-expand .post-title &#123; font-size: 26px; font-weight: 700;&#125;// 文章标题动态效果.posts-expand .post-title-link::before &#123; background-image: linear-gradient(90deg, #a166ab 0%, #ef4e7b 25%, #f37055 50%, #ef4e7b 75%, #a166ab 100%);&#125;// 文章元数据（meta）留白更改.posts-expand .post-meta &#123; margin: 10px 0px 20px 0px;&#125;// 文章的描述description.posts-expand .post-meta .post-description &#123; font-style: italic; font-size: 14px; margin-top: 30px; margin-bottom: 0px; color: #666;&#125;// [Read More]按钮样式.post-button .btn &#123; color: rgba(219, 210, 210, 0.911)!important; background-color: rgba(56, 52, 52, 0.911); border-radius: 3px; font-size: 15px; box-shadow: inset 0px 0px 10px 0px rgba(0, 0, 0, 0.35); border: none !important; transition-property: unset; padding: 0px 15px;&#125;.post-button .btn:hover &#123; color: rgba(219, 210, 210, 0.911) !important; border-radius: 3px; font-size: 15px; box-shadow: inset 0px 0px 10px 0px rgba(0, 0, 0, 0.35); background-image: linear-gradient(100deg, #a166ab 0%, #ef4e7b 25%, #f37055 50%, #ef4e7b 75%, #a166ab 100%);&#125;// 去除在页面文章之间的分割线.posts-expand .post-eof &#123; margin: 0px; background-color: rgba(255, 255, 255, 0);&#125;// 去除页面底部页码上面的横线.pagination &#123; border: none; margin: 0px;&#125;// 页面底部页码.pagination .page-number.current &#123; border-radius: 100%; box-shadow: 0px 0px 10px 0px rgba(0, 0, 0, 0.5); background-color: rgba(255, 255, 255, 0.35);&#125;.pagination .prev, .pagination .next, .pagination .page-number &#123; margin-bottom: 10px; border: none;&#125;.pagination .space &#123; color: rgb(255, 255, 255);&#125;// 页面底部页脚.footer &#123; line-height: 1.5; background-color: rgba(255, 255, 255, 0.75); color: #333; border-top-width: 3px; border-top-style: solid; border-top-color: rgb(161, 102, 171); box-shadow: 0px -10px 10px 0px rgba(0, 0, 0, 0.15);&#125;// 文章底部的tags.posts-expand .post-tags a &#123; border-bottom: none; margin-right: 0px; font-size: 13px; padding: 0px 5px; border-radius: 3px; transition-duration: 0.2s; transition-timing-function: ease-in-out; transition-delay: 0s;&#125;.posts-expand .post-tags a:hover &#123; background: #eee;&#125;// 文章底部留白更改.post-widgets &#123; padding-top: 0px;&#125;.post-nav &#123; margin-top: 30px;&#125;// 文章底部页面跳转.post-nav-item a &#123; color: rgb(80, 115, 184); font-weight: bold;&#125;.post-nav-item a:hover &#123; color: rgb(161, 102, 171); font-weight: bold;&#125;// 文章底部评论.comments &#123; background-color: rgb(255, 255, 255); box-shadow: 0px 0px 10px 0px rgba(0, 0, 0, 0.35); margin: 80px 0px 40px 0px;&#125;// 超链接样式a &#123; color: rgb(80, 115, 184); border-bottom-color: rgb(80, 115, 184);&#125;a:hover &#123; color: rgb(161, 102, 171); border-bottom-color: rgb(161, 102, 171);&#125;// 分割线样式hr &#123; margin: 10px 0px 30px 0px;&#125;// 文章内标题样式（左边的竖线）.post-body h2, h3, h4, h5, h6 &#123; border-left: 4px solid rgb(161, 102, 171); margin-left: -36px; padding-left: 32px;&#125;// 去掉图片边框.posts-expand .post-body img &#123; border: none; padding: 0px;&#125;.post-gallery .post-gallery-img img &#123; padding: 3px;&#125;// 文章``代码块的自定义样式code &#123; margin: 0px 4px;&#125;// 文章```代码块顶部样式.highlight figcaption &#123; margin: 0em; padding: 0.5em; background: #eee; border-bottom: 1px solid #e9e9e9;&#125;.highlight figcaption a &#123; color: rgb(80, 115, 184);&#125;// 文章```代码块diff样式pre .addition &#123; background: #e6ffed;&#125;pre .deletion &#123; background: #ffeef0;&#125;// 右下角侧栏按钮样式.sidebar-toggle &#123; right: 10px; bottom: 43px; background-color: rgba(247, 149, 51, 0.75); border-radius: 5px; box-shadow: 0px 0px 10px 0px rgba(0, 0, 0, 0.35);&#125;.page-post-detail .sidebar-toggle-line &#123; background: rgb(17, 185, 163);&#125;// 右下角返回顶部按钮样式.back-to-top &#123; line-height: 1.5; right: 10px; padding-right: 5px; padding-left: 5px; padding-top: 2.5px; padding-bottom: 2.5px; background-color: rgba(247, 149, 51, 0.75); border-radius: 5px; box-shadow: 0px 0px 10px 0px rgba(0, 0, 0, 0.35);&#125;.back-to-top.back-to-top-on &#123; bottom: 10px;&#125;// 侧栏.sidebar &#123; box-shadow: inset 0px 0px 10px 0px rgba(0, 0, 0, 0.5); background-color: rgba(0, 0, 0, 0.75);&#125;.sidebar-inner &#123; margin-top: 30px;&#125;// 侧栏顶部文字.sidebar-nav li &#123; font-size: 15px; font-weight: bold; color: rgb(7, 179, 155);&#125;.sidebar-nav li:hover &#123; color: rgb(161, 102, 171);&#125;.sidebar-nav .sidebar-nav-active &#123; color: rgb(7, 179, 155); border-bottom-color: rgb(161, 102, 171); border-bottom-width: 1.5px;&#125;.sidebar-nav .sidebar-nav-active:hover &#123; color: rgb(7, 179, 155);&#125;// 侧栏站点概况行高.site-overview &#123; line-height: 1.3;&#125;// 侧栏头像（圆形以及旋转效果）.site-author-image &#123; border: 2px solid rgb(255, 255, 255); border-radius: 100%; transition: transform 1.0s ease-out;&#125;img:hover &#123; transform: rotateZ(360deg);&#125;.posts-expand .post-body img:hover &#123; transform: initial;&#125;// 侧栏站点作者名.site-author-name &#123; display: none;&#125;// 侧栏站点描述.site-description &#123; letter-spacing: 5px; font-size: 15px; font-weight: bold; margin-top: 15px; margin-left: 13px; color: rgb(243, 112, 85);&#125;// 侧栏站点文章、分类、标签.site-state &#123; line-height: 1.3; margin-left: 12px;&#125;.site-state-item &#123; padding: 0px 15px; border-left: 1.5px solid rgb(161, 102, 171);&#125;// 侧栏RSS按钮样式.feed-link &#123; margin-top: 15px; margin-left: 7px;&#125;.feed-link a &#123; color: rgb(255, 255, 255); border: 1px solid rgb(158, 158, 158) !important; border-radius: 15px;&#125;.feed-link a:hover &#123; background-color: rgb(161, 102, 171);&#125;.feed-link a i &#123; color: rgb(255, 255, 255);&#125;// 侧栏社交链接.links-of-author &#123; margin-top: 0px;&#125;// 侧栏友链标题.links-of-blogroll-title &#123; margin-bottom: 10px; margin-top: 15px; color: rgba(7, 179, 156, 0.74); margin-left: 6px; font-size: 15px; font-weight: bold;&#125;// 侧栏超链接样式（友链的样式）.sidebar a &#123; color: #ccc; border-bottom: none;&#125;.sidebar a:hover &#123; color: rgb(255, 255, 255);&#125;// 自定义的侧栏时间样式#days &#123; display: block; color: rgb(7, 179, 155); font-size: 13px; margin-top: 15px;&#125;// 侧栏目录链接样式.post-toc ol a &#123; color: rgb(75, 240, 215); border-bottom: 1px solid rgb(96, 125, 139);&#125;.post-toc ol a:hover &#123; color: rgb(161, 102, 171); border-bottom-color: rgb(161, 102, 171);&#125;// 侧栏目录链接样式之当前目录.post-toc .nav .active &gt; a &#123; color: rgb(161, 102, 171); border-bottom-color: rgb(161, 102, 171);&#125;.post-toc .nav .active &gt; a:hover &#123; color: rgb(161, 102, 171); border-bottom-color: rgb(161, 102, 171);&#125;/* 修侧栏目录bug，如果主题配置文件_config.yml的toc是wrap: true */.post-toc ol &#123; padding: 0px 10px 5px 10px;&#125;/* 侧栏目录默认全展开，已注释.post-toc .nav .nav-child &#123; display: block;&#125;*/// 时间轴样式.posts-collapse &#123; margin: 50px 0px;&#125;@media (max-width: 1023px) &#123; .posts-collapse &#123; margin: 50px 20px; &#125;&#125;// 时间轴左边线条.posts-collapse::after &#123; margin-left: -2px; background-image: linear-gradient(180deg,#f79533 0,#f37055 15%,#ef4e7b 30%,#a166ab 44%,#5073b8 58%,#1098ad 72%,#07b39b 86%,#6dba82 100%);&#125;// 时间轴左边线条圆点颜色.posts-collapse .collection-title::before &#123; background-color: rgb(255, 255, 255);&#125;// 时间轴文章标题左边圆点颜色.posts-collapse .post-header:hover::before &#123; background-color: rgb(161, 102, 171);&#125;// 时间轴年份.posts-collapse .collection-title h1, .posts-collapse .collection-title h2 &#123; color: rgb(255, 255, 255);&#125;// 时间轴文章标题.posts-collapse .post-title a &#123; color: rgb(80, 115, 184);&#125;.posts-collapse .post-title a:hover &#123; color: rgb(161, 102, 171);&#125;// 时间轴文章标题底部虚线.posts-collapse .post-header:hover &#123; border-bottom-color: rgb(161, 102, 171);&#125;// archives页面顶部文字.page-archive .archive-page-counter &#123; color: rgb(255, 255, 255);&#125;// archives页面时间轴左边线条第一个圆点颜色.page-archive .posts-collapse .archive-move-on &#123; top: 10px; opacity: 1; background-color: rgb(255, 255, 255); box-shadow: 0px 0px 10px 0px rgba(0, 0, 0, 0.5);&#125;// 分类页面.post-block.page &#123; margin-top: 40px;&#125;.category-all-page &#123; margin: -80px 50px 40px 50px; box-shadow: 0px 0px 10px 0px rgba(0, 0, 0, 0.5); background-color: rgb(255, 255, 255); padding: 86px 36px 36px 36px;&#125;@media (max-width: 767px) &#123; .category-all-page &#123; margin: -73px 15px 50px 15px; &#125; .category-all-page .category-all-title &#123; margin-top: -5px; &#125;&#125;// 标签云页面.tag-cloud &#123; margin: -80px 50px 40px 50px; box-shadow: 0px 0px 10px 0px rgba(0, 0, 0, 0.5); background-color: rgb(255, 255, 255); padding: 86px 36px 36px 36px;&#125;.tag-cloud-title &#123; margin-bottom: 15px;&#125;@media (max-width: 767px) &#123; .tag-cloud &#123; margin: -73px 15px 50px 15px; padding: 86px 5px 36px 5px; &#125;&#125;// 自定义的TopX页面样式#top &#123; display: block; text-align: center; margin: -100px 50px 40px 50px; box-shadow: 0px 0px 10px 0px rgba(0, 0, 0, 0.5); background-color: rgb(255, 255, 255); padding: 106px 36px 10px 36px;&#125;@media (max-width: 767px) &#123; #top &#123; margin: -93px 15px 50px 15px; padding: 96px 10px 0px 10px; &#125;&#125;// 自定义ABOUT页面的样式.about-page &#123; margin: -80px 0px 60px 0px; box-shadow: 0px 0px 10px 0px rgba(0, 0, 0, 0.5); background-color: rgb(255, 255, 255); padding: 106px 36px 36px 36px;&#125;@media (max-width: 767px) &#123; .about-page &#123; margin: -73px 0px 50px 0px; padding: 96px 15px 20px 15px; &#125;&#125;h2.about-title &#123; border-left: none !important; margin-left: 0px !important; padding-left: 0px !important; text-align: center; background-image: linear-gradient(90deg, #a166ab 0%, #a166ab 40%, #ef4e7b 45%, #f37055 50%, #ef4e7b 55%, #a166ab 60%, #a166ab 100%); background-size: cover; -webkit-background-clip: text; -webkit-text-fill-color: transparent; user-select: none;&#125;// 本地搜索框.local-search-popup .search-icon, .local-search-popup .popup-btn-close &#123; color: rgb(247, 149, 51); margin-top: 7px;&#125;.local-search-popup .local-search-input-wrapper input &#123; padding: 9px 0px; height: 21px; background-color: rgb(255, 255, 255);&#125;.local-search-popup .popup-btn-close &#123; border-left: none;&#125;// 选中文字部分的样式::selection &#123; background-color: rgb(255, 241, 89); color: #555;&#125;/* 设置滚动条的样式 *//* 参考https://segmentfault.com/a/1190000003708894 */::-webkit-scrollbar &#123; height: 5px;&#125;/* 滚动槽 */::-webkit-scrollbar-track &#123; background: #eee;&#125;/* 滚动条滑块 */::-webkit-scrollbar-thumb &#123; border-radius: 5px; background-color: #ccc;&#125;::-webkit-scrollbar-thumb:hover &#123; background-color: rgb(247, 149, 51);&#125;// 音乐播放器aplayer.aplayer &#123; font-family: Lato, -apple-system, BlinkMacSystemFont, "PingFang SC", "Hiragino Sans GB", "Heiti SC", STHeiti, "Source Han Sans SC", "Noto Sans CJK SC", "WenQuanYi Micro Hei", "Droid Sans Fallback", "Microsoft YaHei", sans-serif !important;&#125;.aplayer-withlrc.aplayer .aplayer-info &#123; background-color: rgb(255, 255, 255);&#125;// 音乐播放器aplayer歌单.aplayer .aplayer-list ol &#123; background-color: rgb(255, 255, 255);&#125;// 修视频播放器dplayer页面全屏的bug.use-motion .post-body &#123; transform: inherit !important;&#125;// 自定义emoji样式img#github-emoji &#123; margin: 0px; padding: 0px; display: inline !important; vertical-align: text-bottom; border: none; cursor: text; box-shadow: none;&#125;.site-meta .brand &#123; width: 10%;&#125;// 页面最顶部的横线.headband &#123; height: 1.5px; background-image: linear-gradient(90deg, #F79533 0%, #F37055 15%, #EF4E7B 30%, #A166AB 44%, #5073B8 58%, #1098AD 72%, #07B39B 86%, #6DBA82 100%);&#125; 打开网站缓冲条式特效打开\themes\next\layout\_partials\head\head.swig文件 在下面增加如下代码 123456789101112131415161718&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1, maximum-scale=1&quot;/&gt;&lt;!-- S 新增代码 --&gt;&lt;script src=&quot;//cdn.bootcss.com/pace/1.0.2/pace.min.js&quot;&gt;&lt;/script&gt;&lt;link href=&quot;//cdn.bootcss.com/pace/1.0.2/themes/pink/pace-theme-flash.css&quot; rel=&quot;stylesheet&quot;&gt;&lt;style&gt; .pace .pace-progress &#123; background: #24292e; /*进度条颜色*/ height: 3px; &#125; .pace .pace-progress-inner &#123; box-shadow: 0 0 10px #1E92FB, 0 0 5px #1E92FB; /*阴影颜色*/ &#125; .pace .pace-activity &#123; border-top-color: #1E92FB; /*上边框颜色*/ border-left-color: #1E92FB; /*左边框颜色*/ &#125;&lt;/style&gt;&lt;!-- E 新增代码 --&gt; 至此，网站已基本配置完成。]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>教程</tag>
      </tags>
  </entry>
</search>
