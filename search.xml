<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[WebScraping-2]]></title>
    <url>%2F2019%2F07%2F13%2FWebScraping2%2F</url>
    <content type="text"><![CDATA[没什么好说的，觉得学的太基础，想快快学，但是在家就很懈怠，一直看剧看剧。。。 对了，忘记声明：此系列参照了《Web Scraping with Python, 2nd Edition》———Ryan Mitchell 假设你有一些目标内容。可能是一个名称、统计数据或文本块。也许它将20层标签在HTML代码中，没有任何有用的标签或HTML属性。假设您决定将警告抛到九霄云外，并编写类似下面这样的代码来尝试提取: 1bs.find_all('table')[4].find_all('tr')[2].find('td').find_all('div')[1].find('a') 看起来不太好。除了线条的美观之外，站点管理员对网站的任何微小更改都可能彻底破坏web scraper。 对于已下这种文本，可以用find_all()来提取绿色的文本： 12&lt;span class="red"&gt;Heavens! what a virulent attack!&lt;/span&gt; replied&lt;span class="green"&gt;the prince&lt;/span&gt;, not in the least disconcerted by this reception. 具体代码： 1234567from urllib.request import urlopenfrom bs4 import BeautifulSouphtml = urlopen('http://www.pythonscraping.com/pages/page1.html')bs = BeautifulSoup(html.read(), 'html.parser')nameList = bs.findAll('span', &#123;'class':'green'&#125;)for name in nameList: print(name.get_text()) 其中，.get_text()从正在处理的文档中删除所有标记，并返回只包含文本的Unicode字符串。例如，如果您正在处理一个包含许多超链接、段落和其他标记的大文本块，那么所有这些都将被删除，只剩下一个无标记的文本块。请记住，在一个BeautifulSoup对象中查找要比在一个文本块中查找容易得多。在打印、存储或操作最终数据之前，调用.get_text()应该是您做的最后一件事。一般来说，应该尽可能长地保存文档的标记结构。 Another serving of BeautifulSoupfind/find_all() with BeautifulSoupfind()与find_all()非常相似。它们的细节如下： 12find_all(tag, attributes, recursive, text, limit, keywords)find(tag, attributes, recursive, text, keywords) tag是之前见过的，可以传递标记的字符串名称，甚至是字符串标记名称的Python列表。例如 1.find_all(['h1','h2','h3','h4','h5','h6']) attributes参数接受一个Python属性字典，并匹配包含其中任何一个属性的标记。例如，下面的函数将返回HTML文档中的绿色和红色span标记: 1.find_all('span', &#123;'class':&#123;'green', 'red'&#125;&#125;) recursive是一个 布尔值。您想要深入到文档的哪个部分?如果将recursive设置为True, find_all函数将查看children、children‘s children…用于匹配参数的标记。如果为False，它将只查看文档中的顶级标记。默认情况下，find_all是递归工作的(recursive设置为True)；一般来说，保持现状是一个好主意，除非真正知道需要做什么，并且性能是个问题。 text参数的不同寻常之处在于，它是基于标记的文本内容而不是标记本身的属性进行匹配的。例如，如果想在示例页面上找到“prince”被标记包围的次数，可以用以下行替换前面示例中的.find_all()函数： 12nameList = bs.find_all(text='the prince')print(len(nameList)) limit参数只在find_all方法中使用；find等价于相同的find_all调用，限制为1。如果只对从页面中检索前x项感兴趣，可以设置此选项。但是，请注意，这将按出现的顺序显示页面上的第一项，而不一定是您想要的第一项。 keyword参数允许您选择包含特定属性或一组属性的标记。例如： 1title = bs.find_all(id='title', class_='text') 这将返回class_属性中带有单词“text”和id属性中带有单词“title”的第一个标记。注意，按照惯例，id的每个值在页面上只能使用一次。因此，在实际中，这样一行字可能不是特别有用，应相当于下列案文: 1title = bs.find(id='title') keyword参数在某些情况下是有用的。然而，作为一个BeautifulSoup特性，它在技术上是多余的。请记住，任何可以使用关键字完成的事情也可以使用本章后面介绍的技术来完成(参见regular_express和lambda_express)。例如，以下是相同的： 12bs.find_all(id='text')bs.find_all('', &#123;'id':'text'&#125;) 此外，您可能偶尔会遇到使用keyword的问题，最明显的是当根据类属性搜索元素时，因为class在Python中是受保护的关键字。也就是说，class是Python中不能使用的保留字作为变量或参数名(与前面讨论的beautiful .find_all()关键字参数没有关系)。例如，如果您尝试以下调用，由于类的非标准使用，您将得到一个语法错误: 123456bs.find_all(class='green') File "&lt;ipython-input-1-6de1a859337f&gt;", line 7 bs.find_all(class = 'green') ^SyntaxError: invalid syntax 而以下便可以，加入一个下划线： 1bs.find_all(class_='green') 当然，以下也是可以的： 1bs.find_all('', &#123;'class':'green'&#125;) 回想一下，通过属性列表将标记列表传递给.find_all()就像一个“或”过滤器(它选择包含tag1、tag2或tag3…的所有标记的列表)。如果你有一个很长的标签列表，你可能会得到很多你不想要的东西。keyword参数允许您为此添加一个额外的“和”过滤器。 other BeautifulSoup objects到目前为止，已经在BeautifulSoup库中看到了两种类型的对象: BeautifulSoup objects 在前面的代码示例中看到的实例作为变量bs 在列表中检索，或通过在BeautifulSoup上调用find和find_all分别检索或向下搜索，如下: 1bs.div.h1 然而，库中还有另外两个对象，虽然不太常用，但仍然需要了解: NavigableString objects 用于表示标记内的文本，而不是标记本身(一些函数操作并生成navigablestring，而不是标记对象)。 Comment object 用于在注释标签中查找HTML注释，如： 1&lt;!----like this one----&gt; 这四个对象是在BeautifulSoup库中(此版本时)将遇到的惟一对象。 navigating treesfind_all函数负责根据标签的名称和属性查找标签。但是，如果需要根据文档中的位置查找标记，该怎么办？这就是树导航(navigating trees)派上用场的地方。之前我们的老师方法如下： 1bs.tag.subTag.anotherSubTag 现在，让我们看看如何向上、跨界和对角地导航HTML树。您将使用我们非常可疑的在线购物网站http://www.pythonscraping.com/pages/page3.html ，作为一个用于抓取的示例页面，如图下图所示： 具体的html树是这样的： children and descendants此时要区分children与 descendants。 children：是一个标签的孩子，例如，在上图中，tr是table的孩子。 descendants：是一个标签的后代，例如，在上图中，tr，th，td，img和span都是table的后代。 因此，对于一个标签，它的所有的children都是decendants，但反之未必。 通常，BeautifulSoup函数总是处理所选当前标记的descendants。例如，bs.body.h1选择主体标记的后代的第一个h1标记。它不会找到位于主体之外的标记。 同样的，bs.div.find_all(&#39;img&#39;)也是查找文档中的第一个div，并且返回此div的 descendants中的的所有img的标签。 如果你只想输出只是children的标签： 123456from urllib.request import urlopenfrom bs4 import BeautifulSouphtml = urlopen('http://www.pythonscraping.com/pages/page3.html')bs = BeautifulSoup(html, 'html.parser')for child in bs.find('table',&#123;'id':'giftList'&#125;).children: print(child) 如果是children，那么输出的，如下： 同样的，如果输出后代，只要把children换成descendants即可。 如果，是descendants，输入，类似如下 1234567891011121314151617&lt;tr class="gift" id="gift1"&gt; &lt;td&gt; Vegetable Basket &lt;/td&gt; &lt;td&gt; This vegetable basket is the perfect gift for your health conscious (or overweight) friends! &lt;span class="excitingNote"&gt;Now with super-colorful bell peppers! &lt;/span&gt; &lt;/td&gt; &lt;td&gt; $15.00 &lt;/td&gt; &lt;td&gt; &lt;img src="../img/gifts/img1.jpg"/&gt; &lt;/td&gt;&lt;/tr&gt; 那么输出如下： 123456789101112131415161718192021222324252627&lt;td&gt; Vegetable Basket&lt;/td&gt;Vegetable Basket&lt;td&gt; This vegetable basket is the perfect gift for your health conscious (or overweight) friends! &lt;span class="excitingNote"&gt;Now with super-colorful bell peppers!&lt;/span&gt;&lt;/td&gt;This vegetable basket is the perfect gift for your health conscious (or overweight) friends!&lt;span class="excitingNote"&gt;Now with super-colorful bell peppers!&lt;/span&gt;Now with super-colorful bell peppers!&lt;td&gt;$15.00&lt;/td&gt;$15.00&lt;td&gt;&lt;img src="../img/gifts/img1.jpg"/&gt;&lt;/td&gt;&lt;img src="../img/gifts/img1.jpg"/&gt; next_siblings()有了子孙后代，当然还有同辈之间函数：next_siblings()，具体实例如下： 123456from urllib.request import urlopenfrom bs4 import BeautifulSouphtml = urlopen('http://www.pythonscraping.com/pages/page3.html')bs = BeautifulSoup(html, 'html.parser')for sibling in bs.find('table', &#123;'id':'giftList'&#125;).tr.next_siblings: print(sibling) 这段代码的输出是打印商品表中的所有产品行，除了第一行标题行。为什么标题行被跳过？对象不能是它们自己的兄弟姐妹。任何时候，只要对象有兄弟姐妹，该对象本身就不会包含在列表中。正如函数的名称所示，它只调用next sibling()。例如，如果您要选择列表中间的一行，并在其上调用next_sibling()，那么只会返回后面的兄弟姐妹。因此，通过选择标题行并调用next_sibling()，可以选择表中的所有行，而不需要选择标题行本身。 作为next_sibling()的一个补充，如果希望获得的同级标记列表的末尾有一个易于选择的标记，那么previous_sibling()函数通常会很有帮助。 parents在抓取页面时，您可能会发现，与查找标记的孩子或兄弟姐妹相比，查找标记的父母的频率要低一些。通常，当您以爬行为目标查看HTML页面时，首先要查看标签的顶层，然后找出如何深入到所需的确切数据块。然而，偶尔会发现自己处于一些奇怪的情况，需要BeautifulSoup的父类查找功能.parent和.parents。例如： 12345from urllib.request import urlopenfrom bs4 import BeautifulSouphtml = urlopen('http://www.pythonscraping.com/pages/page3.html')bs = BeautifulSoup(html, 'html.parser')print(bs.find('img',&#123;'src':'../img/gifts/img1.jpg'&#125;).parent.previous_sibling.get_text()) 这段代码将打印由该位置的图像表示的对象的价格../img/gifts/img1.jpg(本例中价格为15.00美元)。 具体过程如下： 1234567&lt;tr&gt; - td - td - td 《3》 - "$15.00" 《4》 - td 《2》 - &lt;img src="../img/gifts/img1.jpg"&gt; 《1》 《1》图像 ../img/gifts/img1.jpg首先被选择 《2》选择它的父母，此例中为td 《3》选择td的previous_sibling，此例中是价钱的那个td 《4》选择这个标签的文本”$15.00” Regular expressions这是一个很重要的模块！ 我用了正则字符串这个短语。什么是常规字符串?它是任何可以由一系列线性规则生成的字符串，例如: 至少出现一个字母a 再加上准确的5次字母b 再加上任何偶数个的字母c 以d或者e为结尾 用正则表达式写出：aa*bbbbb(cc)*(d|e) 符号 含义 举例 实例 * 匹配前面的字符，子表达式或括起来的字符，0或者更多次 a*b* aaaaa, aabbb, bbbb + 匹配前面的字符，子表达式或括起来的字符，1或者更多次 a+b+ aaaab, aaabb, abbb [] 匹配括号里的任何一个字符， [A-Z]* APPLE, HELLO () 变成一个子表达式(优先按照正则表达式的“操作顺序”计算这些值) (a*b)* aaabaab, abaaab, ababaaab {m,n} 匹配前面的字符，(优先按照正则表达式的“操作顺序”计算这些值) a{2,3}b{2,3} aabbb, aaabbb, aabb 匹配任何一个不在括号的字符 A-Z apple, nihao \ 匹配由I分隔的任何字符、字符串或子表达式 b(a\ i\ e)d bad, bid, bed . 匹配任何一个字符(包括符号，数字，空格等) b.d bad, b d, b$d ^ 指示字符或子表达式出现在字符串的开头 ^a apple, asdf, a \ 转义字符(这允许您使用特殊字符作为其字面含义) \.\\ \\\\ .\ \\ $ 通常在正则表达式的末尾使用，它的意思是“将这个匹配到字符串的末尾”。没有它，每个正则表达式都有一个事实，”.*“在它的末尾，接受只有字符串的第一部分匹配的字符串。这可以看作类似于^符号。 [A-Z]*[a-z]*$ ABCabc, zzzyx, Bob ?! ”不包含。这是个奇怪的符号，紧接在一个字符(或正则表达式)前面，表示这个字符不应该在字符串的特定位置找到。这可能很难使用；毕竟，字符可能在字符串的不同部分找到。如果试图完全消除一个字符，请与连用^和$在两端。 ^((?![A-Z]).)*$ no-caps-here, $ymb0ls a4e f!ne Regular expressions and BeautifulSoup因此，如果想应用在BeautifulSoup函数中，已上例中，想要输出所有的 1&lt;img src="../img/gifts/img3.jpg"&gt; 在使用find_all(&quot;img&quot;)的时候，也会把其他的多余项加进来，代码如下： 123456789101112131415from urllib.request import urlopenfrom bs4 import BeautifulSoupimport rehtml = urlopen('http://www.pythonscraping.com/pages/page3.html')bs = BeautifulSoup(html, 'html.parser')images = bs.find_all('img',&#123;'src':re.compile('\.\.\/img\/gifts/img.*\.jpg')&#125;)for image in images: print(image['src']) output:../img/gifts/img1.jpg../img/gifts/img2.jpg../img/gifts/img3.jpg../img/gifts/img4.jpg../img/gifts/img6.jpg Accessing attributes标题翻译为：访问属性 到目前为止，已经了解了如何访问和过滤标签以及访问其中的内容。然而，通常在web抓取中，并不寻找标记的内容；你在寻找它的属性。这对于a之类的标记尤其有用，其中它所指向的URL包含在href属性中；或者img标记，其中目标图像包含在src属性中。 使用标签对象，可以通过调用以下命令自动访问Python属性列表: 1myTag.attrs 请记住，这实际上返回了一个Python dictionary对象，这使得检索和操作这些属性变得非常简单。例如，可以使用以下行找到图像的源位置： 1myImgTag.attrs['src'] Lambda expressionslambda表达式是作为变量传递给另一个函数的函数;您可以将函数定义为f(g(x) y)，甚至f(g(x),h(x))，而不是f(x, y)。 BeautifulSoup允许您将某些类型的函数作为参数传递给find_all函数。 唯一的限制是这些函数必须接受一个标记对象作为参数并返回一个布尔值。在这个函数中，BeautifulSoup遇到的每个标记对象都被求值，求值为True的标记被返回，其余的则被丢弃。 例如，下面的代码检索所有恰好具有两个属性的标签： 1bs.find_all(lambda tag: len(tag.attrs) == 2) 这里，作为参数传递的函数是len(tag.attrs) == 2。如果为真，find_all函数将返回标记。也就是说，它会找到具有两个属性的标签，例如： 12&lt;div class="body" id="content"&gt;&lt;/div&gt;&lt;span style="color:red" class="title"&gt;&lt;/span&gt; Lambda函数非常有用，你甚至可以用它们来替换现有的BeautifulSoup函数: 1bs.find_all(lambda tag: tag.get_text() =='Or maybe he\'s only resting?') 这也可以在没有lambda函数的情况下完成: 1bs.find_all('', text='Or maybe he\'s only resting?') 但是，如果您记住lambda函数的语法，以及如何访问标记属性，那么您可能再也不需要记住任何其他BeautifulSoup语法了! 因为所提供的lambda函数可以是返回True或的任何函数False值，您甚至可以将它们与正则表达式组合起来，以查找具有匹配特定字符串模式的属性的标记。]]></content>
      <categories>
        <category>Web-Scraping</category>
      </categories>
      <tags>
        <tag>Web-Scraping</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[webscraping-1]]></title>
    <url>%2F2019%2F07%2F12%2Fwebscraping1%2F</url>
    <content type="text"><![CDATA[创建爬虫专题，完全出于自己的爱好兴趣，可能与学业无关。因此，所记录的会尽量精简，只作为我的学习笔记。 建议环境：python3，jupyter notebook 初入最初的样例如下，函数urlopen(url)：打开网站 123from urllib.request import urlopenhtml = urlopen('http://pythonscraping.com/pages/page1.html')print(html.read()) 输出是这样的： 1b'&lt;html&gt;\n&lt;head&gt;\n&lt;title&gt;A Useful Page&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n&lt;h1&gt;An Interesting Title&lt;/h1&gt;\n&lt;div&gt;\nLorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n&lt;/div&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n 可以再通过BeautifulSoup对网站进行解析 12345678from urllib.request import urlopenfrom bs4 import BeautifulSouphtml = urlopen('http://www.pythonscraping.com/pages/page1.html')bs = BeautifulSoup(html.read(), 'html.parser')print(bs.h1)output:&lt;h1&gt;An Interesting Title&lt;/h1&gt; 其中，bs为： 1234567891011&lt;html&gt;&lt;head&gt;&lt;title&gt;A Useful Page&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;An Interesting Title&lt;/h1&gt;&lt;div&gt;Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 此网页的结构如下： 123456- html -&gt; &lt;html&gt;&lt;head&gt;...&lt;/head&gt;&lt;body&gt;...&lt;/body&gt;&lt;/html&gt; - head -&gt; &lt;head&gt;&lt;title&gt;A Useful Page&lt;title&gt;&lt;/head&gt; - title -&gt; &lt;title&gt;A Useful Page&lt;/title&gt;- body -&gt; &lt;body&gt;&lt;h1&gt;An Int...&lt;/h1&gt;&lt;div&gt;Lorem ip...&lt;/div&gt;&lt;/body&gt; - h1 -&gt; &lt;h1&gt;An Interesting Title&lt;/h1&gt; - div -&gt; &lt;div&gt;Lorem Ipsum dolor...&lt;/div&gt; 因此对于这个实例，bs.h1、bs.html.body.h1、bs.body.h1、bs.html.h1，这四个的结果是相同的。 对于BeautifulSoup函数，第一个参数是指定的HTML文本，第二个参数是为了选择不同的解析器。其他的还有lxml、html5lib等，可以自行查询其利弊。 连接的可靠性与处理异常网络是混乱的。数据格式很差，网站崩溃，关闭标签丢失。最令人沮丧的经历之一在web抓取运行，在你睡觉的时候来抓取数据，在第二天却发现爬虫因为一些意想不到的错误数据格式而停止执行。在这种情况下，你可能会想咒骂创建网站的开发人员的名字(以及格式奇怪的数据)，但是你真正应该责备的是您自己，因为你一开始就没有预料到异常。 爬虫的第一步，就可能会有异常出现： 1html = urlopen('http://www.pythonscraping.com/pages/page1.html' 在服务器上找不到该页面(或者检索时出错)。 找不到服务器 HTTPError第一种情况，将返回一个HTTPerror，可能是404 Page Not Found，也可能是500 Internal Server Error等等。在所有这些情况下，urlopen函数都会抛出通用异常HTTPError，具体解决办法如下： 12345678910from urllib.request import urlopenfrom urllib.error import HTTPErrortry: html = urlopen('http://www.pythonscraping.com/pages/page1.html')except HTTPError as e: print(e) # return null, break, or do some other "Plan B"else: # program continues. Note: If you return or break in the # exception catch, you do not need to use the "else" statement 如果返回HTTP错误代码，程序现在打印错误，并且不执行else语句下程序的其余部分。 URLErrorno server如果根本找不到服务器(例如，”http://www.pythonscraping.com“ 宕机了，或者URL输入错误)，urlopen将抛出一个URLError。这表明根本无法访问任何服务器，而且由于远程服务器负责返回HTTP状态码，不能抛出HTTPError，必须捕获更严重的URLError。你可以添加一个检查，看看是不是这样: 123456789101112131415161718192021222324252627from urllib.request import urlopenfrom urllib.error import HTTPErrorfrom urllib.error import URLErrortry: html = urlopen('https://pythonscrapingthisurldoesnotexist.com')except HTTPError as e: print(e)except URLError as e: print('The server could not be found!')else: print('It Worked!') output:The server could not be found!# be compared with HTTPError# ”http://www.pythonscraping.com“ works well but no page1000try: html = urlopen('http://www.pythonscraping.com/pages/page1000.html')except HTTPError as e: print(e) # this line runsexcept URLError as e: print('The server could not be found!')else: print('It Worked!')output:HTTP Error 404: Not Found no tag当然，如果从服务器成功检索到页面，仍然存在页面上的内容不完全符合你的预期的问题。每次访问BeautifulSoup对象中的标记时，添加一个检查以确保标记确实存在是明智的。如果你试图访问一个不存在的标签，BeautifulSoup将返回一个没有对象。问题是：试图访问None对象本身上的标记将导致抛出AttributeError。 print(bs.nonExistentTag)，其中，nonExistentTag是一个虚构的标记，而不是BeautifulSoup函数的真实名称。返回一个None对象。这个对象是完全合理的处理和检查。如果不检查它，而是继续尝试在None对象上调用另一个函数，print(bs.nonExistentTag.someTag)就会出现问题，如下所示: 1AttributeError: 'NoneType' object has no attribute 'someTag' 对于no tag的这两种情况，最简单的处理方式： 123456789try: badContent = bs.nonExistingTag.anotherTagexcept AttributeError as e: print('nonExistingTag was not found')else: if badContent == None: print ('anotherTag was not found') else: print(badContent) 对每个错误的检查和处理一开始看起来确实很费力，但是很容易在代码中添加一些重组，从而降低编写的难度(更重要的是，降低阅读的难度)。例如，这段代码是我们用稍微不同的方式编写的相同的scraper: 12345678910111213141516171819from urllib.request import urlopenfrom urllib.error import HTTPErrorfrom bs4 import BeautifulSoupdef getTitle(url): try: html = urlopen(url) except HTTPError as e: return None try: bs = BeautifulSoup(html.read(), 'html.parser') title = bs.body.h1 except AttributeError as e: return None return titletitle = getTitle('http://www.pythonscraping.com/pages/page1.html')if title == None: print('Title could not be found')else: print(title) 在本例中，将创建一个getTitle函数，该函数将返回页面的标题，如果检索有问题，则返回一个None对象。在getTitle中，检查HTTPError，就像前面的示例一样，并将两个BeautifulSoup封装在一个try语句中。可以从这两行抛出AttributeError(如果服务器不存在、html将是一个None对象、html.read()将抛出AttributeError)。实际上，可以在一个try语句中包含任意多行，或者完全调用另一个函数，这是可以做到的。 以下为测试 12345678910111213141516171819202122232425262728293031from urllib.request import urlopenfrom urllib.error import HTTPErrorfrom urllib.error import URLErrorfrom bs4 import BeautifulSoupdef getTitle(url): try: html = urlopen(url) except URLError as e: return e except HTTPError as e: return e try: bs = BeautifulSoup(html.read(), 'html.parser') title = bs.body.h1 except AttributeError as e: return e return titletitle = getTitle('http://www.pythonscraping.com/pages/page1.html')print(title)output:&lt;h1&gt;An Interesting Title&lt;/h1&gt;title = getTitle('http://www.pythonscraping11111.com/pages/page1.html')print(title)output:&lt;urlopen error [Errno 11001] getaddrinfo failed&gt;title = getTitle('http://www.pythonscraping.com/pages/page10000.html')print(title)output:HTTP Error 404: Not Found]]></content>
      <categories>
        <category>Web-Scraping</category>
      </categories>
      <tags>
        <tag>Web-Scraping</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MaOEA/IGD]]></title>
    <url>%2F2019%2F03%2F29%2Fmoeaigd%2F</url>
    <content type="text"><![CDATA[这个还是关于IGD-indicator的多目标函数优化问题，多学学，长长见识。 IGD Indicator-based Evolutionary Algorithm for Many-objective Optimization Problems Yanan Sun, Member, IEEE, Gary G. Yen, Fellow, IEEE, and Zhang Yi, Fellow, IEEE Nadir Point可以分为如下三种：usurface-to-nadir, edge-to-nadir, and extremepoint-to-nadir。时间有限，没有细看引用的论文。 论文中定义了nadir point、worst point、ideal point。 对于m维目标函数 $y^{ext}_1,..,y^{ext}_m$ ， 使 $y^{ext}_i = f(x^{ext}_i) \ and \ x^{ext}_i = argmax_xf_i(x)$. nadir point as $z^{nad}_i = f_i(x_i^{ext})$ . worst point as $z^{w}_i = \max f_i(x)$ . ideal point as $z^*_i = \min f_i(x)​$. 这三个点的区别可以用下图形象的表示出来： 并且在本文中，所定义的极端点如下： z^{nad}_i = \min|f_i(x)| + \lambda \sum_{j=1,j \ne i}^m (f_j(x))^2其中，$\lambda​$ 大于 1。具体样子如下： A与B点为极端点extreme points，C与D点为坏点worse ponits。其中当最小化 $|f_1(x)|+\lambda(f_2(x))^2$ 时， 因为 $\lambda$ 大于 1$，所以 (f_2(x))^2$ 具有更高的优先级，解会在线段BC上，又因为要使 $|f_1(x)|$ 最小，因此B点为极端点。另一个维度同理获得。 具体算法： $IGD^+-EMOA$先介绍一下IGD： IGD =\frac{ \sum_{p \in p^*} dist(p,PF)}{|p^*|}其中，$p^*​$为参考点，$dist(p,PF)​$ 为 p 到离 PF 最近的个体 $y​$ 的欧式距离，$d(p,y)=\sqrt{\sum_{j=1}^m(p_j-y_j)^2}​$。 而 $IGD^+$ 则是在 $d(p,y)$做出改变： d(p,y)=\sqrt{\sum_{j=1}^m\max(y_j-p_j,0)^2}翻译一下：在求平方和时，仅考虑个体比参考点数字大(性能差)的维度。 产生一致性点和NSGA-III不同，NSGA-III是归一化了种群的每一个个体，使极端点形成的平面在各个轴上的截距均为1，总结来说，就是一致性点不变，而改变个体。 此算法相反，修改了每一个一致性点的尺度，种群的每一个个体不变，以此来适应个体。 分配等级与近似距离the rank values are used to distinguish the proximity of the solutions to the Utopian PF from the view of reference points the proximity distances are utilized to indicate which individuals are with better convergence and diversity in the sub-population in which the solutions are with the same rank values. assign rank等级分为三种：$r_1,r_2,r_3$.并且都是个体与参考点 $p^*$ 之间的比较关系。 $r_1​$ ：个体 $s​$ 点至少支配 $p^*​$ 中的一个解。 $r_2$ ：个体 $s$ 点与所有的 $p^*$ 都是非支配关系。 $r_3​$ ：个体 $s​$ 点受 $p^*​$ 部分支配，另一部分的 $p^*​$ 与 $s​$ 非支配。 其中，$p^*$ 类似于下图这种，但要经过各个维度的变换来适应的当前种群。那么在这个空间中，任意取出一点，一定可以满足上面三种中的一个，并且可以直观的看到，优先级：$r_1 &gt; r_2 &gt; r_3$。 具体的说，如果一个最小问题的PF是一个超平面，那么Utopian PF显然等于PF。结果，位于PF的pareto-optimal解全都非支配于从Utopian PF抽样取出的参考点。又由上面所定义的那样，可知pareto-optimal都是 $r_2$。同理，对于convex PF 都是 $r_1$。对于concave PF 都是 $r_3$。 assign proximity distance就像上面所说那样，proximity distance是在 rank 相同的前提下来区分个体的好坏(收敛性)。并定义： $d^i_j$ 是第 $i$ 个个体，对第 $j$ 个参考点的距离。因此 $d$ 矩阵的尺寸为: q x k，(q个种群，k个参考点) 对于第 $i$ 个个体，对第 $j$ 个参考点: r_1 \rightarrow d^i_j = -\sqrt{\sum_{l=1}^m(f_l(x^i)-(p^*)^j_l)^2}\\ r_2 \rightarrow d^i_j = \sqrt{\sum_{l=1}^m\max (f_l(x^i)-(p^*)^j_l,0)^2}\\ r_3 \rightarrow d^i_j = \sqrt{\sum_{l=1}^m(f_l(x^i)-(p^*)^j_l)^2}等级1、3很好理解，解释一下为何2是这样的，如下图： $x^1,x^2,x^3$ 都是 $r_2$(非支配于那三个参考点)，如果单纯的计算欧式距离，那么可以看出 $x^1$ 是最好的解，但是直观上来看，$x^2$ 更有前景收敛于PF。但如果 $r_2$ 那种计算方式，便可得到 $x^2$ 更优。 总结来说，越小的proximity distance表现了更好的估计当待优化的PF未知时。具体算法流程如下： 后代产生Step 1：从当前种群上填充基因池直至满 Step 2：从基因池中选择两个父代，并且从基因池中把他们删除 Step 3：用所选择的父代通过 SBX 操作去产生后代 Step 4：在所产生的后代中变异 Step 5：重复Steps 2-4直至基因池满 具体算法如下： 注意到，其中SBX与多项式变异也有一定的要求。 Generally, two ways can be employed to solve this problem. One is the mating restrictionmethod to limit the offspring to be generated by the neighbor solutions. The other one is to use SBX with a large distribution index. 环境选择算法流程如下： 其中11行：找到A个个体，这些个体满足整体对于参考点 $r$ 有最小的proximity distance，需要一个 linear assignment problem(LAP)。 讨论选择压力的损失是传统的MOEAs解决MaOPs的主要问题，因为传统的个体间的支配比较会给出很大部分的非支配解集。在所提出的算法中，所有个体间的支配关系与通过IGD来计算的所需的参考点相比较。可是，在PF中均匀分布的参考点很难获得。基于此，就在Utopian PF中均与采样出一些点来。而已，为了解决因为参考点不准确的问题，基于它们对所估计出的参考点的支配关系而设计了三种计算距离的方法。我们希望，越小的proximity distance意味着对应的个体有更好的估计。特别地，如果等级为 $r_2$ 的个体，仍然与 $r_1$ 和 $r_3$ 就算距离的方式相同，那么收敛性就会损失。 代码代码最先不断的循环找到nadir point 12345678910DNPE = Global.ParameterSet(100*Global.N);while Global.NotTermination(Population) &amp;&amp; Global.evaluated &lt; DNPE Offspring = GA(Population(randi(end,1,Global.N)),&#123;0.9,20,1,20&#125;); % Off = GA(P,&#123;proC,disC,proM,disM&#125;) dis = distribution index Population = [Population,Offspring]; [~,rank] = sort(Fitness(Population.objs),1); Population = Population(unique(rank(1:ceil(Global.N/Global.M),:)));end% --------------------------------------------% 可以看到：交叉的概率0.9，交叉的参数20，变异的概率1，变异的参数20，非常大的数值了 种群依次为：]]></content>
      <categories>
        <category>indicator-based</category>
      </categories>
      <tags>
        <tag>MOEA</tag>
        <tag>indicator</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NSGA-III]]></title>
    <url>%2F2019%2F03%2F28%2Fnsgaiii%2F</url>
    <content type="text"><![CDATA[这个算法是慕名而来，之前学习的两个算法都用到了一致性点作为参考点，而这个算法也是比较经典的算法，就来学习学习。 An Evolutionary Many-Objective Optimization Algorithm Using Reference-point Based Non-dominated Sorting Approach, Part I: Solving Problems with Box Constraints Kalyanmoy Deb, Fellow, IEEE and Himanshu Jain 可以看到还是先一层一层的留下(收敛性)，如果数量有多余的，需要从加入一些特殊的规则，保持住多样性。多样性的话，就要有对应的参考点，然后利用个体与参考点的关系，选择出更有前景的个体，直至个体数到规定个数。 参考点选择 参考点就是在以ideal point为原点，在m维空间上，确定一个m-1的平面，均匀分布的点，个数可参考如下公式，用之前学过的概率论的格式，就是那个 $C$ 的样子，一般的问题是已知 $m$ (目标函数个数)、种群数，我要找到与种群数与相接近的 $H$。此时一下公式的 $p$ 便为未知量， $p$ 在几何中的意义就是，把坐标平均分成 $p$ 份，上图 $p=4$， $m=3$，$H=15$。 H =\left( \begin{matrix} M + p-1 \\ p \end{matrix} \right)=\left( \begin{matrix} M + p-1 \\ M - 1 \end{matrix} \right) = C^{p}_{M+p-1}解释：这个用到了高中学过的小球问题，有 $p$ 个不作区分的小球放到 $m$ 个作区分的篮子里，篮子可以可以有多少种情况，数学公式为： f_1 + f_2+... + f_m = p \\ f_i \geq 0 \ and \ f_i \in Z,\ \forall i \in [1,m]从而也可以转化为： f_1 + f_2+... + f_m = p + m \\ f_i \geq 1 \ and \ f_i \in Z,\ \forall i \in [1,m]可以想象有 $p+m$ 个小球排成一排，因为每个篮子里均要有小球，因此这些小球形成的间隔共有 $p +m -1$ 个，共放 $m-1$个隔板，因此会得出结果。 平面确定这样如果确定了平面，我们可以求得一致性点，那么如何求出这个平面。 以 $m=3$ 为例，也就是说，通过某种规则，找到这三个点，$z^{1,max},z^{2,max},z^{2,max}$ 组成的平面来找一致性点。再求出与坐标轴形成的截距：$a_1,a_2,a_3$ 。 下图为实例：黑色的为 $z^{1,max},z^{2,max},z^{2,max}$ 。 那 $z^{1,max},z^{2,max},z^{2,max}$ ,怎么求呢，先介绍一个函数，在MOMBI-II也用到了，但是策略不同： ASF(x,W) = \max_{i=1}^{M}f'_i(x)/w_i \quad for \ x \in S_t理解：所谓极端点就是找到在一个维度上很大，在另外两个维度上的值很小的个体。 假设我要求出 $z^{1,max}$ ，我就在每一个维度上除以1、1e6、1e6。这样我就可以抽出另两个维度的目标值，并取出最大的那个目标值，为什么要取出最大的呢？因为我要找到除了第一维度另两个维度都很小的值，第一次要取出最大的，再对每一个个体的最大的那个取出最小的，那么这个个体的另一个目标值(除了第一维度的那个目标值)肯定会更小，这样才能保证另外两个维度上的值很小。具体操作如下line-4： 翻译一下就是： 对于每一个维度操作 找到此维度最小的值 此维度上都减掉它 求出$z^{j,max}$ 计算截距 每一个点都要$\frac{f_i(x)-z_i^{min}}{a_i - z_i^{min}}$ 这步相当于把这个超平面的截距都变成成(1,…,1) 那么我知道了这三个极端点，如何求出截距呢？如下： 以三维为例： 平面方程式为：$ax + by + cz + d = 0$ 。 我想求的截距便为： \left[ \begin{matrix} -d/a \\ -d/b \\ -d/c \end{matrix} \right]此时我们已知三个点坐标，也就可以知道，下面的方阵： \left[ \begin{matrix} x_{11} & x_{12} & x_{13} \\ x_{21} & x_{22} & x_{23} \\ x_{31} & x_{32} & x_{33} \end{matrix} \right] \left[ \begin{matrix} a \\ b \\ c \end{matrix} \right] =\left[ \begin{matrix} -d \\ -d \\ -d \end{matrix} \right]继续化简： \left[ \begin{matrix} x_{11} & x_{12} & x_{13} \\ x_{21} & x_{22} & x_{23} \\ x_{31} & x_{32} & x_{33} \end{matrix} \right] \left[ \begin{matrix} -a/d \\ -b/d \\ -c/d \end{matrix} \right] =\left[ \begin{matrix} 1 \\ 1 \\ 1 \end{matrix} \right]因此： \left[ \begin{matrix} -a/d \\ -b/d \\ -c/d \end{matrix} \right] =inv(\left[ \begin{matrix} x_{11} & x_{12} & x_{13} \\ x_{21} & x_{22} & x_{23} \\ x_{31} & x_{32} & x_{33} \end{matrix} \right])\left[ \begin{matrix} 1 \\ 1 \\ 1 \end{matrix} \right] =\left[ \begin{matrix} x_{11} & x_{12} & x_{13} \\ x_{21} & x_{22} & x_{23} \\ x_{31} & x_{32} & x_{33} \end{matrix} \right] \backslash \left[ \begin{matrix} 1 \\ 1 \\ 1 \end{matrix} \right]然后每一位均取倒数即可。高维度($m \geq 3$)的依此类推。 注意，如果矩阵E的秩小于m，那么这m个极限点就不能构成一个m维的超平面。甚至即使超平面能够建立，也可能在某些方向上得不到截距或某些截距 $a_i$ ，不满足 $a_i &gt; z^*_i$。在所有上述情形下，对于每一个 $i \in \{ i,…,m\}$ ，$z^{nad}_i$设置维 $S_t$ 中的非支配解在目标 $f_i$ 上的最大值。 在MATLAB代码中，如下： 12345678910Extreme = zeros(1,M);w = zeros(M)+1e-6+eye(M);for i = 1 : M [~,Extreme(i)] = min(max(PopObj./repmat(w(i,:),N,1),[],2));endHyperplane = PopObj(Extreme,:)\ones(M,1);a = 1./Hyperplane;if any(isnan(a)) a = max(PopObj,[],1)';end 个体对参考点链接效果如下： 算法流程： 此时这个超平面的各各截距均为1，每一个个体也都适应性拉伸，此时原点与一致性点连接所形成的射线，对于每一个 $S_t$ 个体，找到离它最近的射线，测量距离，如上上图，并对这些个体记录那个参考点，距离是多少。 并且记录 $P_{t+1} = S_t/F_l$ 在每个参考点周围的个数。这很重要！！ j \in Z^r:\rho_j = \sum_{S \in S_t/F_l}((\pi(s)=j)?1:0)选择机制流程如下： 为看着直观，下图为，$S_t,P_{t+1},F_l$ 之间的关系，但仅仅是为了理解，作图很不严谨！ 记录 $P_{t+1} = S_t/F_l$ 在每个参考点周围的个数。这很重要！！ j \in Z^r:\rho_j = \sum_{S \in S_t/F_l}((\pi(s)=j)?1:0) 找到计数最少的参考点集，并随机选择一个 —— 可能因为少的地方更需要开拓空间 找到离此参考点最近的那些 $F_l$ 中个体 —— 更能保证最后个体的一致性 如果有 $F_l$ 这些个体 —— 存在添加的可能性，不然去哪加新个体 这个参考点周围没有 $P_{t+1}$ 中的个体 —— 原来的个体中没有在这参考点附近的 选择 $F_l$ 中离此参考点最近的个体 —— 当然要找离它最近的 这个参考点周围有 $P_{t+1}$ 中的个体 —— 原来的个体中有在这参考点附近的 随便选一个$F_l$ 中在此参考点周围的个体 —— 那就随便找好啦 更新参数 没有 $F_l$ 这些个体 —— 不存在添加的可能性 以后不会考虑这个参考点了 —— 当然不会管这个参考点 重复以上操作直至选择的数量够了。注意，添加进去的点，就会默认在 $P_{t+1}$ 中了。]]></content>
      <categories>
        <category>MOEA</category>
      </categories>
      <tags>
        <tag>MOEA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MOMBI-II]]></title>
    <url>%2F2019%2F03%2F21%2Fmombiii%2F</url>
    <content type="text"><![CDATA[本想在复现的上一个算法AR-MOEA中加上一点小修改，我思来想去觉得每一个步骤都无懈可击。。。于是我意识到可能是论文读的太少，于是又选了一个indicator-based的多目标优化算法学习一下——MOMBI-II，这个算法过程较AR-MOEA比较简单，此算法选择的indicator是R2但效果也不错，学习学习。 Improved Metaheuristic Based on the R2 Indicator for Many-Objective Optimization Raquel Hernandez Gomez, Carlos A. Coello Coello 规定the ideal objective vector：$z^*_i = \min_{\vec{x}}f_i(\vec{x})​$ the nadir objective vector: $z^{nad}_i = \max_{P^*}f_i(\vec{x})$ indicator: R2 R2(A,U) = \frac{1}{U}\sum_{u \in U}u^*(A)其中，$u^*(A) = \min_{\vec{a} \in A} \{ u(\vec{a}) \}$，是在 $A$ 中最尤的效用值(utility value)。 一个测度叫做 achievement scalarizing function (ASF)： u_{asf}(\vec{v}:\vec{r},\vec{w}) = \max_{i \in \{1,...,m\} } \{\frac{|v_i - r_i|}{w_i} \}归一化： f'_i(\vec{x}) = \frac{f_i(\vec{x}) - z_i^{min}}{z_i^{max}-z_i^{min}} \\ \forall i \in \{1,...,m\}算法流程 代码借鉴了PlatEMO 1234567891011121314151617181920212223242526[alpha,epsilon,recordSize] = deal(0.5,0.001,5);%% Generate random population[W,N] = UniformPoint(N,M);Population = Initialization();% Ideal and nadir pointszmin = min(Population_objs,[],1);zmax = max(Population_objs,[],1);% For storing the nadir vectors of a few generationsRecord = repmat(zmax,recordSize,1);Archive= Population_objs;% For storing whether each objective has been marked for a few% generationsMark = false(recordSize,M);% R2 ranking procedure[Rank,Norm] = R2Ranking(Population_objs,W,zmin,zmax);%% Optimizationwhile Global.NotTermination(Population) MatingPool = TournamentSelection(2,N,Rank,Norm); Offspring = GA(Population(MatingPool)); Population = [Population,Offspring]; [Rank,Norm] = R2Ranking(Population_objs,W,zmin,zmax); [~,rank] = sortrows([Rank,Norm]); Population = Population(rank(1:Global.N)); Rank = Rank(rank(1:Global.N)); Norm = Norm(rank(1:Global.N)); [zmin,zmax,Record,Mark] = UpdateReferencePoints(Population_objs,zmin,zmax,Record,Mark,alpha,epsilon); R2Ranking.m 12345678910111213141516function [Rank,Norm] = R2Ranking(PopObj,W,zmin,zmax) N = size(PopObj,1); NW = size(W,1); %% Normalize the population PopObj = (PopObj-repmat(zmin,N,1))./repmat(zmax-zmin,N,1); %% Calculate the L2-norm of each solution Norm = sqrt(sum(PopObj.^2,2)); %% Rank the population Rank = zeros(N,NW); for i = 1 : NW ASF = max(PopObj./repmat(W(i,:),N,1),[],2); [~,rank] = sortrows([ASF,Norm]); [~,Rank(:,i)] = sort(rank); end Rank = min(Rank,[],2);end UpdateReferencePoints.m 12345678910111213141516171819202122232425function [zmin,zmax,Record,Mark] = UpdateReferencePoints(PopObj,zmin,zmax,Record,Mark,alpha,epsilon) z = min(PopObj,[],1); % z* znad = max(PopObj,[],1); zmin = min(zmin,z); Record = [Record(2:end,:);znad]; v = Record(end-1,:) - znad; % 前一轮的zmax减去当前的zmax mark = false(1,length(zmax)); if max(v) &gt; alpha % 如果差值大到一定程度，直接赋值 zmax = znad; else for i = 1 : length(zmax) % 对每一个目标函数上的维度操作 if abs(zmax(i)-zmin(i)) &lt; epsilon zmax(i) = max(zmax); % 如果在i-th维度上 zmax与新的zmin很接近，max(zmax)直接赋值到此维度上 mark(i) = true; elseif znad(i) &gt; zmax(i) zmax(i) = 2*znad(i) - zmax(i);% 如果在i-th维度上，当前种群最大的大于zmax(i) mark(i) = true; elseif v(i)==0 &amp;&amp; ~any(Mark(:,i)) % 如果在i-th维度上,与之前没有变：差值为0，并且 第i列Mark全为0 zmax(i) = (zmax(i)+max(Record(:,i)))/2; % 此维度上Record的最大值与原来的zmax取平均值 mark(i) = true; end end end Mark = [Mark(2:end,:);mark];end 过程理解Ranking其中主要的代码就是这个： 1234567Rank = zeros(N,NW);for i = 1 : NW ASF = max(PopObj./repmat(W(i,:),N,1),[],2); [~,rank] = sortrows([ASF,Norm]); [~,Rank(:,i)] = sort(rank);endRank = min(Rank,[],2); 可以看到max中便是开头介绍的 $u_{asf}$ 算法，公式： u_{asf}(\vec{v}:\vec{r},\vec{w}) = \max_{i \in \{1,...,m\} } \{\frac{|v_i - r_i|}{w_i} \} 首先遍历每一个一致性点W(i,:)，此时因为已经归一化，因此 $\vec{r} = \vec{0}$，用每一个个体点除一致性点向量($\vec{v}$)，因为在一个循环中，W(i,:)是不变的，因此相当于对每一维度的轴进行线性拉伸(点除)。 对得到的矩阵每一行取最大，翻译一下就是找到可以包含住此点的最小边长的立方体(假设三维，高维同理)，此立方体的边长就是 $\max_{i \in \{1,…,m\} } \{\frac{|v_i |}{w_i} \}$，也可以说拉伸后据原点的最大棋盘距离。 紧接着就是sortrows，翻译一下：先对ASF这个向量排序，如果相同的话，再按向量Norm排序。 再对上面的输出索引sort，翻译一下：对[ASF,Norm]进行离散化(ACM中术语-小弘说)，赋值成1~size(ASF,1)的整数值。如果假设数值越小越好，那于对第 i 列的向量，每一个个体都赋予一个等级 最后min(Rank,[],2)翻译一下：查看每一个个体的历史纪录，取它曾经最好(小)的一次。 有必要解释一下主函数里的这两步： 12[Rank,Norm] = R2Ranking(Population_objs,W,zmin,zmax);[~,rank] = sortrows([Rank,Norm]); 根据进化进程，Rank中会有大量的[1 1 1...2 2 2...]这种重复的元素，也就是说，对于[1...1]对应的个体来说，他们都再某个一致性点向量W(i,:)的结果中当过最最小，都“优秀”过。因此他们都是1，对于Rank中都是2的个体，同理。从这个角度来说，同为一个等级的个体都很好，但由于尺寸限制，可能不能都保留，这个时候便可以进一步比较他们到原点的(欧式)距离，对于minimize问题，当然越小越好，因此sortrows([Rank,Norm])。 update reference point这个我理解不了，只能复述一下代码过程，复述内容见上方的代码注释。]]></content>
      <categories>
        <category>indicator-based</category>
      </categories>
      <tags>
        <tag>MOEA</tag>
        <tag>indicator-based</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AR-MOEA]]></title>
    <url>%2F2019%2F03%2F21%2Farmoea%2F</url>
    <content type="text"><![CDATA[最近想要复现一个关于indicator-based的多目标优化算法，因此，选了一个容易入手的AR-MOEA算法，此算法，是由安徽大学的田野老师在2018年提出，选用的indicator是IGD。 An Indicator-Based Multiobjective Evolutionary Algorithm With Reference Point Adaptation for Better Versatility Ye Tian, Ran Cheng, Xingyi Zhang, Fan Cheng, and Yaochu Jin, Fellow, IEEE 算法规定定义：无贡献解 \nexists y \in Y \ satisfying \ dis(y,x') = \min_{x \in X} dis(y,x)其中，距离为欧式距离。例子如下图： 适应度为： IGD-NS(X,Y) = \sum_{y \in Y} \min_{x \in X} dis(y,x) + \sum_{x \in X^*} \min_{y \in Y} dis(y,x')符号规定： the population P contains the candidate solutions as final output the initial reference point set R is used to guarantee uniform distribution of the candidate solutions in P the archive A reflects the Pareto front and guides the reference point adaptation the adapted reference point set R‘ is used in the IGD-NS-based selection for truncating the population P 具体关系如下图： 算法伪代码 MatingSelection(P,R’)： 个体 p 的适应度，定义为： fitness_p = IGD-NS(P \backslash \{p\},R' ) 细节图示以下为我的个人想法与心得：声明此代码借鉴PlatEMO中的算法 主函数以下为例 1234567891011121314151617N = 100; % 种群个数D = 10; % 变量个数M = 3; % 目标个数name = 'DTLZ3'; % 测试函数选择，目前只有：DTLZ1、DTLZ2、DTLZ3[res,Population,PF] = funfun(); % 生成初始种群与目标值REF = UniformPoint(N,M); % 生成一致性参考解[Archive,RefPoint,Range] = UpdateRefPoint(res,REF,[]);PD_v = [];for i = 1:400 MatingPool = MatingSelection(Population,RefPoint,Range); %已修改 Offspring = GA(Population(MatingPool,:)); %已修改 Offspring_objs = CalObj(Offspring); [Archive,RefPoint,Range] = UpdateRefPoint([Archive;Offspring_objs([all(PopCon&lt;=0,2)],:)],REF,Range); [Population,Range] = EnvironmentalSelection([Population;Offspring],RefPoint,Range,N);endhold onplot3(PF(:,1),PF(:,2),PF(:,3),'g*') UniformPoint.m 此函数是产生一致性点，当参数如上图所示，那么，这些一致性点在目标空间中，分布如下： UpdateRefPoint.m，此算法就是根据目前的Archive，Poupulation和Reference points生成新的Archive与Reference points。 先要介绍一下AdjustLocation.m 图为此时刻下的调整之前的Reference Points：两个图是同一状态，只是视角不同 再加上蓝色的点，即为当前种群： 红色的点即为调整之后的Reference Points： 这么看可能会发现不了什么规律，其实根据公式也可以知道，如果开始时对所有点进行归一化，那么由原点连接每一个黑色的点，对应的调整后的点必定在这条射线上。就像算盘上的珠子一样，滑到与所有蓝色的点(当前种群)中与到射线最短的距离所对应的投影点上，也就是原论文中的$p \leftarrow argmin_{p \in P}||F(P)||sin(\vec{z^*r},F(p))$，如下图： (黄线穿过：原点-黑点-红点 ) 只画出部分射线： AdjustLocation解释完了，就容易理解RefPointAdaption.m了 注意一点，在RefPointAdaption.m中的Reference Points是一致性点，所以，应该是这样的： 先对当前解、Reference点进行归一化，简单地说就是为了让射线从原点出发。 把ReferencePoint根据当前种群Archive进行调整，也就是上图的黑点变红点。 更新 Archive： 删除重复和受支配的解(因为又添加了交叉变异的个体) 滑动每一个Reference point到Archive中离它最近的的个体周围(映射点)，并且把这些新的个体称为 $A^{con}$，这样可以使得大多数个体多多少少周围都有几个Reference point，当然有的个体可能周围一个都没有。 如果个数不够就要从剩下的Archive中来凑，找在离newAchieve夹角最小中所有最大的那个$argmax_{p \in A \backslash A’} \min_{q \in A’} arccos(F(p),F(q))$。我猜测是为了增大多样性。 更新Reference Points： 根据之前找到的$A^{con}$ ，把离这些$A^{con}$ 中最近的Reference Point(调整后的)，作为newReferencePoint。 如果个数不够就要从新产生的的newArchive中来凑。 把newReferencePoint根据当前种群Population进行调整。 结果如下： 蓝色为一致性点 绿色为真实PF 红色为AR-MOEA算法结果 算法分析 首先，它是用了IGD-indicator来计算每一个个体的适应度。其次，选用了Archive与ReferencePoint来一起维护收敛与一致性。期间只要有靠近新的ReferencePoint，就有很大的概率被留下来，R’也会不断的接近R，其中在那个平面的点，说明此参考点周围已经子代存在，而呈拱形的点便是从A’\A中选择出来的，随着种群进化过程，平面上的点会逐渐变多，拱形上的点逐渐减少，最后便会得出均匀且收敛性较好的解集。]]></content>
      <categories>
        <category>indicator-based</category>
      </categories>
      <tags>
        <tag>MOEA</tag>
        <tag>indicator</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[代码学习]]></title>
    <url>%2F2019%2F03%2F15%2Flearningofcode%2F</url>
    <content type="text"><![CDATA[最近在复现AR-MOEA算法，虽说是复现，但目前的想法是从PlatEMO中把代码抠出来，我大致的看了一下代码，里面的代码很简洁，其中通过一些函数调用矩阵操作，从而大大的减少了for循环的使用。因此，想要通过这次解构AR-MOEA算法，储备一些常用的Matlab函数。另外，PlatEMO真的是神器！复现的很多很多算法，和常用的一些测试函数等等，很巧的是，AR-MOEA算法和PlatEMO是同一作者，哈哈哈哈。 说明一点：源代码用了很多结构体的东西，我都拆解了一下。。。这个和之前发过的Matlab常用函数可能有所重复，暂时没有想好究竟属于哪一部分，但重要的不是先记录下来吗？ 初始化种群binary：12345678910111213141516171819randi ：生成**均匀分布**的伪随机整数。randi(imax)：产生一个位于(0,imax]之间的整数。randi(imax,n,m)：产生一个位于（0,imax]之间的n*m的矩阵，所有元素都是整数。randi([imin,imax],n,m)：产生一个位于[imin,imax]之间的n*m的矩阵，所有的矩阵元素都是整数。&gt;&gt; randi(10)ans = 8 &gt;&gt; randi(5,2,3)ans = 1 4 3 4 5 1 &gt;&gt; randi([0,1],3,4)ans = 1 1 0 0 1 1 0 0 0 0 1 1 permutation12345678910111213rand：生成均匀分布的伪随机数。分布在（0~1）之间rand(m,n)生成m行n列的均匀分布的伪随机数&gt;&gt; rand(3,4)ans = 0.8328 0.7083 0.7038 0.5311 0.4554 0.3543 0.6873 0.4308 0.8578 0.1437 0.0276 0.8191 &gt;&gt; sort(ans,2)ans = 0.5311 0.7038 0.7083 0.8328 0.3543 0.4308 0.4554 0.6873 0.0276 0.1437 0.8191 0.8578 others1234567891011unifrnd(A,B)：A，B，ans均为同纬度矩阵，以A(i,j)为下界与B(i,j)为上界，均匀分布产生ans(i,j)。&gt;&gt; N = 5;&gt;&gt; lower = zeros(1,4);&gt;&gt; upper = ones(1,4);&gt;&gt; unifrnd(repmat(lower,N,1),repmat(upper,N,1))ans = 0.0145 0.4117 0.6161 0.6673 0.0026 0.5274 0.1487 0.3502 0.5629 0.2023 0.9411 0.8544 0.4124 0.6985 0.0984 0.1186 0.0801 0.0631 0.5249 0.7846 计算函数值此样例为：DTZL1，形式如下： f_1(x)=(1+g(x))x_1x_2 \\f_2(x)=(1+g(x))x_1(1-x_2) \\f_3(x)=(1+g(x))(1-x_1) \\where \ g(x)=100(n-2) +100\sum_{i=3}^{n}{\{(x_i-0.5)^2-cos[20\pi (x_i-0.5)]\}} \\x=(x_1,...,x_n)^T \in [0,1]^n,n=10比较简单的写法： 1234567891011121314ha = [];for ii = 1:N x = Population(ii,:); f=[]; sum=0; for i=3:D sum = sum+((x(i)-0.5)^2-cos(20*pi*(x(i)-0.5))); end g=100*(D-2)+100*sum; f(1)=(1+g)*x(1)*x(2); f(2)=(1+g)*x(1)*(1-x(2)); f(3)=(1+g)*(1-x(1)); ha(ii,:) = f / 2;end 高阶一点的写法： 123456M 为目标函数个数D 为变量维度g = 100*(D-M+1+sum((PopDec(:,M:end)-0.5).^2-cos(20.*pi.*(PopDec(:,M:end)-0.5)),2));PopObj = 0.5*repmat(1+g,1,M).*fliplr(cumprod([ones(N,1),PopDec(:,1:M-1)],2)).*[ones(N,1),1-PopDec(:,M-1:-1:1)];PopDec(:,M:end)-0.5).^2 = (x_i - 0.5)^2 ,i = 3:n 其中，cumprod 这个是第一次见： 123456789101112131415161718192021222324&gt;&gt; A = [1 2 3 4 5];&gt;&gt; B = cumprod(A) % A为向量连乘的形式B = 1 2 6 24 120 &gt;&gt; A = [1 4 7; 2 5 8; 3 6 9]A = 1 4 7 2 5 8 3 6 9&gt;&gt; B = cumprod(A) % 对矩阵A做列累积相乘B = 1 4 7 2 20 56 6 120 504 &gt;&gt; A = [1 3 5; 2 4 6] % 对矩阵A做行累积相乘A = 1 3 5 2 4 6&gt;&gt; B = cumprod(A,2)B = 1 3 15 2 8 48 fliplr 将矩阵A的列绕垂直轴进行左右翻转 matabc如果A是一个行向量，fliplr(A)将A中元素的顺序进行翻转。如果A是一个列向量，fliplr(A)还等于A。 1234567891011&gt;&gt; A =[1 4;2 5;3 6]A = 1 4 2 5 3 6&gt;&gt; fliplr(A)ans = 4 1 5 2 6 3 生成一致性参考点如下图： b = nchoosek(n,k) 返回二项式系数，定义为 n!/((n–k)! k!)。这就是从 n 项中一次取 k 项的组合的数目。说白了就是概率论里的 $C_n^k$ 。 C = nchoosek(v,k) 返回一个矩阵，其中包含了从向量 v 的元素中一次取 k 个元素的所有组合。矩阵 C 有 k 列和 n!/((n–k)! k!) 行，其中 n 为 length(v)。 1234567891011&gt;&gt; nchoosek(5,3)ans = 10&gt;&gt; v = 2:2:10;C = nchoosek(v,4) % 在[2 4 6 8 10] 这5个元素中取出4个的具体例子，列举出来C = 2 4 6 8 2 4 6 10 2 4 8 10 2 6 8 10 4 6 8 10 并且通过几行代码，即可生成均匀的参考点： 123456H1 = 1;while nchoosek(H1+M,M-1) &lt;= N H1 = H1 + 1;endW = nchoosek(1:H1+M-1,M-1) - repmat(0:M-2,nchoosek(H1+M-1,M-1),1) - 1;W = ([W,zeros(size(W,1),1)+H1]-[zeros(size(W,1),1),W])/H1; 交配池pdist2函数是求两个点集的欧式距离(默认) 1Cosine = 1 - pdist2(PopObj,RefPoint,'cosine'); % 此距离为夹角余弦距离,因为函数自带了 1-Cosine，因此要再减回去。 cosine夹角余弦距离： d_{s,t} = 1 - \frac{x_sx_t'}{||x_s||_2 . ||x_t||_2}true 生成logical的数组 12345K&gt;&gt; true(1,5)ans = 1×5 logical 数组 1 1 1 1 1 锦标赛选择varargin 表示用在一个函数中，输入参数不确定的情况，这增强了程序的灵活性。 例如：function g=fun(f,varargin) 然后在程序中使用时，假如在调用函数时，intrans(f,a,b,c)，那么：varargin{1}=a,varargin{2}=b,varargin{3}=c cellfun 是对cell进行操作的函数 12345678910&gt;&gt; C = &#123;1:10, [2; 4; 6], []&#125;&gt;&gt; cellfun(@mean, C)ans = 5.5000 4.0000 NaN &gt;&gt; days = &#123;'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday'&#125;;&gt;&gt; cellfun(@(x) x(1:3), days, 'UniformOutput', false)ans = 1×5 cell 数组 'Mon' 'Tue' 'Wed' 'Thu' 'Fri' sortrows 默认依据第一列的数值按升序移动每一行，如果第一列的数值有相同的，依次往右比较。例： 就是说，把每一行看作整体，先从第一列升序排列，遇到相同的，就比较第二列按升序，如果还有相同的就比较第三轮升序,…….依次 123456789101112131415A = 95 45 92 41 13 1 84 95 7 73 89 20 74 52 95 7 73 5 19 44 20 95 7 40 35 60 93 67 76 61 93 81 27 46 83 76 79 91 0 19 41 1&gt;&gt; sortrows(A)ans = 76 61 93 81 27 46 83 76 79 91 0 19 41 1 95 7 40 35 60 93 67 95 7 73 5 19 44 20 95 7 73 89 20 74 52 95 45 92 41 13 1 84 连续用两个sort ，第一次见到这种操作，很有意思，把一组数进行替换，替换成他在这组数中的升序排名。如果原向量是适应度，那么就可以替换成1~N的序号 12345678910&gt;&gt; a = [1.1 3.1 5.1 7.1 4.1 2.1 6.1]&gt;&gt; [~,i] = sort(a)i = 1 6 2 5 3 7 4&gt;&gt; [~,ii] = sort(i)ii = 1 3 5 7 4 2 6% 原代码&gt;&gt; [~,rank] = sortrows([varargin&#123;:&#125;]);&gt;&gt; [~,rank] = sort(rank); 使用randi来进行随机选择 K 元锦标赛的序号 1Parents = randi(length(varargin&#123;1&#125;),K,N) % N 是种群个数 先通过rank(Parents)来通过序号找到对应的适应度值，用min 来找到每一列的最小值(函数输入时对适应度去负了) 1[~,best] = min(rank(Parents),[],1); 最后，best是一系列1、2组合的矩阵，再通过一下变换可求出结果 1index = Parents(best+(0:N-1)*K); 更新参考点unique 对向量去重，并且从小到大排序输出。 ismember 1234567891011121314&gt;&gt; a=[1 2 3 4 5];&gt;&gt; b=[3 4 5 6 7];&gt;&gt; c=[2 4 6 8 10];&gt;&gt; ismember(a,b) % a中的每一个元素是否在b中ans = 1×5 logical 数组 0 0 1 1 1 &gt;&gt; [lia,lib]=ismember(a,c) % a在lib中对应位置在c上的索引，如有多个，取第一个lia = 1×5 logical 数组 0 1 0 1 0lib = 0 1 0 2 0 交叉操作binary： 12345678% One point crossoverk = repmat(1:D,N,1) &gt; repmat(randi(D,N,1),1,D);k(repmat(rand(N,1)&gt;proC,1,D)) = false;Offspring1 = Parent1;Offspring2 = Parent2;Offspring1(k) = Parent2(k);Offspring2(k) = Parent1(k);Offspring = [Offspring1;Offspring2]; permutation： 1234567% Order crossoverOffspring = [Parent1;Parent2];k = randi(D,1,2*N);for i = 1 : N Offspring(i,k(i)+1:end) = setdiff(Parent2(i,:),Parent1(i,1:k(i)),'stable'); Offspring(i+N,k(i)+1:end) = setdiff(Parent1(i,:),Parent2(i,1:k(i)),'stable');end 其他： 12345678910% Simulated binary crossoverbeta = zeros(N,D);mu = rand(N,D);beta(mu&lt;=0.5) = (2*mu(mu&lt;=0.5)).^(1/(disC+1));beta(mu&gt;0.5) = (2-2*mu(mu&gt;0.5)).^(-1/(disC+1));beta = beta.*(-1).^randi([0,1],N,D);beta(rand(N,D)&lt;0.5) = 1;beta(repmat(rand(N,1)&gt;proC,1,D)) = 1;Offspring = [(Parent1+Parent2)/2+beta.*(Parent1-Parent2)/2 (Parent1+Parent2)/2-beta.*(Parent1-Parent2)/2]; 变异操作binary： 123% Bitwise mutationSite = rand(2*N,D) &lt; proM/D;Offspring(Site) = ~Offspring(Site); permutation： 12345678910% Slight mutationk = randi(D,1,2*N);s = randi(D,1,2*N);for i = 1 : 2*N if s(i) &lt; k(i) Offspring(i,:) = Offspring(i,[1:s(i)-1,k(i),s(i):k(i)-1,k(i)+1:end]); elseif s(i) &gt; k(i) Offspring(i,:) = Offspring(i,[1:k(i)-1,k(i)+1:s(i)-1,k(i),s(i):end]); endend 其他： 1234567891011121314 % Polynomial mutationLower = repmat(lower,2*N,1);Upper = repmat(upper,2*N,1);Site = rand(2*N,D) &lt; proM/D;mu = rand(2*N,D);temp = Site &amp; mu&lt;=0.5;Offspring = min(max(Offspring,Lower),Upper);Offspring(temp) = Offspring(temp)+(Upper(temp)-Lower(temp)).*((2.*mu(temp)+(1-... 2.*mu(temp)).*(1-(Offspring(temp)-Lower(temp))./... (Upper(temp)-Lower(temp))).^(disM+1)).^(1/(disM+1))-1);temp = Site &amp; mu&gt;0.5; Offspring(temp) = Offspring(temp)+(Upper(temp)-Lower(temp)).*(1-(2.*(1... -mu(temp))+2.*(mu(temp)-0.5).*(1-(Upper(temp)-... Offspring(temp))./(Upper(temp)-Lower(temp))).^(disM+1)).^(1/(disM+1))); hist函数： hist(X,Y)：X是一个事先给定的区间划分，统计Y在X这个区间划分下的个数，划分规则如下： 12345678910111213141516171819&gt;&gt; a = randi(5,1,10)a = 2 1 4 2 1 2 4 2 3 1&gt;&gt; k = hist(a,1:6)k = 3 4 1 2 0 0 b = [2.6 1 4 2 1 2 4 2 3 1];&gt;&gt; k = hist(b,1:6)k = 3 3 2 2 0 0 &gt;&gt; a = [2.5 -10 4 2 1 2 4 2 3 1];&gt;&gt; k = hist(a,1:6)k = 3 4 1 2 0 0 % ---------------------------------------------------------------- % 可以看到随机产生了1x10的[1~5]的整数向量a，那么函数结果为分别在:% (-inf 1.5],(1.5 2.5],(2.5 3.5],(3.5 4.5],(4.5 5.5],(5.5 inf) 用处： 1234567PopObj = [PopObj1;PopObj2];Distance = pdist2(PopObj,Ref); [d,pi] = min(Distance,[],2);rho = hist(pi(1:N_PopObj1),1:N_Ref);% -----------------------------------------------------------------% pi为PopObj到哪个Ref最近的index，rho即为离PopObj1种群最近的哪个Ref的对于所有Ref的计数量，% 可用于NSGA-III中]]></content>
      <categories>
        <category>matlab</category>
      </categories>
      <tags>
        <tag>MOEA</tag>
        <tag>matlab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[QIs for All Quality Aspects]]></title>
    <url>%2F2019%2F03%2F06%2Fallaspects%2F</url>
    <content type="text"><![CDATA[一方面一拖再拖，一方面后面的 indicators 很多都是单独的一整篇论文，并非后面的一小部分，阅读并理解起来比较吃力，也有很多地方只看了算法步骤，而没有细看具体推导与证明，其中一篇，记忆很深刻，姚老师的 DoM-indicator 行文很严谨，并且断断续续看了四天才大概理解。 这类中的质量指标在文献中最常用，因为它们涵盖了解决方案集质量的所有四个方面。表2中的75-100项列出了这些QIs。一般可分为两类:基于距离的QIs(项目75-91)和基于容量的QIs(项目92-100)。 distance-based QIs： volume-based QIs： Distance-based QIs基于距离的QIs的基本思想是测量PF到所考虑解集的距离。因此，需要一个能很好地表示PF的参考集(reference set)。只有接近参考集的每个成员的解集才能有一个好的评估值，从而反映所有质量方面的收敛性、扩散性、一致性和基数性。这个想法可以通过平均(或累加)引用集的成员到解集中它们最近的解的距离，或者从这些距离中找到最大值来实现。对于前者，反向代际距离(IGD)是一个典型的例子，它考虑了平均值欧氏距离。其他的例子包括Dist1(D1)和一些IGD的变异。他们使用差异距离度量(如Tchebycheff distance和Hausdorff distance)，或者在评价中引入支配关系或附加点。 测量帕累托前沿到解集的最大差分(距离)可以很容易地识别出它们之间的差距，从而判断解集在前沿是否具有良好的覆盖性。Dist2(D2)和$\epsilon$-indicator就是这样的QIs。Dist2指标考虑Tchebycheff距离，而$\epsilon$-indicator考虑的是在目标上的最大区别：参考集的点优越于所考虑的解。与averaging difference-based QIs不同，maximum difference-based QIs可能具有明确的物理意义；例如，$\epsilon$-indicator是测量最小值添加到任何的解将使它被至少一个参考点集所weakly dominated。然而，他们的结果通常只涉及到一个特定目标的一个特解，因此自然会有大量的信息丢失。 最近提出了一种质量指标，称为优势移动(DoM)，它可以看作是上述两种QIs的组合。具体地说，给定两个解集A和B，A到B的DoM是移动A中一些点以便B中的任意一点都至少由A中的一点所支配。这种直观的指标具有许多可取的性质，如两种解决方案比较的自然延伸，符合帕累托优势，不需要问题知识和参数。然而，它的计算并不简单。虽然提出了一种双目标情况下的高效计算方法，但如何在有三个或三个以上目标的情况下高效计算仍有待探索。值得一提的是，早期的质量指标[126]可以看作是DoM的简化版本。它划分了引用集(即，$A\cup B$)为许多集群,将A对每个簇的最大差分累加。这使得计算变得高效，但是自然地失去了它的物理意义。 Inverted Generational Distance(IGD)它是最常用的指标之一，尽管之前提出了一些类似的观点。顾名思义，IGD是GD指标的反演，即测量从帕累托前沿到解集的距离。 形式上，给定解集A和参考集 $R=\{ r_1,r_2,…,r_M \}$ IGD(A,R) = \frac{1}{M} \sum_{i=1}^M \min_{a \in A} d_2(r_i,a)$d_2(r_i,a)$ 表示 $r_i$ 与 $a$ 的欧式距离。IGD值越低越好，说明该集合具有较好的收敛性、扩散性、均匀性和基数性的组合特性。 然而，IGD评估的准确性在很大程度上取决于参考集对帕累托前沿的逼近质量。不同的参考集可以使指标偏好不同的解集。通常建议对帕累托前沿采用高分辨率的大参考集。如[89,92]所示，集合中点数不足很容易导致反直觉的评价。此外，由优化器生成的所有非支配解决方案组成的引用集也可能导致误导结果，尽管这种做法在实际问题中得到了广泛采用。 Front to set distance看了好几遍，没有发现和IGD有什么不同，，，笨死了 为了度量MOEA的性能，我们只考虑运行MOEA所产生的最终总体中包含的所有非支配解决方案的子集。我们称这样的子集为近似集并用 $S$ 表示。近似集的大小取决于用于运行MOEA的设置。此指标计算离散帕累托最优集中每个解到近似集S中最近解的距离，并取平均值作为指标值： D_{P_F \rightarrow S}(S) = \frac{1}{|P_S|} \sum_{z^1 \in P_S}\min_{z^0 \in S}\{ d(z^0,z^1) \}由于我们感兴趣的是在目标空间中测量性能，两个多目标解 $z^0$ 和 $z^1$ 之间的距离就是它们的目标值 $f(z^0)$ 和 $f(z^1)$ 之间的欧氏距离。$D_{P_F \rightarrow S}(S) $ 指标既表示接近帕累托最优前沿的目标，也表示得到一个diverse、wide-spread 解决方案前沿的目标。这个性能指标的值越小越好。一个与此indicator密切相关的性能指标的hypervolume指标。在hypervolume指示器中，选择目标空间中的一个点，使其由需要测量的近似集中的所有点支配。然后，指示值等于由逼近集和所选参考点包围的多维区域的超体积。这个值是由近似集支配的目标空间中区域的指标。hypervolume 指示器和 $D_{P_F \rightarrow S} $ 指示器之间的主要区别在于，对于 hypervolume 指示器，必须选择一个参考点。不同的参考点导致不同的指示值。此外，不同的参考点可能导致指示值表明对不同的近似集的偏好。由于在 $D_{P_F \rightarrow S} $ 指标中使用了真正的帕累托最优前沿，因此 $D_{P_F \rightarrow S} $ 指标并不适用于此缺点。当然， $D_{P_F \rightarrow S} $ 指标的一个主要缺点是，在实际应用中，真正的帕累托最优前沿是未知的。在这种情况下，所有逼近集的帕累托前缘可以用来代替实际的帕累托最优前缘。 Delineation of Pareto Optimal Front介绍了描述度量 $\Phi$ 评价收敛性和多样性的程度一个已知的帕累托最优。本研究的目标是确定一组能够很好地表示帕累托最优。这个度量背后的思想是在帕累托最优前沿上的每个解能被已得到的非支配解有多好的表示出来。计算描述度量 $\Phi$ ，大量的H等间隔的解必须知道以反映真实帕累托最优前沿的帕累托最优集。用于计算的距离度量 $\gamma$ 同一组 $H$ 解决方案使用。从每个帕累托最优解到以获得的解 $l_i$ 的欧氏距离,这距离的平均值作为描述度量 $\Phi$,也就是说: \Phi(P_T) = \frac{1}{H} \sum_{i=1}^H l_i需要注意的是，在计算这个度量时，要考虑算法获得的所有解，包括那些受支配的解。 Dist1(D1)我们假设 $M$ 是一个好的 $R$ 的近似解，如果它可以给 $R$ 中的所有地区的重要信息，换句话说，如果对于每一个解 $y \in R$ ，这里都有一个比较接近的解 $x \in M$ 。我们建议用以下基于成就尺度函数的度量方法来度量两个解的亲密性： c(x,y) = \max_{j=0,...,J}\{0,w_j(f_j(y)-f(j(x) )\}$J$ 为目标函数的个数。因此，如果在所有目标上x达到解y的值，则测量值为0。否则，它取特定目标相对于y的最大加权偏差值。上述表达式中使用的权重设置为： w_j = 1 / \Delta_j其中，$\Delta_j$ 是在reference set的 $f_j$ 的范围。 Dist1=\frac{1}{card\{R\}} \sum_{y \in R} \{ min_{x \in M} \{c(x,y)\} \}Dist2(D2) Dist2= \max_{y \in R} \{ min_{x \in M} \{c(x,y)\} \}第一个度量给出关于 $y \in R$ 到 $M$ 中最接近解的平均距离的信息，而第二个度量给出关于最坏情况的信息。值越低，集合 $M$ 越接近集合 $R$。而且，$Dist2/Dist1$ 比值越低，从集合 $M$ 到集合 $R$ 的解分布越均匀。 $\epsilon$-indicator$\epsilon$-indicator 考虑sets之间的最大差异，它是受$\epsilon$-approximation所感，著名的测量设计和比较近似优化算法,运筹学和理论计算机科学。给定两个解集，$\epsilon$-indicator是一个集合在目标中被转换(以加法或乘法的方式)以弱支配另一个集合的最小因子。这就产生了两个版本:加法$\epsilon$-indicator和乘法$\epsilon$-indicator。数学上，解集A对于解集B的加法$\epsilon$-indicator定义如下： \epsilon_+(A,B) = \max_{b \in B} \min_{a \in A} \max_{j \in \{1...m\}} a_j - b_j$a_j$ 是 $a$ 的第 j 个目标，$m$ 是目标函数的个数。解集A对于解集B的乘法$\epsilon$-indicator定义如下： \epsilon_\times(A,B) = \max_{b \in B} \min_{a \in A} \max_{j \in \{1...m\}} \frac{a_j}{ b_j}这两个indicators都是越小越好。$\epsilon_+(A,B) \leq 0$ 或者 $\epsilon_\times(A,B) \leq 1$ 意味着 A weakly dominate B。当用代表PF的参考集R替换B时，$\epsilon$-indicator可以用作一元指标。它衡量的是被考虑的集合到帕累托前沿的距离。但是，由于返回的值只涉及两个集合中一个特解的一个特定目标(其中最大的差异)，指示器可能会忽略大量集合的差异。这可能导致不同执行的解决方案集具有相同/类似的评估结果。 (前提每个目标都是越小越好)对于加法拆解理解：设 $k = \min_{a \in A} \max_{j \in \{1…m\}} a_j - b_j$ 就是说对于B中指定一个解 $B_i$ ,把A中所有的解都减 $k$，那么A中至少(意味着min)存在一个解可以 weakly dominate $B_i$ ；如果遍历所有的$B$，那么需要取最大的那个 $k$，才能满足把 $A$ 中所有解都减掉 $k$ ，对于B任意一个解，A中都存在解可以 weakly dominate。对于乘法同理。 具体例子如图： 可知：$\epsilon_+(A_1,A_2) = 1$,$\epsilon_+(A_1,A_3) = 9/10$,$\epsilon_+(A_1,P) = 4$ $A_1$=(4,7),(5,6),(7,5),(8,4),(9,2) $A_3$=(6,8),(7,7)(8,6)(9,5)(10,4) 因为，想求 $\epsilon_+(A_1,A_3) $ 因此，先遍历 $A_3$ 中的元素，定性上说，在 $A_1$ 中里此元素越远，$k = \min_{a \in A_1} \max_{j \in \{1…m\}} a_j / b_j$越难被选上。 最后可以看到，(9,2) 与 (10,4) 的距离为标准，求得的结果，(10,4) 刚好在边缘上，且也可以看到，横轴间的距离差会比纵轴间的间隔会更大，因为横轴的数值就大。 ObjIGDObjective-wise Inverse Generational Distance(ObjIGD) ObjIGD度量评估MaOOA在每个目标上的收敛性和分布性能。ObjIGD的主要思想类似于IGD度量，然而ObjIGD测量的是PF与最接近的解决方案之间基于一个目标的距离。第i个目标的对象定义如下： ObjIGD_i(S,P)=\frac{ \sum_{j=1}^{|P|} \min_{s \in S}|F_i(p_j)-F_i(s)| }{|P|}$P$ 是 reference($PF_{true}$)。$S$ 是 $PF$ 近似集。$F_i(p_j)$ 是第$ i$ 个目标的第 $j$ 个解，$F_i(s)$ 是近似解的第 $i$ 个目标，因此，整体$ObjIGD$为： ObjIGD(S,P)=\frac{\sum_{i=1}^M ObjIGD_i(S,P)}{M}其中，$ObjIGD_i(S,P)$ 是第 $i$ 个目标的 $ObjIGD$ 的值，$M$ 是目标函数的个数。测度值越低，表明目标的收敛性和分布性越好。 IGD-NS在 IGD 计算中，我们经常发现，一些非支配解往往被忽略，因为它们不是均匀地从Pareto optimal front选取的计算 IGD 的任意参考点的最近邻。这意味着这些非支配解集中的解对集合的IGD值没有任何贡献，因此在逼近帕累托最优前沿方面，它们的重要性低于集合中其他非支配解。因此，我们将这些解称为非支配解集中的无贡献解(noncontributing)。具体地说，无贡献解的定义如下。 解 $y’$ 被认为在解集 $P$ 中，对于解 $P^*$是无贡献解，满足： \nexists x \in P^*:dist(x,y')=\min_{y \in P}dist(x,y)其中，$P^*$ 是一组参考点均匀采样的帕累托最优。从上面的方程,它可以学到无贡献解不是 $P^*$ 中任意点的最近邻点。 在考虑无贡献解的情况下，将提出的性能度量，即带无贡献解检测的IGD的度量(IGD-NS)，定义如下： IGD-NS(P,P^*)=\sum_{x \in P^*}\min_{y \in P} dis(x,y) + \sum_{y' \in P'}\min_{x \in P^*} dis(x,y')$P’$ 是population中无贡献解，上式的第一部分与IGD类似，控制了 $P$ 的多样性和收敛性；然而第二部分是对于每一个无贡献解到 $P^*$ 中点的最小距离的总和。因此，当且仅当满足以下两个条件时，可以得到一个较小(良好)的IGD-NS度规值:首先，种群具有良好的收敛性和多样性;第二，总体包含尽可能少的无贡献解。 个人理解：就是遍历 $P^*$ 中的每一个点，找到与此点距离最近的 $P$ 中的点都删掉，$P$ 中剩下的就是 $P’$ $IGD_p$ IGD_p(X,Y) = \left( \frac{1}{M}\sum_{i=1}^M dist(y_i,X)^p \right)^{1/p}这个就没有什么好说的了。。。 $\Delta_p$ \Delta_p(X,Y)=\max(GD_p(X,Y),IGD_p(X,Y))\\ =\max \left( \left( \frac{1}{N}\sum_{i=1}^N dist(x_i,Y)^p \right)^{1/p}, \left( \frac{1}{M}\sum_{i=1}^M dist(y_i,X)^p \right)^{1/p} \right)这个也是。。。。 $\epsilon$-performanceε-dominance是一个概念,用户可以指定他们想要的精度得到帕累托最优解决方案的多目标问题,在本质上给他们的能力来分配每个目标的相对重要性。这是通过应用一个网格(由用户指定大小的值)问题的搜索空间。$\epsilon$ 值较大导致巨大网格(和最终减少解决方案),而较小的 $\epsilon$ 值产生一个更精细的网格。每种解决方案的健身然后映射到一个盒子健身根据指定的 $\epsilon$ 值。 $\epsilon$-dominance适用于一套参考解根据用户指定的ε值 在每一代,匹配算法生成的每个解决方案,其相应的 $\epsilon$-nondominated参考集解。每个参考解只能有一个与之相关的算法解。如果存在多个解在 $\epsilon$-nondominated 参考集解，然后用欧氏距离最小的解来选择。这考虑了在参考解中的 $\epsilon$ 重叠地区，并且腾出额外的解与其他 $\epsilon$-nondominated参考解。 Each $\epsilon$-nondominated reference solution that has a corresponding algorithm solution receives a score of one, while each reference solution that has no corresponding algorithm solution receives a score of zero. ： \epsilon(P) = \sum_{i=1}^n h_i/n$h_i$ 是 对于 $\epsilon$-nondominated reference set 的第 $i$ 个解，并且 n 是reference set的个数。 这个指标测量了收敛性通过考虑,聚集在 $\epsilon$ 的引用集的解。多样性是占每个$\epsilon$-nondominated引用包括只有一个解决方案的解决方案,不管$\epsilon$-block额外的解的存在性。这可以确保集群解决方案不会对度量的计算产生影响。 说实话没太看懂，，，怎么个对应(corresponding algorithm)法子。 $I_{SDE}$ I_{SDE}(x,y) = \sqrt{\sum_{1 \leq i \leq m }sd(f_i(x),f_i(y))^2}其中： sd(f_i(x),f_i(y))=\begin{cases} f_i(y)-f_i(x) & if \ f_i(x) < f_i(y)\\ 0 & otherwise \end{cases}m 为目标函数个数。需要计算所有的 x 与 y 对。 PCI定义1：p 为一个点，Q为一组点$\{ q_1,q_2,..,q_k \}$ 。p 对 Q 的支配距离定义为p在目标空间中满足 p weakly dominate 所有的 Q 的最小距离： D(p,Q) = \sqrt{\sum_{i=1}^m(p^{(i)}-d(p^{(i)},Q))^2}其中： d(p^{(i)},Q) = \begin{cases} min\{ q_1^{(i)},q_2^{(i)},...,q_k^{(i)} \},&if \ p^{(i)} > min\{ q_1^{(i)},q_2^{(i)},...,q_k^{(i)} \}\\ p^{(i)},&otherwise \end{cases}$p^{(i)}$ 是 解 p 的第 i 个目标，m 为目标函数的个数。 $D(p,Q)$ 只考虑了 Q 中优于 p 的解，无关差于 p 的解。这可以使指标不受收敛性差的参考点的影响，如优势抵抗解。$D(p,Q)$ 的范围是0到无穷，越小越好。如果 p 在少数的目标函数中，轻微差于 Q ，$D(p,Q)$ 会很小，只有 p weakly dominate Q ：$D(p,Q)=0$ 易证： \max\{D(p,q_1),...,D(p,q_k)\} \leq D(p,Q) < D(p,q_1)+...+D(p,q_k)定义2： P，Q为两个解集。P 对 Q 的支配解集 $D(P,Q)$ 。定义如下：对于任意点 $q \in Q$ 中 P 的最小的总距离，使得至少有一个点 $p \in P$ weakly dominate q。 在该指标中，由于参考集由所有的近似集组成，因此一个聚类可以包含来自不同近似集的点。让一个聚类 C 包含 P 和 Q。$P = \{ p_1,…,p_i \}$ 与 $Q = \{ q_1,…,q_j \}$，显然 $D(P,C) = D(P,Q)$ 。当 $i=1$ 时，$D(P,C)$ 是 $p_1$ 对 C 的理想点的支配距离。当 $i \geq 2$ 时，$D(P,C)$ 可以小于 $\min\{D(p_1,C),…,D(p_i,C)\}$。 如上图：ideal point 代表了 每个cluster中每个函数的最小值 cluster $C_1$ ：$P_1$ 只有一个点，因此 $D(P_1,C_1) = (0.5^2 + 0.5^2)^{0.5} = 0.707$ cluster $C_2$ ：$P_2$ 有两个点，为 $D(P_2,C_2)= 0.559 &lt; \min\{1.031,1.25\}$ ,其中1.031与1.25是 $P_2$中的点分别到ideal point的点的距离。 cluster $C_3$： $P_3$ 是一个极端情况， $D(P_2,C_2)=0$，但是如果单个计算的话均为 1。 由此可以知道：当 $i \geq 2$ 时，$D(P,C)$ 可以小于 $\min\{D(p_1,C),…,D(p_i,C)\}$。这是因为共有 $i^j$ 种可能性，对于$p_1,p_2,…,p_i$ 去分开 $q_1,q_2,…,q_j$ ，就是对于每一个 $q$ 都有 $i$ 个可能性被 $p$ weakly dominate。因此，粗略计算如下： D'(P,C) = \max\{ \min\{ D(p_1,q_1),...,D(p_i,q_1) \},\\ ...\min\{ D(p_1,q_j),...,D(p_i,q_j) \} \}当 $i \geq 2$ 时，这仅仅有 $i \times j$ 个比较，尽管 $D’(P,C) \leq D(P,C)$ ，但是当 $C$ 的尺寸小时差距是很小的，例如：$D’(P_2,C_2) = 0.5 &lt; D(P_2,C_2)=0.559$ 与 $D’(P_3,C_3) = D(P_3,C_3) = 0$ 。 首先。所有的解集都要归一化， 如果评估的近似解小于两个，PCI考虑 the minimum move of one solution in the approximation set to weakly dominate the cluster (Step 8 否则计算the minimum move of the set’s solutions in the cluster to weakly dominate the cluster (Step 10 在 cluster 算法中：使用贪心的方法来逐步合并点根据他们的优势距离。设为归一化超平面上具有N个点理想分布的两个相邻点的区间(优势距离的意义)，其中N为参考集的大小。在这种情况下，$\sigma = 1/h$ 与 $N=C_{m-1+h}^{m-1}$ 其中，$h$ 为每个目标的分支，$m$ 为目标函数的个数，因为： (h+m-1)\times (h+m-2)\times ...\times (h+1) \approx (h + m/2)^{m-1}因此： \sigma \approx \frac{1}{\sqrt[m-1]{N(m-1)!}-(m/2)}G-Metric规定：$A_1,A_2,…,A_m$ 是 m 个NSs(non-dominated sets)： Scale the values of the vectors in the NSs Group the NSs by levels of complete outperformance For each level of complete outperformance and for every $A_i$ in the level, calculate the zone of infuence $I_{A_i}$ For every $A_i$, combine its convergence and DE to create a number that represents its relative performance respect to the other NSs Scale and normalization Take the union of the m sets, $C = \cup_{i=1}^m A_i$ From C take its non-dominated elements.$C^*=ND(C)$ Find $max_j$ and $min_j$ as the max and min value respectively, for the component j for all points $p \in C$ 暗指在known pareto front 中挑选。 Using $max_j$ and $min_j$ make a linear normalization of all points in all $A_i$ . Convergence Component已知 $D={A_1,A_2,…,A_m}$ ，其中 $A_i$ 是一个NS 令 $j=1$ 令 $L_j=\{\}$ 从 D 中提取出，并放入 $L_j$ 中，这些 $A_i$ 满足 $ \urcorner ((\bigcup_{A_k \in D }A_k) \ O_C \ A_i)$ 如果 D 不空，那么 j = j + 1，返回到第二步 结束 注意：这是以每一个NS作为整体的。 $L_1$ 是不能被 D 中除了 $L_1$ 的解所completely outperform。如果$A\in L_j$ ,$B \in L_k$ 并且 $j &lt; k$ ，我们可以知道 A 要好于 B，如下图，这有5个NSs ：A，B，C，D 和 E。我们分三个层次： $L_1 = \{A\}$，$L_2 = \{B,C\}$，$L_3 = \{D,E\}$ Dispersion–Extension Component定义1：$I_{p_i}$ 是一些据点 $p_i$ 的距离小于或等于一个正实数 $U$ 的一些点集，U 可以当作为半径。 定义2：$I_S$ 是 $I_{p_i}$ 的并集，$for \ all \ p_i \in S $ 一般来说(对于点或集合)，我们将影响区域称为I。 $I$ 的测量 $\mu(I)$ ：它是对一个点或NS的注入带的测量。它是对一个点或NS的测量。对于 2d 它意味着是面积，在 3d中意味着体积，依次类推。 如果 S 有一个较差的 DE(Dispersion–Extension)，那么他们中的许多都挨着很近，并且相互交叉，结果 $\mu(I_S)$ 就会变小。现在假设我们重新定位S的元素以改进DE。我们通过增加元素之间的扩展和距离，以及/或使它们的距离更均匀来实现这一点(如下图)。随着我们提高了 DE，$I_{p_i}$ 会下降，与此同时，DE 与 $\mu(I_S)$ 都会增加，因此，$\mu(I_S)$ 正比于DE，并且 $\mu(I_S)$ 是一个好的 DE indicator。 $I_S$ 也正比于 $I_{p_i}$ 之间的交叠。具有良好DE的NSs比具有不良DE的NSs重叠更少。 Computing the G–Metric已知 m 个 非支配解集，$A_1,A_2,…,A_m$ 归一化所有的解集 把所有的解集分类成$A_k$ for k = 1~Q ，其中，Q 是等级的数量。 对于每一个 $A_i \in L_k$ ，消除所有的点 $p \in A_i$，满足 $p$ 被另一个点 $q$ 所支配，$q \in A_j$ 对于任意 $A_j \in L_k$ 翻译一下就是：在 $L_k$ 中留下非支配解，其他的都删去。 计算基于所有的 $A_i \in L_k$ 的 U (下面会详细说) 计算 $\mu(I_{A_i})$ 对每一个 $A_i \in L_k$ (下面会详细说) 对于每一个 k = 1~Q-1 对于所有的 $A_i \in L_k$ : G(A_i) = \mu(I_{A_i}) + \sum_{j = k + 1} ^Q \mu_{max}(L_j)其中，$\mu_{max}(L_j)$ 是 对于 $A_i \in L_j$ 最大的 $\mu(I_{A_i})$ . 例如下图： 这段有点不会了，索性直接贴图了。。。。 Dominance move(DoM)我看了四天！！！ 好多证明和推导，在这里就不解释了…. 定义：$n_R(q)$ ，为在 $R$ 中最接近点 $q$ 的点。 距离测量： D(P,Q) = \min_{P' \preceq Q} \sum_{i = 1}^n d(p_i,p_i')\\ d(p_i,p_i') = \sum_{j=1}^m |p^j_i - p_i'^j|$p_i^j$ 是 在 $P$ 中第 $i$ 个解的第 $j$ 个目标函数。$p’$ 是 $p$ 转移到 $p$ 试支配 $Q$，使得：$Q$ 中的任意一点都可以被 $P^‘$ 支配。$m$ 是目标函数的个数。 d(p,Q_s) = \sum_{j=1}^m(p^j - \min\{ p^j,q^j_{s1},q^j_{s2},...,q^j_{sk} \})m$ 是目标函数的个数。 假设计算 $D(P,Q)$ 删除 $Q$,$P$ 个子中的被支配的解，再删除 $Q$ 中被 $P$ 支配(存在一个就行)的点。 设 $R = P \bigcup Q$ ，首先把 $Q$ 中的每一个点当作一组，然后对于 $Q$ 中的每一个点，在 $R$ 中寻找它的最近邻点；对 $Q$ 中的每一个点，寻找到一个 $ r \in R$ ，使 $r = n_R(q)$ ，如果 $r \in P$ ，那么把 $r$ 归为此 $q$ 一组；如果 $ r \in Q$ ，如果 $q$ 和 $r$ 已经在一组，什么都不需要做，否则，把这两组归为一组。 如果在任何组中不存在 $q \in Q$ ，满足：$q = n_R(n_R(q))$ ，即这两个点互为最近邻，那么结束； 对于有环(互为最近邻)的组，用这两个点的理想点取代这两个点，产生新的集合名为 $Q’$ ，寻找在 $P \bigcup Q’$ 中此理想点的最近邻点，并归类为一组，转向，Step.3 举例： 以下为 在收敛性，一致性，延展性，基数性，四个方面做出比较，效果都不错，但有一个很大的问题就是，只能比较二元问题，对于二元以上的存在一些漏洞，证明上不是充要条件。 Volume-based QIsHypervolume(HV)HV首次作为空间的大小所展示，然后被用作几个专业术语hyperarea metric，S-metric，Lebesgue measure。由于HV指标具有理想的实际可用性和理论特性，因此可以说是最常用的QIs。计算HV不需要表示帕累托前沿的参考集，这使得它适合于许多实际的优化场景。HV结果对帕累托优势集的任何改进都是敏感的。当一个集合A优于另一个集合B时(即,一个A◁B)，然后HV返回A的质量值高于B。因此，对于给定的问题，达到最大HV值的集合将包含所有帕累托最优解。 HV indicator 的定义如下。已知解集A和参考点r, HV可计算为： HV(A) = \lambda(\cup\{ x | a \prec x \prec r \})$\lambda$ 表示勒贝格测度，简而言之，一个集合的HV值可以看作是由每个解和参考点(分别为左底顶点和右顶顶点)确定的超立方体的并集的体积。 HV的局限性是它的数量关于目标数而指数增加的运行时间(除非P=NP)。HV的另一个问题是其参考点的设置。对于如何为给定的问题选择合适的参考点仍然没有共识，尽管有一些常见的实践，例如帕累托前沿的最低点或比较解集集合的最低点的1.1倍。不同的参考点会导致HV评价结果不一致[110]。除了少数特殊情况外，关于高压参考点的选择缺乏系统的研究/理论指导。Recently,have demonstrated a clear difference of specifying the proper reference point for problems with a simplex-like Pareto front and an inverted simplex-like Pareto front. 他们还通过实验表明，一个比最低点稍差的参考点并不总是合适的，特别是在多目标优化和/或小群体规模的情况下。此外，HV指标偏向膝关节区域，偏向凸区域多于凹区域。证明，一组达到最大HV值的解的分布很大程度上取决于帕累托前缘的斜率。例如，HV可能倾向于高度非线性帕累托前缘上非常不均匀的解集。这已经得到证明。 hyperarea ratiohyperarea 定义为 $PF_{known}$ 值所包含的空间，例如，在二维目标优化中，就是原点和函数值所覆盖的矩形面积： H = \{ \bigcup_i a_i | v_i \in PF_{known} \}其中，$v_i$ 是 $PF_{known}$ 中的非支配解向量，$a_i$ 是由 $v_i$ 分量和原点确定的超面积。 以下图为例： 被(0,0) 与 (4,4) 所围成的矩形的面积是 16。被 (0,0) 与 (3,6) 所围成的为 (3 x (6-4)) = 6个，依次…结果： $P_{true}$ ‘s H = 16 + 6 + 4 + 3 = 29. $PF_{true}$ ‘s H = 20 + 6 + 7.5 = 33.5. 同时，也注意到：如果 $PF_{true}$ 是 non-convex ，这种测量方法会有错误。它们还隐式地假设MOP的目标空间原点坐标为(0..，0)，但情况并非总是如此。$PF_{known}$ 中的向量可以转换为以零为中心的原点，但是由于MOPs之间每个目标的范围可能完全不同，因此最佳 $H$ 值可能相差很大。也定义了 $hyperarea \ ratio$ 定义如下： HR = \frac{H_1}{H_2}$H_1$ 为 $PF_{known}$ 的超面积，$H_2$ 为 $PF_{true}$ 的超面积。在极小化问题里：ratio 值为 1，当 $PF_{known} = PF_{true}$ ；如果大于 1，即为 $PF_{known}$ 的超面积大于 $PF_{true}$ ，上例中，$HR = \frac{33.5}{29} = 1.155$ 。 Hyperarea Difference (HD)使 $A,B \subseteq X $ 是两个decision vectors，那么，函数 $D$ 定义如下： D(A,B):= \xi (A+B) - \xi (B)所给的是被 $A$ weakly dominate 但是不被 B weakly dominate 的空间的大小(objective space)。 如上右图，A 为 前沿1，B 为前沿2。一方面，$\alpha $ 是被前沿1但不被前沿2所占的大小。另一方面，$\beta$ 是被前沿2但是不被前沿1所占的大小，黑色的区域是被两个都占的大小，因此，$D(A,B) = \alpha$ ，$D(B,A) = \beta$ 。因为： \alpha + \beta + \gamma = l(A+B)\\ \alpha + \beta = l(A)\\ \alpha + \gamma = l(B)\\在这个例子中，$D(B,A) &gt; D(A,B)$ 意味着与C度量相比，这两个方面的差异体现。另外，它给出了集合是否完全支配另一个集合的信息，例如 $D(A,B) = 0$，$D(B,A) &gt;0$ 意味着 $A$ 支配 $B$。 理想下，D 测量常用于被 $V$ 归一化的 $l$ 指标，对于应该最大化问题： V = \prod_{i = 1}^k (f_i^{max} - f_i^{min})$f_i^{max},f_i^{min}$ 是 目标 $f_i$ 的最大值，最小值。可是，也有其他的情况，$V = l(X_p)$ ，表现得也不错。结果，四个值被考虑，当考虑两个解集时，$A,B \in X_f$: $l(A) / V$ ，它给出了目标空间中被 $A$ 弱支配的区域的相对大小。 $l(B) / V$ ，它给出了目标空间中被 $B$ 弱支配的区域的相对大小。 $D(A,B) / V$ ，她给了被 $A$ 弱支配但不被 $B$ 弱支配的区域的相对大小。 $D(B,A) / V$ ，她给了被 $B$ 弱支配但不被 $A$ 弱支配的区域的相对大小。 由于 $D$ 度量是在 $l$ 度量的基础上定义的，因此不需要额外的实现工作。 Volume measure粗略的说$ \mathcal{V}(A,B) $ 是包含严格由 $A$ 的元素支配但不受 $B$ 的元素支配的两条边的最小超立方体的体积的分数(并且在[0,1]区间内)。如下图所示，两个连续的前沿 $A$ 和 $B$ 在目标空间的不同区域存在不同程度的差异，并且相互支配。(目标函数最小化) $\mathcal{V}(A,B)$ 定义如下，对任何D维的向量 $Y$ ，$H_Y$ 为包括 $Y$ 的最小的轴平行超立方体。 H_Y=\{ z \in R^D:a_i \leq z_i \leq b_i \ for \ some \ a,b \in Y \ i=1,...,D \}现在用映射到单位超立方体上的规格化缩放和平移来表示$h_Y(y):H_Y \rightarrow [0,1]^D$。此转换用于消除目标伸缩的影响。相当于 $k = h_Y(y)$ 把原来的点 $y$ 通过缩放与平移到单位超立方体中的点 $k$ 。 D_Y(A)=\{ z \in [1,0]^D:z \prec h_Y(a) \ for \ some \ a \in A \}上式为超立方体中被归一化控制的点的集合，那么$\mathcal{V}(A,B)$定义如下： \mathcal{V}(A,B)=\lambda(D_{A \cup B}(A) \backslash D_{A \cup B}(B) )其中，$\lambda(A)$ 是 $A$ 的勒贝格测量。个人认为： ​ 绿色的部分为$\mathcal{V}(B,A)$ 。 ​ 红色的部分为$\mathcal{V}(A,B)$ 。 尽管这个描述相当繁琐，但是 $\mathcal{V}(A,B)$ 和 $\mathcal{V}(B,A)$ 很容易通过对 $H_{A \cup B}$ 的蒙特卡罗抽样来计算，并计算A或b占绝对优势的样本的比例。本研究选取5万个样本进行蒙特卡罗估计。体积测量 $\mathcal{V}$ 的好处是,它将奖励设置更大的区段当这些区段是前面的比较,而不是当他们在后面,不受点分布方面,而且它也给信息多远一组(平均)面前的另一个地方。 不幸的是，这个测度 $\mathcal{V}$ ，像原来的度规$\mathcal{C}$ 一样，具有这样的性质，如果$\mathcal{W}$ 是一个非支配集，并且 $A \subseteq W$，$B \subseteq W$ ，$\mathcal{V}(A,B)$ 与 $\mathcal{V}(B,A)$ 两者都是积极的。 Integrated Preference Functional (IPF)作为一组在运筹学上已建立完善的QIs，IPF测量由集合中的每个非支配解和给定的效用函数在相应的最优权值上确定的polytopes的体积。它可以被理解为表示解决方案集为DM[16]所携带的预期实用程序。IPF指标的计算分为两个步骤:1)找出每个非优解的最优权重区间;2)对这些最优权重区间上的效用函数进行积分。 形式上，$A \subset \mathcal{R}^m$ 是非支配解集，其中 m 是目标函数个数。考虑一个参数化的效用函数族 $u (a,w)$，其中给定的权重 $w$ 产生一个要优化的值函数，其中 $a \subset A$ 和 $w \in W \subset \mathcal{R}^m$ ,对于给定的 $w$，让 $𝑢^*(A,𝑤)$ 为在A中最好的效用函数值的解决方案。给定权重密度函数$h:W \rightarrow \mathcal{R}^+$ ，表示未知权重w的概率分布，并且$\int_{w \in W}h(w)dw=1$，那么集合A的IPF值为： IPF(A)=\int_{w\in W} h(w)u^*(A,w)dw效用函数可以表示作为目标的凸组合(即加权线性和函数)或加权Tchebycheff函数。前者只考虑受支持的解决方案，而后者则涵盖所有非支配的解决方案。IPF indicator可以在/不需要 DM 的输入的情况下使用。当DM的偏好可以按照某个部分权重空间来表达时，IPF衡量的是该集合在部分帕累托前沿所代表的偏好的好坏。当没有可用的偏好信息时，可以假设所有的权重都是相等的(即$h(W)=1,\forall w \in W$)，IPF 衡量的是这组数据如何很好地代表整体帕累托。较低的IPF值为佳。然而，使用IPF指标的一个限制是，随着目标数量的增加，其计算复杂度呈指数级增长，因为它需要在(连续的)权重空间上进行积分。 以下为论文原文： 对于多目标优化问题，经常使用值(utility)函数法将各种目标函数组合成输入的一个标量函数。这个组合目标可以表示为参数化函数族 $g(x;α)$，一个给定的值参数向量 $\alpha$ 在它的领域 A 中代表一个特定的标量目标，并且目标是最小化。在二元目标的情况下0和1之间的 $\alpha$ 是一个标量,凸组合的情况下的目标。 对于给定的集合 $X$ (多目标函数的非支配解)，对于任意给定 $\alpha$ ，通过 $g(x;\alpha)$ 至少存在一个最优解。对于给定的 $g$ ，定义一个函数 $x_g:A \rightarrow X$，它把参数值( $\alpha$ )映射到 $X$ 中的相应解上。这个函数 $x_g(\alpha)$ 很清晰的把 $A$ 分成了几个区域，反函数 $x_g^{-1}(x)$ ，随着 $x \in X$，定义参数空间 A 在解上的分区，其中 $x_g$ 是常量： A = \bigcup_{x \in X}x^{-1}_g(x) = \bigcup_{x \in X} A_x对于，$x_1 \neq x_2$ ，其中，$A_{x_1} \ and \ A_{x_2}$ ，在二元目标例子中，至多有一个值相同。通常情况下，$A_{x_1} \bigcap A_{x_2}$ 是 对于 $x_1 \ and \ x_2$ 最优解时，两个区域间的边界。在所有实际情况下，这将是一组测度零，不会影响指规数的计算。给定: $h:A \rightarrow R_+$ ,$\int_{\alpha \in A} h(\alpha) d \alpha = 1$, IPF(X) = \int h(\alpha) g(x_g(\alpha);\alpha)d\alpha将解集映射到实数的积分偏好函数。因为 $x_g$ 是(piecewise)分开的常量，上式的积分可以分解成与 $x \in X$ 相对应的 $x_g^{-1}(x)$ 的不同区域。 IPF(X) = \int_{\alpha \in A} h(\alpha) g(x_g(\alpha);\alpha)d\alpha = \sum_{x \in X}\left[ \int_{\alpha \in x^{-1}_g(x)} h(\alpha) g(x;\alpha)d\alpha \right]因此,给定一个 $\alpha$ 的值产生一个特定的目标函数，因为至少有一个最优解在集 $x_g(\alpha)$ 。密度函数 $h(\alpha)$ 分配不同的值给权重向量 $\alpha$ 值,然后 $IPF$ 提供了一个通用的“最优”的解决方案,在已选择权重密度函数。 最后形式的方程表明,我们只需要能够评估积分 $h(\alpha)$ ,因此目标函数的形式是无关紧要的。此外，这里提出的 $IPF$ 测度没有考虑到决策者的任何个人偏好结构，因此可以认为是一般性的。当然，所有这些的主要困难是计算出 $x_g$ 为分段常数的 $A$ 的适当区域，以及计算式(2)中的积分。这些困难取决于函数g、函数h的类型和考虑的目标的数量。 $h(\alpha)$ 如下图： 在实际问题中应用IPF测量，需要对每个目标进行适当的标度。当所考虑的目标是不可比较的(例如，延迟作业的数量和总完成时间)，则无法解释混合的目标值。此外，当每个目标值的范围之间的差异非常大，以至于一个目标值可以被另一个目标值抵消时，将多个目标混合到一个合理的标量值需要适当的缩放。Schenkerman(1990)提出在缩放目标值时，合适的最小值和最大值分别是最大化问题中近似集的非支配最小值和理想点。他还坚持认为，其他的最低要求可能会阻止决策者做出自己喜欢的决定。De et al.(1992)在比较最小化问题的近似集与面积和长度度量时采用了相同的比例方法。正如Gershon(1984)所指出的，规模可以衡量目标的重要性，这影响所考虑的权重。 另外下面是在另一个论文里对 $IPF$ 的介绍，觉得更通俗，就摘过来了。 IPF(Tchebycheff)如Carlyle et al.(2003)所述，决策者的价值函数可以表示为目标的凸组合这一假设意味着只有支持的点才有助于IPF度量。一般来说，当决策者的隐式值函数是非线性的时，这是一个严重的限制，因此，在非支配解集中某些不受支持的点实际上可能是更可取的。在极端情况下，可能会出现这样的问题:受支持的有效解决方案非常少，而绝大多数有效解决方案可能不受支持。在评估非支配点集时，考虑不支持点的影响的一个好方法是使用加权的Tchebycheff函数来表示决策者的价值函数。Tchebycheff函数对应于权重规度$L_p​$ ,在下式中，当 $p = \infty​$ : minimize_{i \in I} \left( \sum_{j \in J} \alpha^p_j (z_j^i - z_j ^{**})^p \right)^{1/p}其中，$I=\{ 1,2,…,n \}$ 是解集的索引，$J=\{ 1,2,…,m \}$ 是目标的索引，$\alpha_j$ 是第 j 个目标的权重，并且 $\alpha_j \geq 0$，同时，$\sum_{j \in J} \alpha_j = 1$ ，$z^i_j$ 是第 i 个解的第 j 个目标函数值，$z^{**}_j$ 是第 j 个目标的理想值。注意到这一点可以通过最小化第 j 个目标本身来找到。当 $p = 1$ 时，测度对应于目标函数的凸组合当 $z^{**}_j = 0$ 时。当 $p = \infty$ 时，权重测度 $L_{\infty}$ 测度为： minimize_{i \in I} [ \max_{j \in J}\{ \alpha_j(z^i_j - z^{**}_j) \} ]加权Tchebycheff函数可用于生成所有非支配点，支持点和不支持点，因此在多目标优化问题中得到了广泛的应用。当使用加权Tchebycheff函数时，集合中的每个非支配点都有一个最优权区间。本文给出加权契比雪夫函数的IPF测度的计算方法。如果我们假设所有的权值都是等可能发生的($h(\alpha ) = 1 ,for \ all \ \alpha \in A​$)。当考虑二元函数时： minimize_{i \in I} [ \max \{ \alpha z^i_1, (1-\alpha) z^i_2 \} ]其中，$0 \leq \alpha \leq 1$ ， 并且考虑两个问题，1). 找出每个非支配点的最优权区间。2).在分解后的最优权值区间上对标量值函数积分。 以下的 Step.1~Srep.3可解释第一个问题，Step.4解释第二个问题。 Step.1：按照解的第一维度升序排好解如下： z_1^1 < z_1 ^2...>z_2^n Step.2：获得 break-even 权重，$\alpha ^i_b$ 对于每一个点 $i \in I$ ，其中，关系如下： \alpha_b^iz_1^i = (1-\alpha_b^i)z_2^i下图a，有在目标空间中的一个点，虚线表示一个break-even点 $\alpha ^i_b$ 。满足上式，并从图b，看出所有的点 $z^i,i \in I$ 满足如下： \alpha^b_i = \frac{z^i_2}{z^1_1 + z_2^i}使用break-even权重，$\max\{ \alpha z^i_1, (1-\alpha) z^i_2 \}$ 对每一个非支配点都可以如下这样： \max\{ \alpha z^i_1, (1-\alpha) z^i_2 \} = \begin{cases} \alpha z_1^i &\alpha \geq \alpha_b^i\\ (1-\alpha_b^i)z_2^i &\alpha \leq \alpha_b^i \end{cases} 定理一：对于所有的不等式，均满足：$\alpha_b^1 &gt; \alpha_b^2&gt;…&gt;\alpha_b^n$ ，具体推导见原论文。 Step.3：对于每一个非支配解，获得一个上界，$\alpha_U^i$，获得一个下界，$\alpha_L^i$ 。 \alpha_U^1 = 1\\ \alpha_L^1 = \alpha_U^2 = \frac{z_2^1}{z_1^2 + z_2^1}\\ .\\ .\\ \alpha_L^i = \alpha_U^{i+1} = \frac{z_2^i}{z_1^{i+1} + z_2^i}\\ .\\ .\\ \alpha_L^n = 0 Step.4：在步骤3分解的最优权重区间上对加权Tchebycheff函数进行积分，对在 Z 中每一个点有如下： IPF(Z) = \int^1_0 h(\alpha) \min_{i \in I}[\max\{ \alpha z^i_1,(1-\alpha)z_2^i \}]d \alpha\\ =\sum_{i \in I} \left( \int_{\alpha^i_L}^{\alpha^i_b} h(\alpha)(1-\alpha)z_2^i d \alpha\\+ \int_{\alpha^i_b}^{\alpha^i_U} h(\alpha)\alpha z_1^i d \alpha \right) 下面为一个实例： R Family与IPF指标类似，R族[73]也将DM s偏好纳入评价。然而，与IPF不同的是，R质量指标中的集成是基于效用函数(而不是权重空间)的。给定两个解集A和B，一个效用函数空间R和一个效用密度函数(U)，可以定义为 R(A,B,U) = \int_{u \in U} h(u)x(A,B,u)du根据结果函数 $x(A,B,u)$，R家族有三个指标。R1考虑DM优先选择其中一个的概率，R2考虑效用函数的期望值(就像IPF指标)，R3引入了基于R2的比值。其中R2使用频率最高，可以表示为 R2(A,B,U) = \int_{u\in U}h(u)u^*(A)du - \int_{u \in U}h(u)u^*(B)du其中，$u^*(A)$ 表示A在此特定效用函数上所获得的最佳值。可以看出，两个集合的R2值可以单独计算。与IPF指标一样，当偏好信息不可用时，$h(u)$可以均匀分布在 $u$ 上。然而，计算中通常使用离散有限集 $U$，这与IPF中考虑的连续集$W$相反。这可以使R2的计算变得友好。特别地，如果效用函数 $u$ 的集合可以用权值 $W$ 的集合和这些权值上的参数化效用函数来表示，那么R2可以进一步计算为 R2(A) = \frac{1}{|W|}\sum_{w \in W} u^*(A,w)与IPF一样，$u(A,w)$ 的物化过程中也存在多项选择，如加权线性和函数和加权Tchebycheff函数，但后者在实践中应用较为广泛。 当h(w)设为1时，将式(13){R2(A)}与式(10)(IPF(A))进行比较，R2和IPF指标表现得非常相似。IPF指标考虑的是一个连续的权值空间，它需要相对于目标维数呈指数增长的计算时间，而R2指标考虑的是一组离散的权值，它的计算速度很快，但其精度自然低于IPF。]]></content>
      <categories>
        <category>indicators</category>
      </categories>
      <tags>
        <tag>MOEA</tag>
        <tag>indicator</tag>
        <tag>AllaspectsQI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[QIs for Spread and Uniformity]]></title>
    <url>%2F2019%2F02%2F06%2Fspreadanduniformity%2F</url>
    <content type="text"><![CDATA[过年期间，学习就更加懈怠了。。 前言spread和uniformity的品质方面是密切相关的，需要将它们放在一起考虑，以反映解决方案集的diversity。这激发了QIs去覆盖spread和uniformity的品质。这类QIs大多数可以分为两类，distance-based indicators and region division-based indicators，尽管也有其他的选择，如基于集群的指标和基于容量的指标。如图： Distance-based QIs(59~62)该类中的QIs(表中项目59-62)通常考虑解与其邻域之间的距离，然后将这些距离相加，从而估计整个集合的覆盖范围。沿着这个思路的是 $\Delta$ ,然后是sparsity index，extended spread，and $\Delta_{Line}$ 。然而，这样的评估只能在双目标问题中工作，如非支配解连续位于两个目标上。这些QIs的另一个问题是，它们需要帕累托前沿(例如边界)的信息作为参考，这在实践中往往是未知的 $\Delta$此论文来自于伟大的$NSGA-II$ ！ \Delta = \frac{d_f + d_l + \sum_{i=1}^{N-1}|d_i-\bar{d}|}{d_f + d_l + (N-1)\bar{d}}具体参数可看下图，一目了然。 值得注意的是，这并不是可能的解决方案的最坏情况。我们可以假设$d_i$有很大的方差。在这种情况下，度量可能大于1。因此，上述度量的最大值可以大于1。然而，一个好的分布会使所有的 $d_i$ 距离都等于 $\bar{d}$ 并且会$d_f=d_l=0$(在非支配集中存在极端解)。因此，对于最广泛且均匀分布的非支配解集，其分子为零，使得度规 $\Delta$ 取的值为零。对于任何其他分布，度规的值都大于零。对于两个具有相同$d_f$和$d_l$值的分布，度规$\Delta$取的值较高，而极值解的分布较差。请注意，上述多样性度量可用于任何非支配解集，包括非帕累托最优集的解集。利用三角化技术或Voronoi图方法[1]进行计算$d_i%=$，可以将上述过程推广到估计高维解的spread。 Extended spreadS 是一个解集，$S^*$ 是已知的Pareto-optimal solutions。 $\Delta(S,Q)$ : 原始度规计算两个连续解之间的距离，这只适用于2个目标问题。我们通过计算一个点到它最近的邻居的距离来进行扩展: \Delta(S,S^*) = \frac{\sum_{i=1}^m d(e_i,S) + \sum_{X \in S^*} |d(X,S)-\bar{d}|}{\sum_{i = 1} ^m d(e_i,S) + |S^*| \bar{d}}其中，$\{ e_1,…,e_m \}$ 是 $ S^*$ 中的 m 个极值解，并且： d(X,S) = \min_{Y \in S,Y \neq X}||F(X)-F(Y)||^2\\ \bar{d} = \frac{1}{|S^*|} \sum_{X \in S^*} d(X,S).如果解决的方案有很好的distribute 并且包括这些极值点，那么，$\Delta(S,S^*) = 0$。 $\Delta_{Line}$(不是很懂)The $\Delta_{Line}$ measures the diversity and spread of approximate solutions without the need for the $PF_{true}$ . Let $\beta$ be the mid-points of equally divided intervals in the range of [0, 1] $\left( [0,\frac{1}{N}],[\frac{1}{N},\frac{2}{N}],…,[\frac{N-1}{N},1] \right)$ where $N$ is the number of solutions in approximate the PF, then the objective line distribution ( $\Delta^i_{Line}$ ) is defined as:但是并不是很懂下标的规定。 \Delta^i_{Line}(S,\beta) = \frac{\sum_{j=1}^{|\beta|}\min_{s \in S}|\beta_j - F_i(s)| }{|\beta|}其中，$F_i(s)$ 是第 $i$ 个目标的归一化近似解，第i个目标线分布的零值表示近似PF沿第i个目标的均匀分布。$S$ 是一个粗略前沿PF。 整体线分布测度定义为: \Delta_{Line}(S,\beta) = \frac{\sum_{j=1}^{M} \Delta^i_{Line}(S,\beta)}{M}其中，$M$ 是目标函数的个数。 Region Division-based QIs (63~74)此分类的基本思想把一个特定的空间分割成许多细胞(重叠)，然后计算细胞的数量有解决方案集。这是基于一组更多元化的解决方案通常占据更多的细胞。考虑到细胞的不同形状，大多数用于扩散和均匀性的QIs都属于这一类。 它们中的一些考虑以解为中心的niche-like细胞，比如，Chi-square-like deviation, U-measure and sparsity。 有些则考虑gird-like的单元格将空间划分为多个超盒，比如，cover rate, number ofdistinct choices , diversity metric , entropy and diversity comparison indicator. 其余的考虑fan-shaped(扇形)细胞，它们用一组均匀分布的光线来分割空间(权重向量)，比如，Sigma diversity metric, M-DI and DIR. 除此之外，考虑最小能量点(s-energy)划分空间[74]也是一种潜在的方法，因为它们可以很好地表示各种形状的空间。 Chi-square-like deviation把search space (也就是自变量的空间)，分成几等分，每一个小区域叫做subregion。 v = \sqrt{\sum_{i=1}^{q+1} \left( \frac{n_i-\bar{n_i}}{\sigma_i } \right) } $q$ 是所期望得到最优解的个数。第$(q + 1)$个子区域是受支配的区域 $n_i$ 是第 $i $ 个非支配子区域实际的个数 $\bar{n}_i$ 是第 $i$ 个非支配子区域的期望个数 $\sigma^2_i$ 是第 $i$ 个非支配子区域的个数的方差 通过概率论，他可以由下面估计： \sigma_i^2=\bar{n}_i(1-\frac{\bar{n}_i}{P})$P$ 是种群尺寸 因为并不希望任何的子代落到非支配区域，因此 $\bar{n}_{q+1} = 0$。并且有，$\sigma^2_{q+1} = \sum_{i = 1}^q \sigma^2_i$ 。如果点的分布是理想的话，那么$v=0$。因此，具有良好分布能力的算法具有低偏差度量的特点。 Sparsity index好像没有公式，只有一段话。。。 大体意思就是：找到一个超平面，把每一个解映射过去，并且每一个解占有一定的大小(size=d 的 hyper-box) 越重合就越不稀疏，再把体积求和，当然体积越大越好。主要在于d的取值，不易太大，不易太小。 U-Measure(太多 再说)Cover rateCover rate is the index(指标) for the diversity of the Pareto optimum individuals. The cover rate is derived in the following steps. At first, one of the object functions is focused. Secondly, the distance between the individuals that have the maximum and the minimum values is divided into the certain number of the division. Thirdly, the division area that have the Pareto optimum individuals is counted. Fourthly, the counted number is divided by the number of division. When every divided area has at least one Pareto optimum individual, this number becomes 1. When there are no area that has the Pareto optimum individuals, this number becomes 0. Fifthly, these steps are treated for every objective function. Finally, the cover rate is determined to average the number of each objective function. When the cover rate is close to 1, it means that the Pareto optimum individuals are not concentrated on one point but they spreads. In Figure 4, the concept of the cover rate are shown, when there are two objective functions. 翻译一下就是：如上图，为一个目标函数(个人觉得如果对于一个目标，理应是在一维坐标上)，找到最大值最小值，分成确定的几份，在每个小间隔中，如果有点就为1，否则为0。依次遍历每一个函数，最后求平均值。 Number of Distinct Choices ($NDC_\mu$)从设计者的角度来看，所观察到的帕累托解集中包含的点越多，可供选择的设计选项就越多。然而，如果观测到的帕累托解在目标空间中过于接近，那么对于设计者来说，观测到的帕累托解之间的变化可能无法区分。换句话说，观察到的帕累托解的数量越多，并不一定意味着设计选择的数量越多。简而言之，对于一个观察到的帕累托解集$p=(p_1,…,p_{\bar{np}})$ ，只有那些彼此之间有足够差异的解决方案才应被视为有用的设计选项。 设数量$\mu , \ (0 &lt; \mu &lt;1)$为设计人员指定的数值，可将m维目标空间划分为$1/\mu^m$的小网格。为了简单起见，将$1/\mu$作为整数。每个网格都是指一个正方形(m维中的超立方体)，即无差异区域$T_{\mu(q)}$，其中区域内任意两个解点$p_i$和$p_j$都被认为是相似的，或者设计人员对这些解不感兴趣。下图给出了二维目标空间中的量$\mu$ 和 $T_{\mu(q)}$。 $T_{\mu(q)}(q,P)$ 表示是否有任何点$p_k \in P$属于区域$T_{\mu}(q)$。当至少有一个解点$p_k$落在无差异区域$T_{\mu}(q)$中时，$T_{\mu(q)}(q,P)$等于单元(或1)。$T_{\mu(q)}(q,P)$等于0(或0)只要$T_{\mu}(q)$区域没有解。一般来说，$T_{\mu(q)}(q,P)$可以表述为: T_{\mu(q)}(q,P) = \begin{cases} 1 & \exists p_k \in P \ p_k \in T_\mu(q)\\ 0 & \forall p_k \in P \ p_k \notin T_\mu(q) \end{cases}质量度量$NDC_{\mu}(q)$，即预先指定的m值的不同选择的数量，可以定义为: NDC_{\mu}(P)=\sum_{l_m=0}^{v-1}...\sum_{l_2=0}^{v-1}\sum_{l_1=0}^{v-1}NT_\mu(q,P)where $q = (q_1,q_2,…,q_m)$ with $q_i=\frac{l_i}{v} $ 其中，$v=1/\mu​$ ，点 $q​$ 位于目标空间m-网格线的任意交点上，坐标为$(q_1,q_2,…,q_m)​$。如本节开头所示，，如果想让$NDC_{\mu}(P)​$值较高的观察到的Pareto解集，对于预先指定的 $\mu​$ 就要有相对于较低的值(网格越密，被删去的点就越少)。 $NDC_{\mu}$ 和 cover rate 是有区别的，前者是把目标空间看作整体，并分成了很多个hyper-box；后者是分析每一个维度，最后加权平均一下。 Diversity metric(DM)规定： $P^{(t)}$ 为每一代的种群。$\mathcal{F}^{(t)}$ 是 $P^{(t)}$ 的非支配解。目标(参考点集) $P^*$ 从 $P^{(t)}$ 中确定 $\mathcal{F}^{(t)}$ , 使 $\mathcal{F}^{(t)}$ 非支配于$P^*$ 对于网格的每一个索引 $(i,j,…)$ ，并计算下面两个： H(i,j,...)=\begin{cases} 1,& if \ the \ grid \ has \ a \ representative \ point \ in \ P^* \\ 0,& otherwise \end{cases} and h(i,j,...)=\begin{cases}1,& H(i,j,...)=1 \ and \ if \ the \ grid \ has \ a \ representative \ point \ in \ F^{(t)} \\0,& otherwise\end{cases} 给 $m(h(i,j,…))$ 赋值根据该索引本身与它邻居的$h()$。同样的，用 $H()$ ，来计算 $m(H(i,j,…))$ 计算多样性衡量标准 by averaging the individual $m()$ values for $h()$ with respect to that for $H()$: D(P^{(t)}) = \frac{ \sum_{i,j,...\\H(i,j,..) \ne 0} m(h(i,j,...)) }{\sum_{i,j,...\\H(i,j,..) \ne 0} m(H(i,j,...))}在这个简单的例子中，网格的值函数 $m()$ 可以通过使用它的 $h()$ 和相邻的两个 $h()$ 维度来计算。对于一组连续的三个二进制 $h()$ 值，总共有8种可能。任何值函数的赋值方法如下: 111 是最好的分布，000 是最坏的分布。 010 或 101表示具有良好扩展的周期模式，其值可能大于 110 或 011 。例如，上述估值将使网格覆盖率为50%的近似集具有更大的分布(如1010101010)，优于具有相同覆盖但分布较小的另一集(如1111100000)。 110 或 011 的值可能超过 001 或 100，因为有更多的网格覆盖。 h(…j-1…) h(…j…) h(…j+1…) m(h(…j…)) 0 0 0 0.00 0 0 1 0.50 1 0 0 0.50 0 1 1 0.67 1 1 0 0.67 0 1 0 0.75 1 0 1 0.75 1 1 1 1.00 对于 $H()$ 使用相同的值。在目前的研究中，通过计算上述度量维度来处理两个或多个维度的超平面，而通过考虑一组移动的超盒来非常谨慎设计地上述值函数的一个高维版本。对一个包含9个盒子的二维集合的考虑如下: 作为上述计算过程的说明，下图显示了一个两目标最小化问题的一组目标点(标记为填充圆$P^*$)和一组总体点(标记为阴影和打开的方框 $P^{(t)}$ )。用阴影框标记的点是相对于目标点的非支配点( $\mathcal{F}^{(t)}$ )，用于多样性计算(这是步骤1)。这里以f2 =0平面为参考平面，将 $f_1$ 值的完整范围划分为G=10个网格。下一步，计算每个网格的 $h()$ 和 $H()$ 值。对于边界网格(极端网格和网格$(…,j,…)$ 与 $H(…,j - 1 ….)= 0$ 。 在边界处的网格，假设一个假想的相邻网格的h()或h()值为1，例如上图的虚线格子。也注意到，有的格子里有不止一个点在其中，但也就算一个。移动的三个格子，确定中间位置的数值。为避免边界效应(使用虚网格的效应)，我们将上述度量归一化如下: \bar{D}(P^{(t)}) = \frac{ \sum_{i,j,...\\H(i,j,..) \ne 0} m(h(i,j,...)) -\sum_{i,j,...\\H(i,j,..) \ne 0} m(0)}{\sum_{i,j,...\\H(i,j,..) \ne 0} m(H(i,j,...))-\sum_{i,j,...\\H(i,j,..) \ne 0} m(0)}0 为值为零的数组。仔细想想就会发现，计算上述$\bar{D}(P^{(t)})$项和边界网格调整时$H(i,j…) \ne 0$ 允许使用一种通用方法来处理具有断开的pareto最优前端的问题。该度量不包括不存在参考解的网格的值函数。 如果不知道帕累托最优前沿(特别是对实际问题)，则可以用以下方法确定目标集。 首先，MOEA运行T代，并存储按代计算的总体($P^{(T)}， t = 0,1…T)$)。 然后,将每个种群的非支配成员 $\mathcal{F}^{(t)}$ 组合在一起，则target set 就是这些的总和。 P^*=Non-dominated(\cup^T_{t=0}\mathcal{F}^{(t)}) Diversity comparison indicator (DCI)很巧这里介绍了DM的缺点： a reference set，它要求是均匀分布在PF，这是必需的，以便准确反映分布的optimal front。也是要求，解决方案参考集近似近似的解决方案的数量以保证理想的分布近似可以达到最佳的DM值(一个)。这些要求在多目标优化问题中通常是不可用的。 DM需要访问网格中的每个hyperbox来估计分布，这对数据结构和计算成本都带来了很大的挑战。对于m个目标的优化问题，需要考虑 $r^{m-1}$ 超盒，其中r为每个维度的划分数。 在超盒的分布估计中，DM需要通过一个值函数给每个相邻的超盒分配一个合适的值，以区分其邻域内解的不同分布。由于超盒的邻居数量随着目标数量的增加呈指数增长(m维超盒最多有($3^m$-1)个邻居)，当涉及大量目标时，很难定义准确反映不同分布的值函数。 由于网格中解的邻域的指定，DM可能无法给出具有大量目标的近似的精确分集结果。DM中解的邻域的设置是基于解的网格坐标的曼哈顿距离，而不是它们的欧氏距离。它可能会误导性地消除相邻解，但将更远的解视为相邻解。 网格的位置和大小在该指标中具有重要意义。设置网格区域不应涉及整个目标空间，而应针对给定问题的帕累托前沿不远的区域，因为不同近似有意义的多样性比较的前提是它们已经接近最优前沿[50]。假设较高和较低的网格边界为：$LB=(lb_1,lb_2,…,lb_m)$ and $UB=(ub_1,ub_2,…ub_m)$ ,m 是目标函数的个数，如果一个解向量$(q_1,q_2,…,q_m)$ 在 $LB$ 与 $UB$ 之外，(也就是说 $k \in \{ 1,2,…,m \}:q_k ub_k$ ) 那么此解向量在indicator calculation 中会被忽略掉。 在将所提出的DCI应用于不同问题时，网格边界可以由用户定义的“满足区域”来确定，也可以由问题的理想点和最低点来设置。“满足区域”是用户的一种估计，即在该区域中所获得的解被认为满足收敛性的质量要求。当用户没有明确规定他/她“满意的地区,”网格边界可以通过给定问题的理想点和最低点(下图所示),理想点和最低点是两个重要的概念在多目标优化中,当PF是未知时他们可以通过一些有效的方法估计。在这里，将一个问题的理想点和最低点所构成的区域的轻微松弛看作网格环境： ub_k = np_k + \frac{np_k - ip_k}{2 \times div}\\ lb_k = ip_k其中，$ip_k$ 是第 $k$ 个目标的理想点，$np_k$ 是第 $k$ 个目标的最低点，$div$ 是一个常数(一个维度中目标空间的划分数，例如下图为5) 根据网格的边界和划分的数量，第 $k$ 个目标中的超盒大小 $d_k$ 可以形成如下图所示： d_k = \frac{ub_k-lb_k}{div}在这种情况下，通过下边界和超盒尺寸可以确定解在帕累托前近似中的网格位置如下(向下取整): G_k(q)=\lfloor (F_k(q)-lb_k)/d_k \rfloor其中$G_k (q)$ 表示第 $k$ 个目标中解 $q$ 的网格坐标。$F_k(q)$ 是 $q$ 在第 $k$ 个目标中的真实值。上图中，A，B，C，D 的坐标一次为 (0,4)，(0,3)，(2,2)，(4,0)。以下在引入关于距离的两个概念 $h_1,h_2$ 是网格中的两个超立盒子，那么两个网格的距离为： GD(h_1,h_2)=\sqrt{\sum_{k=1}^m (h_1^k - h_2^k)^2}$h_1^k，h_2^k$ 是 $h_1,h_2$ 的在第 $k$ 个目标函数的坐标。$m$ 是目标函数总数。例如 B 与 C 距离为 $\sqrt{(0-2)^2 + (3-2)^2} = \sqrt{5}$ . P 是也该粗略解集， h是一个超方体盒，从 P 到 h的最短格距离为： D(P,h) = \min_{p \in P} \{ GD(h,G(p)) \}例如，上图中 在粗略解集A，B，C，D中距坐标为(1,3)的超方体盒子的距离为 $GD(h^{(1,3)},G(B)) = 1$ 。显然，在网格环境中解分布均匀且分布广泛的近似，其到所有超盒的平均距离值较低。 不同的帕累托前近似解可能位于不同的超盒中。在这里，我们只考虑在混合逼近集中非支配解所在的超盒，因为受支配解的多样性对用户来说可能毫无意义。对于一个近似解，如果它的解覆盖或接近所有被考虑的超盒，那么与其他近似相比，它将获得一个相对较好的多样性;另一方面，如果它的解决方案远离大多数这些超盒，则会获得相对较差的多样性。算法1给出了计算待比较近似的DCI值的主要步骤。 贡献度(算法1的第6行)反映了近似对超盒的贡献，并由它们之间的距离决定。对于近似，如果所考虑的超盒中至少存在一个解，则可获得该近似对超盒的最大贡献程度。如果从近似值到超框的距离大于指定的阈值即，则贡献度为0。具体地说，近似P对超盒h的贡献程度定义为： CD(P,h) = \begin{cases} 1 - D(P,h)^2 / (m + 1) &d(P,h) < \sqrt{m+1}\\ 0 &d(P,h) \geq \sqrt{m+1} \end{cases}值得指出的是，我们将网格距离的阈值设置为$\sqrt{m+1}$，是为了保证相邻的两个个体始终能够交互(即，它们所在的超盒总是相邻的)。直观地说，如果两个超盒的个体可以任意接近，那么它们应该被视为邻居(在个体之间没有另一个超盒)。显然，满足上述条件的最远的两个超盒是网格距离为$\sqrt{m}$的对角超盒。由于超盒之间的网格距离始终为离散值$\sqrt{0},\sqrt{1},…,\sqrt{m},\sqrt{m+1}…$，将阈值设置为$\sqrt{m+1}$，只是使这些超盒对角相邻，在计算贡献度时可以相互作用。 图3为不同目标数下贡献度函数曲线。注意，贡献度取一个离散值，因为$D(P,h) \in \{\sqrt{0},\sqrt{1},…,\sqrt{m},\sqrt{m+1}…\}$。从图中可以看出，一些观察结果如下: 贡献度取0到1之间的值。在一定范围内，从近似到超盒在一定范围内，它单调地减小。 hyperbox的邻域半径随着目标数量的增加而增加。这表明，当目标数量增加时，可以考虑更大范围的个体进行交互。 当距离变量D(P, h)相等时，贡献度随着目标个数的增加而增加。这种增加似乎是合理的，因为随着网格中超盒总数的增长，超盒之间的相对距离变得更小。 总体而言，贡献度函数不仅考虑了近似到超盒的距离信息，还考虑了目标个数不同的网格环境的性质，对目标个数的变化具有良好的适应性。实际上，任何形式的函数都可以通过记住上述性质来赋值为贡献度函数。为了简单起见，这里使用二次函数。 根据贡献度函数，近似的DCI值是[0,1]区间内的一个数值。需要重申的是，DCI只是评估不同的帕累托前近似的相对分布质量，而不是为单个近似提供分布的绝对度量。最佳价值(即由近似得到的DCI = 1)不能反映其在整个帕累托前缘的均匀分布。相反，它表明该近似比其他近似有一个完美的优势。 上图展示了DCI的计算过程，有三个二元目标问题的pareto approximation $P_1,P_2,P_3$ ，并放在了网格环境中，有11个超方盒(灰色)被决定，其中解A，B并没有考虑其中，因为他们在混合解中被支配了。然后，对于每个超盒，根据前面提到的公式式计算三种近似的贡献度。比如，当考虑$h^{0,7}$ 时，$P_2$ 的贡献值为1，因为它在超方盒中。对于$P_1$ 来说：$1-1^2/3=2/3$ 作为$D(P_1,h^{0,7}) = 2/3$ ，对于$P_3$ 为0，因为$\sqrt{10} &gt; \sqrt{3}$ 。最后，根据算法1(第10行)求出各近似对这些超盒的平均贡献度，分别为：0.848，0.606，0.515。 M-DIM-DI 是在 DCI 的基础上修改的。 在DCI方法中，将各种算法的NDFs(non-dominated fronts)集合在一起，识别出一组帕累托最优解。使用由网格划分参数定义的网格，将每个算法的贡献与组合的帕累托最优解进行比较。 假设有两组帕累托前近似 $P_1$ 和 $P_2$ ，如下图所示。在这种情况下，$P_2$ 是组合的Pareto front，它的DCI度量是最高的(值1)，但是我们可以看到，这个值并没有反映出在front的极限之间的目标空间中解的均匀分布。在没有关于POF(Pareto Optimal Front)的任何资料的情况下，如果假定有一个连续的front，$RTF$ 很可能提供尽可能最好的解决办法。 在M-DI中，多样化是相对于RPF(Reference Pareto Front：单位截距在超平面上均匀分布的一组点)计算的。Nadir and Ideal point 计算方式与 DCI 相同。在RPF上的reference的数量 $W$ ，与在优化进程期间的人口尺寸 $N$ 有关 。For example, a population of 90 used for a 3-objective optimization problem would mean use of 91 reference points on the RPF. 其中 $CD(P,h)$ 仍不变，$h$ 是被RPF所占据的hyper-boxes。而不是在DCI 中的把所有解集合在一起，取出非支配解所占的hyper-boxes，因此： M-DI = \frac{\sum_{i=1}^{|h|}CD(P,h_i)}{|h|}EntropyIdeal/good points： 将理想点定义为目标空间中的一个点，该点的分量分别由目标函数的约束最小化得到： Minimize \ f_i(x) \quad s.t.:x \in DNadir/bad points： 在此论文中是，在本文中，我们任意地高估了目标的范围，以至于没有遇到违反估计上限的设计点。 Influence Function： 在决策空间中，第 i 个解的影响函数$\Omega_i:F^m \rightarrow R$ ，$\Omega_i$ 是随第 i 个解而下降的函数，种类很多，本轮中选择 Gaussian influence function。 \Omega(r) = \frac{1}{ \sigma \sqrt{2 \pi} } e^{-r^2/2\sigma^2}Density Function： 将可行目标空间各点的密度函数定义为各解点影响函数的集合，设共有 N 个解点，可行目标空间 $F_m$ 中任意点 $y$ 处的密度函数可得： D(y) = \sum_{i=1}^{N} \Omega_i(r_{i \rightarrow y})$r_{i \rightarrow y}$ 是一个标量，它展示了 $y$ 与 第 $i$ 个解点的欧式距离。$\Omega_i( . ) $ 是 第 $i$ 个点的影响函数，下图展示了在一维里一些点的影响距离。 Entropy： Claude Shannon 引入信息论熵来测量随机过程的信息含量，从而建立了信息论领域。从那时起，熵的许多不同的应用在不同的领域有他们自己的解释和定义。假设一个随机过程有n个可能的结果第i个结果的概率是。这个过程的概率分布可以表示为： P = [p_1,...,p_i,...,p_n];\sum_{i=i}^{n}p_i=1; p_i \geq0这个概率向量有一个相关的Shannon s熵，H的形式这个概率向量有一个相关的Shannon s熵，H的形式： H(P) = - \sum_{i=1}^n p_i \ ln(p_i)其中， 当 $p_i = 0$ 时，$p_i \ ln(p_i)=0$。最大值为 $H_{max}=ln(n)$ 当所有的值都相同的，最小值为0，当一个为1，其他的所有均为0。事实上，香农熵衡量的是 $P$ 的平整度，即。，如果向量中各分量的值近似相等，则熵值很大，但如果各分量的值相差很大~概率分布不均匀!，对应的熵值较低。 如下图所示 网格的尺寸是 $a_1 \times a_2$ 在feasible domain。对每一个密度函数，$D_{ij} = D(y_{ij})$，$a_1$ 和 $a_2$ 的数量确定为每个单元格的大小小于或等于无差异区域(无差异区域定义为任意两个解点被认为是相同的单元格大小，或决策者对这些解不感兴趣)。$a_1$ 和 $a_2$ 的数量可以根据设计者的经验或对类似问题的认识主观确定；或者客观地基于可用的计算能力和期望的精度。假设非常小的网格大小有助于提高准确性，但它也增加了计算熵的计算负担，这反过来可能使质量评估过程非常缓慢，甚至在计算上不可行。显然，适当的网格大小取决于问题，并且在不同的情况下有所不同。因为这些项的和。在香农熵的定义中，熵是1，我们定义一个归一化密度，$\rho_{ij}$ ，为: \rho_{ij} = \frac{D_{ij}}{\sum_{k_1=1}^{a_1}\sum_{k_2=1}^{a_2} D_{k_1k_2}}实际上，上述归一化密度的定义对于空解集的定义并不好，这就是为什么在密度函数的定义中假设解集是非空的原因。我们将给空解集的熵赋值为0来表示最坏的情况，即0的多样性。现在我们有: \sum_{k_1=1}^{a_1}\sum_{k_2=1}^{a_2} \rho_{k_1k_2} = 1\\ \rho_{k_1k_2} \geq 0,\forall k_1,k_2这样一个分布的熵可以定义为: H = -\sum_{k_1=1}^{a_1}\sum_{k_2=1}^{a_2} \rho_{k_1k_2}ln(\rho_{k_1k_2})并且，对于m维目标空间，将目标空间中的可行域划分为a13a23。3am细胞，熵定义为: H = -\sum_{k_1=1}^{a_1}\sum_{k_2=1}^{a_2}...\sum_{k_2=1}^{a_m} \rho_{k_1k_2...k_m}ln(\rho_{k_1k_2...k_m})熵值越大的解集在目标空间的可行域内分布越均匀，覆盖范围越广。 Sigma diversity metric提出了计算目标空间中解的位置的Sigma多样性度量。 如下图： 上左图，对于每一个线，都有$f_2 = af_1$，因此，$\sigma $ 便为： \sigma = \frac{ f_1^2 - f_2^2 }{f_1^2 + f_2^2}所有的在此线上的点都满足 $f_2 = af_1$ ，也就都有相同的 $\sigma = \frac{1-a^2}{1 + a ^2}$ 在一般情况下，$\sigma$ 被定义为 $ C_m^2$ 个元素的向量，其中m是目标空间的维数。在这种情况下，$\sigma$的每个元素都是上式中两个坐标的组合。例如f1、f2、f3三个坐标，定义如下:(如上又图) \sigma =\begin{pmatrix} f_1^2 - f_2^2 \\ f_2^2 - f_3^2 \\ f_3^2 - f_1^2 \end{pmatrix} /(f_1^2 + f_2^2 +f_3^2)例，$\sigma = (0 \ 0.5 \ -0.5)$ 时，$f_1 = 1,f_2 = 1,f_3 = 0$ 带入上面即可。 这意味着目标空间中的每个点都可以用向量来描述。直线上的所有点都有相同的向量在非常接近的直线上的解都有相似的向量。这是用来构造多样性度量的思想。 在计算近似集的多样性之前，必须先计算一组reference lines(参考线)。参考线数必须等于近似解的个数。必须强调的是，每个目标的参考线必须计算一次，并且可以存储在一个表中。那么Sigma多样性度量可以计算如下: 计算参考线 计算每条参考线的向量(参考向量 reference sigma vector)。 在每个参考向量旁边保留一个初始值为零的二进制标记。每个引用的旗帜 $\sigma$ 向量为 1,当至少有一个解决方案有一个向量 $\sigma$ 等于它或在一个距离(欧式距离)低于d。d的值取决于测试函数,但是它应该减少当有大量的参考线时。 计数器C对标记为1的引用行进行计数，多样性度量D变为： D = \frac{C}{number \ of \ reference \ lines}Sigma多样性度量表示的是在目标空间中非支配解的分布百分比 在极值解位于坐标轴上的情况下，我们可以得到D的一个高值，即,100%。对于离散解集或不连通解集，D的值永远达不到最大值。 由上式中的D可知，如果D的值很高，就意味着解的分布很好。但当D很小时，它意味着解是： 集中在空间的一部分 分布在前沿的小群体中 的确，这两种解决方案之间存在差异。下图显示了具有相同D值的两组解之间的差异。这两组解有不同的扩展，Sigma多样性度量无法区分它们。 红线是红点所占的reference lines；黑线是红黑点所占的reference lines。可以看到都是6条！ $\mathcal{M} ^* _2$Analogously, we define one metric $\mathcal{M}_2^*$ and on the objective space. Let $Y’,\bar{Y} \subseteq Y$ be the sets of objective vectors that correspond $X’$ to $\bar{X}$ and , respectively, and $\sigma ^* &gt; 0$ and $|| \cdot ||^*$ as before: 公式： \mathcal{M}^*_2({Y'}):=\frac{1}{|Y'-1|}\sum _{p'\in Y'} \{q' \in Y'; ||p'- q'||^* > \sigma ^*\}]]></content>
      <categories>
        <category>indicators</category>
      </categories>
      <tags>
        <tag>MOEA</tag>
        <tag>indicator</tag>
        <tag>diversity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[QIs for Cardinality]]></title>
    <url>%2F2019%2F01%2F28%2Fcardinality%2F</url>
    <content type="text"><![CDATA[这部分要么太难，要么太简单。。。。怀疑自己智商 介绍基数的QIs可以归结为一个简单的概念——计算非支配解决方案的数量。基于基数的QIs所具有的一个可取(必要)的属性是，在考虑的集合中添加一个不同的非支配解决方案应该能够改进(而不是降低)评估结果。这(弱)单调的概念是一致的。下面列出了10个基数QIs(项目45-54)： 根据Pareto最优解的参与程度，基于基数的QIs可以分为两类(项目45-48和项目49-54)。 一种是直接考虑集合中的非支配解，例如 the indicators cardinality 𝐷 number of unique nondominated solutions overall nondominated vector generation (ONVG) ratio of nondominated individuals 另一类是比较解集中的非支配解(nondominated solutions)和问题的帕累托最优解(Pareto optimal solutions)，该类中的QIs通常返回属于帕累托最优集的非支配解与最优集大小的比值，(例如：C1，ONVG ratio）,或者或者与解集本身的比值(例如，C2，error ratio) 除此之外，还有其他一些指标，它们只是简单地计算属于最优集的解决方案的数量。 虽然这里描述的是对最终MOEA性能的度量，但是其中许多度量也可以用于跟踪世代总体的性能。然后，除了一个总体性能度量之外，它还指示执行期间的性能(例如，到MOEA optimu的收敛速度)。虽然使用了两个目标的例子，但是这些指标可以扩展到具有任意数量的目标维度的PF。 由于解决方案集的基数通常几乎没有与帕累托前沿的代表性相关的信息，因此通常认为它不如其他三个质量方面重要。然而，如果优化器能够找到问题的很大一部分帕累托最优解决方案，那么评估基数质量可能会变得更加合理。这对于一些组合多目标优化问题尤其适用，其中帕累托最优解的总数很小。在这类问题中，计算得到的帕累托最优解的个数是反映解集质量的可靠指标。事实上，这种评价在一些组合问题的早期研究中经常使用。 Error ratio此indicator与onvg与onvg ratio 出自同一本书，并且有如下定于，为了方便引用原文： 简而言之：$P$ (也就是 pareto optimal set 包含于solution set) 是针对自变量来说的 也就是decision space。 $PF$ (也就是 Pareto Front ) 是针对目标函数值来说的，也就是objective space An MOEA reports a finite mumber of vectors in $PF_{known}$ which are or are not members of $PF_{true}$. If they are not members of $PF_{true}$ the MOEA has erred or perhaps not converged. This metric is mathematically represented by: E=\frac{\sum_{i=1}^{n}}{n}e_iwhere n is the number pf vectors in $PF_{known}$ and e_i = \begin{cases} 0 & if \ vector \ i,i=(1,...,n) \in PF_{true},\\ 1 & otherwise \end{cases}$E=0$，表明$PF_{known}$都在 $PF_{true}$。 $E=1$，表明$PF_{known}$中一个都不在 $PF_{true}$。 上图的值：$E=\frac{2}{3}$ 。 我们还注意到一个类似的度量，它度量由另一个 $P_{true}$ 支配的$P_{known}$ 中的解决方案的百分比。 然而，由于ER只在帕累托最优解中起作用，它可能会带来一些反直觉的情况。例如，在一个集合中添加更多的非支配解决方案可能会导致更差的分数。因此，考虑比较集本身中的非支配解可能是更好的选择，而且也不需要帕累托前沿。 Overall Nondominated Vector Generation and Ratio(ONVG)测试的MOEAs 每一代把 $P_{current}$ 添加到 $P_{known}$ 中，可能导致不同的数量的$P_{known}$ 。这个测量度计算的是在MOEA期间所找到的所有非支配解的数量，定义如下： ONVG = |PF_{known}|Schott 使用这个测量标准(尽管是在帕累托最优集上定义的，例如$|P_{known}|$ ) 。基因型或表现型地的定义这个测量标准可能是偏好问题，但是我们再一次注意到多个解可以映射到相同的向量上，或者换句话说，$|P_{known}| \geq |PF_{known}|$ (多对一)。尽管计算非支配解的数量可以让我们了解MOEA在生成所需解方面的有效性，但它并没有反映出$|P_{known}|$中的向量与$|PF_{known}|$ 之间的“距离”有多“远”。此外，太少的向量和$|PF_{known}|$的代表性可能很差;太多的向量可能会压倒DM。 ONVG Ratio很难确定$|ONVG|$的最佳值是多少。$PF_{known}$ 的基数可能在不同的计算分辨率下发生变化，也可能在拖把之间存在差异(可能是根本的)。报告$PF_{known}$的基数与离散$P_{true}$的比值可以让我们对找到的非支配向量的数量与要找到的存在向量的数量有一定的感觉。然后将这个度量定义为: ONVGR = \frac{|PF_{known}|}{|PF_{true}|}上图中，可知 $ONVG=3$，$ONVGR=0.75$。 C1如果已知由所有有效解组成的参考集R，那么看起来最自然的质量度量就是找到的参考点的比例。度量可以用以下方式定义： C1_R(A)=\frac{|A \cap R| }{ |R| }C2如果参考集不包含所有的非支配点，那么A中的被R所非支配的点集也许是属于非支配解集上的，这种情况，使用下列方法也许更可行： C2_R(A)=\frac{ | \{ u \in A | \ \nexists r \in R , r \succ u \}| }{|A|}然而，这些主要措施也有一些明显的缺点。他们对近似值的改进无动于衷。例如，考虑图11中所示的两个近似参考集，这两个近似是针对一个双目标背包问题得到的。显然，近似1比近似2好得多。近似1中的所有点都非常接近参考集，它们覆盖了参考集的大部分区域。然而，这两种近似的测度值都是相同的C1和C2。 图12中的示例说明了主要度量的另一个缺点。这两个近似由5个不占主导地位的点组成，所以它们的基数测度是相等的。然而，构成逼近3的所有点在目标空间中都是非常接近的，即它们代表了非支配前沿的同一区域。另一方面，近似值4的点分散在整个参考集合中。它们携带着丰富得多的信息，例如关于可能的目标范围的信息。这个例子表明，对于基本测度，无论它们的接近程度和关于非支配集形状的信息如何，逼近中的每个点都具有相同的权重。 Ratio of non-dominated individuals (RNI)这个绩效指标被定义为非主导个体的比率(RNI)对于给定的总体X， RNI(X)=\frac{nondom\_indiv}{P}nondom_indiv是种群X中非支配的个体数量，P是种群X的大小。因此，RNI = 1的值表示种群中所有的个体都是不受支配的，RNI = 0表示种群中没有一个个体是非支配的。由于通常需要大于零的总体大小，所以在$0 \leq RNI \leq 1$的范围内总有至少一个非支配个体。]]></content>
      <categories>
        <category>indicators</category>
      </categories>
      <tags>
        <tag>MOEA</tag>
        <tag>indicator</tag>
        <tag>CardinalityQI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[QIs for Uniformity]]></title>
    <url>%2F2019%2F01%2F26%2Funiformity%2F</url>
    <content type="text"><![CDATA[又看了好几天的剧。。。罪恶感啊 介绍均匀性的质量指标衡量集的解分布的均匀程度。由于解集的质量可以看作是其表示PF的能力，所以一个均匀分布的解集比一个非均匀分布的解集提供更好的帕累托前沿表示，可以认为它具有更好的质量。理想的均匀性QI应该排在由完全相等的解组成的集合的最高位置，对这个集合的一点干扰会导致更糟糕的评估结果。具体的indicators如下: 通常可以通过测量解之间距离的变化来评价解集的均匀性。这个类中的许多QIs都是按照这些思路设计的，例如，$spacing(SP)$[39],$deviation \ measure \Delta$[35] , $ uniformity \ distribution$[43], $\ minimal \ spacing$[38], $ spacing \ measure$[37] 和$uniformity$[41]。 其他则考虑解之间的最大最小距离[40 36 44]，和构建集群[34]或最小生成树[42]。 Minimal spacing前言先介绍spacing： S=\sqrt{\frac{1}{|Q|} \sum_{i=1}^{|Q|}(d_i-d)^2 } $d_i=min_{k\in Q\ and\ k \ne i}\sum_{m=1}^M|f_m^i-f_m^k|$ 。离$Q_i$最近的点的距离，距离公式每一维度(目标函数)的差值的平均值。 $f_m^i​$：在最后的非支配解$Q​$中第$i​$个解的第$m​$个目标函数值。 $d$：所有$d_i$的平均值。 $S$越接近0越说明解集是更加的均匀分布的帕累托最优前沿。 但此算法在上图所示中便展现出缺点： 可以直观的看出fig(b)的一致性比fig(a)要好，但通过公式却体现出相反的结论。 原因：离a最近的是b，离b最近的a，离c最近的是d，离d最近的是c。那么S值一定比fig(b)的低。而忽略了fig(a)中b与c之间很大的距离。 正文此算法更像是一个流程，总结下来就是把每个解看成一个点，每一个点只访问一次，求把所有点连起来的距离总和的最小值。 把所有点设为unmarked状态，随机找一个解，作为seed，此点变为marked。 在所有的unmarked点中，找到离刚刚设为marked/seed点最近的点。此点设为marked， 依次循环(2)，直至所有点均是marked，并记录路径的距离和。 把每个点都作为seed，取路径和最小。最后再处以$|Q|-1$ 其中，由于每个目标函数的性质可能不同，他们的取值范围也就可能不同，距离公式归一化修改为： d_i=\frac{1}{|F^{max}_m-F^{min}_m|}min_{k\in Q\ and\ k \ne i}\sum_{m=1}^M|f_m^i-f_m^k|$F^{max}_m$，$F^{min}_m$第m个目标的最大值和最小值。 如此算法,易得fig(b)的值会比fig(a)更小，更有效！ Spacing(SP)SP 测量一组解集之间解的距离变化。特别的，$A = \{a_1,a_2,…,a_N \}$, SP(A)=\sqrt{\frac{1}{N-1} \sum^N_{i=1} (\bar{d} - d_1(a_i,A/a_i))^2 }其中： $\bar{d}$ 是所有 $d_1(a_1,A/a_1)$ $d_1(a_2,A/a_2)$ $d_1(a_2,A/a_2)$,…, $d_1(a_N,A/a_N)$ 的平均值，$d_1(a_i,A/a_i)$ 是 $a_i$ 对 $A/a_i$ 的一范数(Manhattan distance)， d_1(a_i,A/a_i)=\min_{a \in A/a_i} \sum_{j=1}^m|a_{ij}-a_j|$m$ 是目标函数的个数，$a_{ij}$ 是第 $a_i$ 的解的第 $j$ 个目标的值。SP被最小化;数值越低，均匀性越好。SP值为0表示解集的所有成员在曼哈顿距离的基础上间距相等。请注意，SP仅测量解决方案的“邻域”分布。即使与MS一起工作，SP也不能涵盖集合的多样性质量，尽管这两个指标在文献中经常一起使用来达到这一目的。以下图为例，图2(b)和(c)中的解集均采用SP和MS满分;然而，它们分别位于帕累托前沿的边界和极端点。 Spacing metric假设有两个目标函数， spacing = \left[ \frac{1}{N-1}\sum_{i=1}^{N-1}(1 - \frac{d_i}{\bar{d}}) \right]为了计算$d_i$，我们考虑第一个目标，将$PF$中的所有点按升序排序。接下来，为了计算$d_i$，我们使用下面的公式: d_i = \sqrt{(f_1(\vec{x_i} )-f_1(\vec{x_i+1}) )^2+((f_2(\vec{x_j} )-f_2(\vec{x_j+1}) )^2}$\bar{d}$ 便为 $d_i$ 的和的平均值。 Deviation measure $\Delta$由于优化解的多样性是多目标优化中的一个重要问题，我们设计了一种基于最终总体中最优非支配前沿解之间连续距离的度量方法。将得到的第一组非优解与均匀分布进行比较，计算偏差如下:(这个有特殊的背景才可适用) \Delta = \sum_{i=1}^{|\mathcal{F}_1|}\frac{|d_i-\bar{d}|}{|\mathcal{F}_1|}$\mathcal{F} = \{ \mathcal{F}_1,\mathcal{F}_2,… \}$ 是所有的非支配前沿。 为了确保这种计算考虑到解在真实前沿的整个区域的扩散，我们将边界解包含在非主导锋$\mathcal{F}_1$中。对于离散的帕累托最优前沿，我们为每个离散区域计算上述度量的加权平均值。在上式中，$d_i$是目标函数空间中最终总体的第一非支配前沿上两个连续解之间的欧式距离。参数$\bar{d}$是这些距离的平均值。 Cluster ($CL_\mu$)需要先介绍 Number of Distinct Choices ($NDC_\mu$). $NDC_\mu$从设计者的角度来看，所观察到的帕累托解集中包含的点越多，可供选择的设计选项就越多。然而，如果观测到的帕累托解在目标空间中过于接近，那么对于设计者来说，观测到的帕累托解之间的变化可能无法区分。换句话说，观察到的帕累托解的数量越多，并不一定意味着设计选择的数量越多。简而言之，对于一个观察到的帕累托解集$p=(p_1,…,p_{\bar{np}})$ ，只有那些彼此之间有足够差异的解决方案才应被视为有用的设计选项。 设数量$\mu , \ (0 &lt; \mu &lt;1)$为设计人员指定的数值，可将m维目标空间划分为$1/\mu^m$的小网格。为了简单起见，将$1/\mu$作为整数。每个网格都是指一个正方形(m维中的超立方体)，即无差异区域$T_{\mu(q)}$，其中区域内任意两个解点$p_i$和$p_j$都被认为是相似的，或者设计人员对这些解不感兴趣。下图给出了二维目标空间中的量$\mu$ 和 $T_{\mu(q)}$。 $T_{\mu(q)}(q,P)$ 表示是否有任何点$p_k \in P$属于区域$T_{\mu}(q)$。当至少有一个解点$p_k$落在无差异区域$T_{\mu}(q)$中时，$T_{\mu(q)}(q,P)$等于单元(或1)。$T_{\mu(q)}(q,P)$等于0(或0)只要$T_{\mu}(q)$区域没有解。一般来说，$T_{\mu(q)}(q,P)$可以表述为: T_{\mu(q)}(q,P) = \begin{cases} 1 & \exists p_k \in P \ p_k \in T_\mu(q)\\ 0 & \forall p_k \in P \ p_k \notin T_\mu(q) \end{cases}质量度量$NDC_{\mu}(q)$，即预先指定的m值的不同选择的数量，可以定义为: NDC_{\mu}(P)=\sum_{l_m=0}^{v-1}...\sum_{l_2=0}^{v-1}\sum_{l_1=0}^{v-1}NT_\mu(q,P)where $q = (q_1,q_2,…,q_m)$ with $q_i=\frac{l_i}{v} $ 其中，$v=1/\mu$ ，点 $q$ 位于目标空间m-网格线的任意交点上，坐标为$(q_1,q_2,…,q_m)$。如本节开头所示，，如果想让$NDC_{\mu}(P)$值较高的观察到的Pareto解集，对于预先指定的 $\mu$ 就要有相对于较低的值(网格越密，被删去的点就越少)。 正文上一节的质量度量，即 $NDC_{\mu}(P)$。然而，仅使用这个质量度量，无法正确解释集群现象。例如，假设有一个预先指定的m值，观察到的Pareto解集$P_1$提供了10个不同的解，有$NDC_{\mu}= 10$。现在假设，这里有另一组解$P_2$ 它提供了100个解，$NDC_{\mu}=10$ 。可以看出，设计人员并不希望看到解决方案集P2，因为该集中的许多解决方案可能是集群的。因此，引入了质量度量集群$CL_\mu(P)$: CL_\mu(p)=\frac{N(P)}{NDC_\mu(P)}其中$N(P)$为观察到的帕累托解的个数。在理想情况下，得到的每一个帕累托解都是distinct的，那么数量$CL_\mu(p)$的值等于1。在所有其他情况下，$CL_\mu(p)$都大于1。此外，集群数量$CL_\mu(p)$的值越高，解决方案集的集群化程度就越高，因此解决方案集的受欢迎程度就越低。 Hole relative size当我们看到这组度量标准，特别是间距度量(spacing metric)标准时，我们意识到它们有时在显示沿帕累托边界(帕累托边界上的一个洞)的点分布的不连续时是不准确的。因此，为了克服这个缺点，我们设计了一种新的度量，称为孔相对大小(hr)。 HRS度量允许计算沿帕累托边界分布的点的最大孔的大小。然后用孔的大小除以点与点之间的平均间距进行归一化。如下所示： HRS = \frac{\max_i d_i}{\bar{d}}$d_i$ 两个相邻解的距离。 $\bar{d}$ 点间的平均距离。 这个度量比间距度量提供的信息更多，但是，在尝试规避间距度量中的一个缺点时，我们在HRS度量中引入了另一个缺点:它不能在不连续的帕累托边界上工作。事实上，不连续的帕累托边界有天然的漏洞。因此，对于帕累托边界上的固定数量的解，HRS度规总是以高概率测量相同的值。因此，我们建议在不连续测试问题中不要使用这个度量。 Uniformity assessment(没看懂，心力憔悴)]]></content>
      <categories>
        <category>indicators</category>
      </categories>
      <tags>
        <tag>MOEA</tag>
        <tag>indicator</tag>
        <tag>UniformityQI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[QIs for Spread]]></title>
    <url>%2F2019%2F01%2F23%2Fspread%2F</url>
    <content type="text"><![CDATA[玩了好几天，看了好多剧，所以这几天的进度稍微有点慢，另外，《一起同过窗》真香！ 延展特性涉及解集覆盖的区域。一个具有良好分布的解集应该包含来自PF每个部分的解集，而不遗漏任何区域。然而，大多数扩展的QIs只度量解决方案集的范围(extent)。下表为总结： 这些QIs通常考虑the range formed by the extreme solutions of the set(由集合的极值解构成的范围)，例如maximum spread，和它的变体[25] [27] [28] [29] [30] [33]，或者 考虑the range enclosed by the boundary solutions of the set(集合的边界解所围成的范围)，实例如下图： 只考虑这些解的QIs可能会忽略PF的内部区域。 幸运的是，确实存在一些为解决方案集的整个覆盖范围设计的QIs。 例如，[23]测量解集的支持点的面积和长度；[24]计算解集在PF的最大不相似度；[31]将每个解与解集的其余解的不同之处相加。 Maximum Spread (MS)$MS(or \ \mathcal{M}_3^*)$ 被广泛的使用于延展性indicator。它通过考虑每个目标的最大范围来度量解决方案集的范围，公式为： MS(A) = \sqrt{\sum^m_{j=1} \max_{a,a' \in A} (a_j-a_j')^2 }m 是目标函数的个数。MS应求极大值。值越高，说明的可延展性越好，在二元目标情形下，非支配解集的MS值为其两个极值解的欧氏距离。 但是，如前所述，MS只考虑集合的极值解，不能反映扩散的特性。此外，由于它不涉及集合的收敛性，远离PF的解通常对MS值有很大贡献。这很容易引起误导性的评价。例如，一个解集集中于PF的一小部分，但有一个离PF很远的离群值，那么它的MS值就很好。为了解决这一问题，引入帕累托前缘的范围作为评价的参考，例如[27] [28]。 Extension规定： \min_{x \in X} F(x) = (f_1(x),f_2(x),...,f_l(x))\\ U_i = \max_{x \in Pareto(U)}f_i(x)\\ L_i = \min_{x \in Pareto(U)}f_i(x)\\ i=1,...,l令：$P_r = \{ F_1^1,…,F_l^1 \}$，其中，$F_i^1=(L_1,…,L_{i-1},U_i,L_{i+1},…,L_l),[i=1,…,l]$ 规定： d_r^p=\min\{ d(p_r,p)|p \in P \},p_r \in P_r因此，得表达式： EX=\sqrt{\sum(d_r^p)^2 }/l易知，$d_r^p$ 越小，说明有更好的延展性。 如果是三维图的话，$P_r$ 分别如下： Modified MS(勿看，瞎记的)只有知道正常和期望的条件，才能定义和避免异常和不期望的条件，例如解在目标空间的次优区域的分散，或者收敛到感兴趣区域之外的次优解。换句话说，为了克服收敛性和多样性的矛盾要求，需要一个应用相关的尺度来定义低、理想和高多样性的近似概念，这在高维问题中尤为明显。在所提议的机制的上下文中，决策人员DM1(通常，最好是领域专家)只需要对所需折衷表面的定义极值提出近似估计。这些极值将作为包含理想的PF的超立方体的顶点。 I_s = D / \left[ \sum_{m=1}^M \left( \max_{z_* \in Z_*}\{z_{*_m}\} - \min_{z_* \in Z_*} \{z_{*_m} \} \right)^2 \right]^{1/2}$z_t \in Z_t$ 可以表示PF的目标集。$I_s$ 能取任何正的实数值。理想情况下，要找到一个接近统一($I_S = 1$)的指标值(理想的多样性)。小于1 ($I_S &lt; 1$)的指示值表示与期望的解决方案的扩展相比，操作的解决方案之间的多样性较低。另一方面，指示符值大于1($I_S &gt; 1$)突出了目标空间中解的过度分散(高多样性)。这种超空间的过度分散很可能导致解与PF的发散，并通过引入循环行为，迫使MOEA反复探索空间中以前访问过的区域，从而阻碍了优化过程。 第二个多样性管理机制是DM2，它预测NSGA-II中使用的多项式突变算子可能会使潜在的解点广泛分散。DM2试图通过引入自适应突变算子，以一种可控的方式控制这种离散。这个新的变异算子试图定义组决策变量的变异范围在每一代的基础上的多样性程度的局部non-dominated集解决方案,为每个单独的决策变量中设置,在当地的多样性以NSGA-II年代拥挤的措施。 计算第i代近似集的扩展指标。 if $I_s&lt;1$ 在变异选择和生存选择过程中激活多样性促进机制。 Else If $I_s \geq 1$ 在变异选择和生存选择过程中，失活多样性促进机制。 Coverage error $\epsilon$$\epsilon$ 的概念： 解释一下就是：有两个集合$D,Z$，$D$ 是 $Z$ 的一部分，如果想要用 $D$ 代表 $Z$，那么就要用符号 $d_{\epsilon}$ 表示。并规定，遍历 $Z$ 中的每一个点，画一个圆，半径是 $\epsilon$ ，都要有 $D$ 中的解存在，并且找最小的 $\epsilon$。 $\delta$ 的概念： 翻译一下：这个是单对 $D$ 集合来说的，$D$ 中两两点的最小距离。 例子如下：实心 + 空心 = Z；实心 = D 因此 $\epsilon$ 要尽可能的小，$ \delta$ 尽可能的大。 \epsilon = \max_{z \in Z} \min_{x \in D} d(z,x)For a fixed element $z$ of $Z$, how well it is covered is determined by the closest point to $z$ in the representation $D$. How well the entire set $Z$ is covered depends on how well an arbitrary element of $Z$ is covered, and thus the coverage error \epsilon$ is equal to the maximum of coverage error quantities for individual points in Z. Similarly, the uniformity level $\delta$ is determined by the quantity. \delta=\min_{x,y \in D,x \ne y}d(x,y)the fact that $D$ is of finite cardinality, computing the uniformity level $\delta$ is simple as long as the metric $d$ is computable. PD PD(X) = \max_{s_i \in X}(PD(X-s_i)+d(s_i,X-s_i))where d(s,X)=\min_{s_i \in X}(dissimilarity(s,s_i))$d(s_i,X-s_i)$ 是从一个物种 $s_i$ 到另一个种群 $X$ 的相异度。 下图提供了一个方式展示了PD是如何计算的，在左图,解$s_i$和其他方案 $X−si$ 视为两个社区，他们的多样性之和是 $X−si$ (black dots)的和 与 $si$ 到 $X−si$ 的相异值的和组成： 每个解与整个总体的不同之处是可以计算的，每个解都与其最近的未复制邻居相关联。然后，这些差异的和导致了整个种群的多样性，可以看作是X的结构，上右图所示，(其中较暗的线比较亮的线连接得早)。具体算法如下： 其中： $d$ 是n*n的矩阵，例如(i,j)就是 第i个解与第j个解的p范数距离($L_p-norm$)，因此是对称矩阵。 $min(d,[],2)$ 出自于matlab语法，对每一行取最小值，因此输出是一列。 另外，这位老师居然还是我们学校的老师，在电院，好奇翻了一下个人主页，居然有代码！我会附录在本博客最后，其中中文为我注释。 不同的相异评价在计算PD占很重要的作用。通常采用两个解之间的距离作为它们的相异之处。但是请注意，欧几里得距离不太适合在高维空间中测量邻域。由于MaOPs的解分布在高维目标空间中，基于$L_2$范数的欧氏距离不适用于PD中的不相似度计算。 从下图中我们可以清楚地看到，p越小，各维$L_p$对0越敏感。相反，基于$L_p-norm-based$的距离测度不适用于测量p&gt;1的高维数据的差异性。因此，为了测量MaOPs的多样性，需要将p设置为p &lt; 1。已有研究表明，只要p&lt; 1，该测度的有效性对p不敏感。因此，p在PD中不是一个参数，本文将p设为0.1。 指示器使用单个标量值来描述m维分布。因此，无论哪个指标，都会丢失一些信息。因此，尽管不同的指标可能捕获不同的信息，但希望捕获一些关键信息。当得到PF f1 +f2 +f3 = 1的三个极值点时，在这三个极值点的集合中加入不同的解，多样性度量的值是不同的。下图为在三个极值点集合中加入PF的另一个解时PD、MS、NDC (b =4)、熵(b =4)的变化值，其中颜色表示矩阵的大小(颜色较深的点值小于颜色较浅的点值)。如果根据这些指标选择一个解决方案以增加多样性，下图中较亮的部分优先于较暗的部分。一旦得到极值点。MS值达到最大值。因此，没有任何解决方案能够改进MS。虽然中间部分是由NDC和熵推动的，但解在网格内是无法区分的。对于PD，中间部分提升，值不断变化。从图4可以看出，PD通常可以促进不同的解决方案。 Overall Pareto Spread当设计的目标函数都被考虑时，总体的PF延展性度量量化了所观测的目标在目标空间中的延展能力。这个度量被定义为两个超矩形的体积比，其中一个是 $HR_{gb}$ ，它对于每一个所设计的目标的好点与坏点。类似地， $HR_{ex}$ 定义了所观察到的Pareto解集的极值点。整个PF的延展性变为$HR_{gb}$与 $HR_{ex}$ 之比： OS(P)=\frac{HR_{ex}(P)}{HR_{gb}}$P$ 是所观测的Pareto解，$m$ 为目标函数个数，其中： OS(P)= \frac{\prod_{i=1}^{m}|\max_{k=1}^{\bar{np}} (p_k)_i -\min_{k=1}^{\bar{np}}(p_k)_i |}{\prod_{i=1}^{m}|(p_b)_i-(p_g)_i|}\\ =\prod_{i=1}^{m}| \max_{k=1}^{\bar{np}}[\bar{f_i}(x_k)] -\min_{k=1}^{\bar{np}}[\bar{f_i}(x_k)] | 例如，在图4所示的两个目标空间中，PF-spread的计算公式为: OC(P) = \frac{h_1h_2}{H_1H_2}其中： $P_1,P_2$ 是两个Pareto solution sets。if $OS(P_1)&gt;OS(P_2)$, then the solution set P1 is preferred to P2 . h_1=|\bar{f_1}_{max}-\bar{f_1}_{min}|\\ h_2=|\bar{f_2}_{max}-\bar{f_2}_{min}|\\ H_1=|(p_g)_1-(p_b)_1|\\ H_2=|(p_g)_2-(p_b)_2|PD’s code123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990% Authors: Handing Wang, Yaochu Jin, Xin Yao% University of Surrey, UK, and University of Birmingham, UK% EMAIL: wanghanding.patch@gmail.com, yaochu.jin@surrey.ac.uk, X.Yao@cs.bham.ac.uk% WEBSITE: http://www.surrey.ac.uk/cs/people/handing_wang/% DATE: March 2016% ------------------------------------------------------------------------% This code is part of the program that produces the results in the following paper:% Handing Wang, Yaochu Jin, Xin Yao, Diversity Assessment in Many-Objective Optimization, Cybernetics, IEEE Transactions on, Accepted, 10.1109/TCYB.2016.2550502.% You are free to use it for non-commercial purposes. However, we do not offer any forms of guanrantee or warranty associated with the code. We would appreciate your acknowledgement.% ------------------------------------------------------------------------function [ pd ] = PD( X )% Usage: [ pd ] = PD( X )%% Input:% X -Objective values of the population n*m (n solutions with m objectives)%% Output: % pd -PD value of population X%p=2;%lp norm setting0.1C=zeros(size(X,1),size(X,1));%connection arrayD=zeros(size(X,1),size(X,1));%dissimilarity array%Calculate the dissimilarity between each two solutionsfor i=1:size(X,1)-1 for j=i+1:size(X,1) d=sum(abs(X(j,:)-X(i,:)).^p,2).^(1/p); D(i,j)=d; D(j,i)=d; endendDMAX=max(max(D))+1;D(logical(eye(size(D))))=DMAX;n=size(X,1);pd=0;for k=1:n-1 %Find the nearest neighbor to each solution according to D in each row. [d,J]=min(D,[],2); %Find solution i with the maximal di to its neighbor j [dmx,i]=max(d); while liantong(C,i,J(i))==1 %i and j are connected by previous assessed solutions if D(J(i),i)~=-1 D(J(i),i)=DMAX; %Mark the connected subgraph end if D(i,J(i))~=-1 D(i,J(i))=DMAX; end [d,J]=min(D,[],2); %Find solution i with the maximal di to its neighbor j [dmx,i]=max(d); end C(J(i),i)=1; C(i,J(i))=1; pd=pd+dmx; if D(J(i),i)~=-1 D(J(i),i)=DMAX;%Mark the used dissimilarity di. end D(i,:)=-1;%Mark the chosen solution iendendfunction [w]=liantong(C,I,J)% Usage: [w]=liantong(C,I,J)%% Input:% C -Connection array% I -index I% J -index J%% Output: % w -1 if solutions I and J are connected, 0 if solutions I and J are not connected.%V=I;Child=find(C(V,:)==1);if isempty(find(Child==J))==0 % 直接连接 w=1; returnelse C(V,:)=0; % 删掉点I C(:,V)=0; for i=1:size(Child,2) % 遍历连接点I的其他点 w=liantong(C,Child(i),J); % 进行递归 if w==1 return end endendw=0;end]]></content>
      <categories>
        <category>indicators</category>
      </categories>
      <tags>
        <tag>MOEA</tag>
        <tag>indicator</tag>
        <tag>SpreadQI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Convergence--Distance-based QIs]]></title>
    <url>%2F2019%2F01%2F21%2Fdistancebased%2F</url>
    <content type="text"><![CDATA[可谓呕心沥血，翻译的累死我了，这篇是关于收敛性的indicators的《Distance-based QIs》。 分类可以进一步分为两类： 测量所考虑的解集到从帕累托前缘导出的一个或多个特定点的距离：the ideal point, knee point(s) , the Zeleny point and the seven particular points。 the ideal point是由帕累托前缘各目标的最优值所构造的点。 knee point(s)是帕累托前缘上的点，它具有从相邻点计算出的最大反射角。 the Zeleny point是通过分别最小化每个目标得到的点。 the seven particular points是由二元多目标问题的帕累托前缘的理想点和极值点导出的7个特殊点 测量到一个很好地表示帕累托前沿的reference set的距离。在这一组中，最常用的指标是GD。GD首先计算解集中每个解到参考集中最近点的欧氏距离，然后求所有这些距离的二次平均值。这一组中的其他QIs可以看作是GD的变体，例如taking the arithmetic mean of the distances，the powermean，considering the Tchebycheff distance，introducing the dominance relation between solutions and points in the reference set。 measure the distance of the considered solution set to one or several particular points derived from the PFTchebycheff distance to the knee point d(z,z^*,\lambda)=\max_{1 \leq j \leq k}\{ \lambda_j |z_j^* - z_j| \}其中： k：目标函数的数量。 $\lambda_i=\frac{1}{R_i}$，$R_i$是第i个目标函数的范围(range)。 Defined this way, the knee of the Pareto front is the point in the feasible objectivespace, $ \Lambda$, which corresponds to $ \min_{z∈\Lambda} d(z, z^∗, \lambda)$. 如果一个偏好关系的$PF_{approx}$集合比另一个关系的$PF_{approx}$集合包含更多的膝节点周围的解，则该偏好关系优于其他关系。 Seven point average distance该问题用于二元目标优化。 如果有效集的先验知识是可用的，MCGA完全解析E的能力可以很精确的理解为它与个体的标准和其他(已决定的)点有多接近。由于E对于任何一个测试问题都是未知的，因此为每个问题生成7点法，以衡量算法的有效性。个体准则最优约束了两个标准问题的有效集，但也可通过单独优化每一个准则而不考虑另一个准则来求出个体准则最优。有了这两点，七点法再$J_1-J_2$被定义如下原点[0,1]，最大点(在E范围内)[0,$J_2^{worst}$]和[$J_1^{worst}$,0]，和在原点与最大值之间的每个轴上的两个点。 原文： With the resulting two points at hand, the seven comparison points are denned on $J_1-J_2$as the origin [0,0], the maximum (within the range of E) of each criterion [0, $J_2^{worst}$] and [$J_1^{worst}$, 0], and two points on each axis between the origin and the maximum value. 全距离测量是通过距离处以7，该距离是从七个点中每一个点到离此点最近的MCGA种群的点的距离和。因此，每次创建距离度量时，使用总体中的7个成员。他的优点是比较不同人群在某一特定问题上的相对优势的准确方法。对于给定的问题，距离度量值最小的总体将是最接近E的总体。 这七个点具体是什么我实在没有翻译出来，在查找文献时《Evolutionary Algorithms for Solving Multi-Objective Problems 》作者：Carlos Coello Coello， David A. Van Veldhuizen， Gary B. Lamont时，有如下叙述： measure the distance to a reference setGenerational Distance (GD)GD首先计算解集中每个解到参考集中最近点的欧氏距离，然后取所有这些距离的二次平均。 公式： GD(A)=\frac{1}{N} ( \sum_{i=1}^{N} (d_2(a_i,PF)^2)^{1/2}a solution set $A=\{ a_1,a_2…,a_N\}$ $d_2(a_i,PF)$是$a_i​$到PF的2范式距离(欧几里距离) 在实际应用中使用了一个很好地表示PF的参考集R。 d_2(a_i,PF)=\min_{r \in R}d_2(a_i,r)$d_2(a_i,r)$是$a_i$与$r$的欧几里距离。如果前端的几何性质是已知的，GD不一定需要一个表示PF的引用集。 GD的值理应是要极小的。如果值为0表明该集合位于Pareto front /reference set中。作为为后代间的代际评估而设计时，GD通常用于度量solution set 向PF的演化过程。然而，由于GD考虑的是二次平均值(quadratic mean)，因此它对异常值非常敏感，无论其他解的表现如何，它都会返回一个异常值得分很低的解集。当$ N \rightarrow \infty, \ GD \rightarrow 0 $，尽管这个集合远离PF。因此，只有当考虑的集合具有相同/或非常相似的大小时，GD才可靠地可用。幸运的是，公式中的算术平均数代替二次平均数，这个问题可以解决。事实上,在一些最近的研究，GD指标的一般形式的指数“p”和“1 /p”而不是“2”和“1/2”。设置p = 1现在已经被普遍接受，并与它的反转版本IGD一起使用(度量从帕累托前的点到所考虑集合中最近解的距离的算术平均值)。 来自“Measuring the Averaged Hausdorff Distance to the Pareto Front of a Multi-Objective Optimization Problem”的下文： 虽然在许多研究中使用了GD，但并不是EMO社区的所有研究人员都接受GD。我们推测一个可能的原因(可能是主要的原因)是它的归一化策略，如下面的例子所示:假设我们有一个(任意的)点$a \in Q$，在不丧失通用性的情况下，让图像F(a)到PF的距离为1。现在将 archive $A_n$定义为由a的n个副本给出的multisets，即$A= {a,…,a}$。“平均”距离的F(A)向PF，有: GD(F(A_n),F(P_Q))=\frac{||(1,...,1)^T||_p}{n}=\frac{\sqrt[p]{n}}{n}我们可以看到，随着n的增加，近似质量就会变得越来越“好”，尽管估计值并没有怎么变，archives $A_n$甚至收敛到“完美”估计： \lim_{x \to \infty}{GD(F(A_n),F(P_Q))=0}由上述的结果可以推广:例如，我们可以考虑a的小扰动，而不是multisets。或者，如果$F(A)​$是有界的，不管$A_n​$的a是否被支配，也不管$F(a)​$离PF有多远，甚至满足$|A_n|=n​$的任意archive序列任何$A_n​$都能被选择。因此，在EMO上下文中，从这个角度来看，用进一步的、甚至占主导地位的解决方案“填充”归档文件是有好处的，因为通常较大的集合会产生更好的GD值。在社区中，它的建立是为了固定种群大小，以便对不同的算法进行比较(例如，N = 100)。然而，这给基于不受先验定义值限制的存档的MOEAs带来了麻烦。因此，“完美的”归档器(关于GD)可以接受所有(或至少是尽可能多的)候选解决方案。这当然不是我们想要的效果。 为解决以上问题，便提出了$GD_p$： $GD_p$ GD_p(X,Y)=\left(\frac{1}{N} \sum_{i=1}^{N}dist(x_i,Y)^p\right)^{1/p}$dist(x_i,Y)=\inf_{v \in Y}||x_i,v||$，$\inf$ 为下界(最小值)。 公式上的区别：把$\frac{1}{N}$在$()^{1/p}$从放括号外变为括号里。 我们把这个新指标命名为$GD_p$(索引p)只区分经典版本，这是需要在这项工作中进一步比较。“新”指标不具有上述讨论的不需要的特征，因此在比较具有不同大小的集合时似乎更为公平。特别是，大型候选集不再必须是“好”的。例如上例中$GD(F(A_n),F(P_Q))=1$ 对于所有的$n \in \mathbb{N}$ 。 \min_{x \in Q}{F(x)}\\ F(x) = (f_1(x),...,f_k(x)),the \ vector \ of \ the \ objective \ functions命题1：令$k=2​$(二元目标优化问题)，$F(P_Q)​$是连接的，有$a,b\in Q​$，有： a \prec b \ \Rightarrow \ dist(F(a),F(P_Q)) 0$dist(F(b),F(P_Q))$是固定值 r($r \ne 0$)，以$F(b)$为圆心，r为半径画一个圆，交点便是$p_b$(有点圆与$P_Q$相切的感觉)。分情况讨论： 当 $a \in P_Q$ 时，那么$dist(F(a),F(P_Q))=0$ ，以此得结论结果。 当 $a \notin P_Q $ 时 当 $ p_b \prec a$ 时 因为$a \prec b$ dist(F(a),F(P_Q)) \leq||F(a)-F(p_b)|| < ||F(b)-F(p_b)||=dist(F(b),F(P_Q)) 当 $p_b \nprec a$ 时，也就是 $p_b$ 和 $a$ 互相非支配，那么应该存在$i,j \in \{1,2\}, i \ne j$ f_i(p_b) < f_i(a) \ \ and \ \ f_j(p_b) > f_j(a） ​ 因为$a \notin P_Q$，那么也会存在$p_a \in P_Q$ 令 $p_a \prec a$(满足上面两个都是小于号) ，因为$F(P_Q)$ 是 ​ 连贯的( index from &gt; to &lt; 一定有一个=)，这存在一条$F(p_a)$到$F(p_b)$ 的路径， ​ 那么一定存在 $\bar{p} \in P_Q \ let: \ f_j(\bar{p})=f_j(a)$ ，又因为 $\bar{p}$ 和 $p_b$ 互相不支配(同在$P_Q$)， ​ 那么有： dist(F(a),F(P_Q)) \ \leq \ ||F(a)-F(\bar{p})|| \ = |f_i(a)-f_i(\bar{p})| \ < \ |f_i(b)-f_i(p_b) | \\ \ \leq \ ||F(b)-F(p_b)|| \ = \ dist(F(b),F(P_Q))证明完毕。其中要解释一下，为何： |f_i(a)-f_i(\bar{p})| \ < \ |f_i(b)-f_i(p_b) | $f_i(b) &gt; f_i(a)$ ，这是因为 $ a \prec b$ $f_i(p_b) &lt; f_i(\bar{p})$，这个比较麻烦QWQ $\bar{p} \ and \ a $ = $\begin{cases} f_j(\bar{p})=f_j(a) &amp; (1 \\ f_i(\bar{p}) &lt; f_i(a) &amp; (2 \end{cases}$ $ p_b \ and \ a $= $\begin{cases} f_j(p_b) &gt; f_j(a) &amp;(3 \\ f_i(p_b ) &lt; f_i(a) &amp;(4 \end{cases}$ ​ $ (1,(2 \Rightarrow f_j(p_b) &gt; f_j(\bar{p}) $ ，又因为 $\bar{p}$ 和 $p_b$ 互相不支配，那么$for \ i \ must \ be:f_i(p_b) &lt; f_i(\bar{p})$ 一个有趣的问题当然是如果拖把涉及两个以上的目标会发生什么。但是，我们不得不把这个问题留到以后调查。 当帕累托前缘断开时，上述结果不成立。然而，如果一个元素足够接近帕累托集合，这种“单调行为”仍然成立。下面的例子和命题分别给出了反例和证明。 例如：$F(P_Q)=\{(10,0)^T,(0,1)^T \}$ , $F(a)=(11,3)^T,F(b)=(5,2)^T \ so \ a \prec b, but$ $dist(F(b),F(P_Q)) = \sqrt{1^2 + 3^2}=\sqrt{10} &lt; \sqrt{29}=\sqrt{5^2 + 2^2} = dist(F(a),F(P_Q))$ 命题2： 翻译一下就是：对于一个$k$个目标的问题，任何一个维度$i$，存在$y(a,i)$的目标值向量属于$F(P_Q)$，并且满足$y(a,i)$在除了第$i$维度上的值与 $F(a)$ 相同,（第$i$维任意）。【其中与命题1的差别是，在1中$k = 2$，但在此命题中，并没有这个限制】 证明：推到与前一个类似，只是推广到高纬度上了$k&gt;2$。 因为$P_Q$是紧凑的，所以一定存在 $p_b\in P_Q$，满足： dist(F(b),F(P_Q)) =||F(b)-F(p_b)|| 当 $ p_b \prec a$ 时 因为$a \prec b$ dist(F(a),F(P_Q)) \leq||F(a)-F(p_b)|| < ||F(b)-F(p_b)|| 当 $ p_b \nprec a$ 时，存在$i \in \{1,…k\}$，满足$f_j(p_b) &gt; y(a,i)_i$ (翻译一下：一个解y(ami)，它的第i维满足$f_j(p_b)$ 与，其他维度的数值与$a$相同)并且： dist(F(a),F(P_Q)) \ \leq \ ||F(a)-y(a,i)|| \ = f_i(a)-y(a,i)_i \ < \ f_i(b)-f_i(p_b) \\ \ \leq \ ||F(b)-F(p_b)|| \ = \ dist(F(b),F(P_Q)) 这个结果的关键是投影$y(a, i)$的存在性，$F(a)$足够接近帕累托前沿，在这种情况下不需要$F(P_Q)$的连通性。如下图： 总结，假使PF是连贯的(至少对于k = 2)，主导解(dominating solutions) $a$ 产生更好的 $dist$ 值比其被支配解(dominated points)$b$。此外，这个依然保留的话，要么当F (a)是“足够远”帕累托前面(在这种情况下，声明：$dist(F(b),F(P_Q))=||F(b)-F(p_b)|| &gt; 0$，则必须 $p_b$ 支配 $a$ )，要么就足够接近(命题2)。 从GDp的角度来看，这些结果可以解释为:如果新的归档结果来自于前一个归档，用一个支配解替代了一个被支配解，那么$GD_p$值就会下降。对于$A1 = \{b, x_2，…， x_n\}$， $A2 = \{a, x_2，…， x_n\}$，其中$a$和$b$为上式，则为: GD_p(F(A_2),F(P_Q)) < GD_p(F(A_1),F(P_Q))然而，下面的结果更为普遍，则需要进一步的假设： 命题3： $A,B \subset \mathbb{R}^n \ be \ finite \ sets \ such \ that​$ $ \forall a \in A \ \exists b \in B:F(b) \leq_p F(a) $ $ \forall b \in A \ \exists a \in B:F(b) \leq_p F(a) $ $ \exists b \in B \backslash A ,\ \exists a \in A\backslash B:b \prec a$ $ \forall a \in A \ \forall b \in B:if \ a \prec b \Rightarrow dist(F(a),F(P_Q))&lt;dist(F(b),F(P_Q)) $ 那么： GD_p(F(B),F(P_Q))]]></content>
      <categories>
        <category>indicators</category>
      </categories>
      <tags>
        <tag>MOEA</tag>
        <tag>indicator</tag>
        <tag>ConvergenceQI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Convergence--Dominance-based QIs]]></title>
    <url>%2F2019%2F01%2F14%2Fdominancebased%2F</url>
    <content type="text"><![CDATA[此篇介绍的是QIs for Convergence的第一部分《Dominance-based QIs》。看了一部分方法的论文，剩下一部分实在看不下去了，想继续看看别的，有时间有精神回来补一下~ QIs用于收敛性收敛性作为解集质量的一个重要方面，在集的评价中受到了广泛的关注。文献中存在两类收敛QIs。一是考虑解或集之间的帕累托支配关系(表2项目1-9);另一种方法是考虑解集到帕累托前的距离，或者从帕累托前导出的一个/多个点(项目10 -22)。 Dominance-based QIsA type of frequently-used dominance-based QIs is to consider the dominance relation between solutions of two sets , such as the C indicator , $\widetilde{C}$ indicator, $\sigma- \tau- and \ \kappa-$ metrics , and contribution indicator.Other QIs concerning solutions’ dominance include wave metric, purity, Pareto dominance indicator, and dominance-based quality. The wave metric crunches the number of the nondominated fronts in a solution set. The purity indicator counts nondominated solutions of the considered set over the combined collection of all the candidate sets. The Pareto dominance indicator measures the ratio of the combined set’s nondominated solutions that are contributed by a particular set. The dominance-based quality considers the dominance relation between a solution and its neighbours in the set. $C-metric$定义为： C(A,B)=\frac{|\{b\in B:\exists a \in A,a \preceq b \}|}{|B|}$C​$一方面可以计算出$B​$中的解被$A​$中解所支配的比例部分，另一方面也可以计算出$A​$相对于$B​$的性能。 当$C(A,B)=1​$时，意味着$B​$中的所有解都被$A​$中的所$\preceq​$。 当$C(A,B)=0​$时，意味着$B​$中的所有解都无法被$A​$中的$\preceq​$。 注意：$C(A,B) \ne 1-C(B,A)$ $ C(A,A) \ne 0$ 如果$W​$是一个非支配解集，$A,B​$满足$A \subseteq W​$，$B \subseteq W​$，但$C(A,B)​$可为[0,1]中的任意一个值。 $\widetilde{C}-metric$多目标优化环境下的性能度量是评价优化器定量性能的数学工具，它通过单独考虑优化器或与其他优化器进行比较来评价的。这种方法可以与优化器在线评估和性能改进的优化器结合使用，也可以离线应用于两个或两个以上优化器的最终结果，以比较它们的性能、产生的结果的质量和/或要求的计算努力。 性能指标可以大致分为两类： 基本度量:一个标准度量满足一定要求的解决方案的数量或比例，比如度量关系。 序数或几何度量:这些方法不度量数量，而是通过考虑几何位置来度量。 \widetilde{C}(A,B)=\frac{|\{b\in B:\exists a \in A,a \prec b \}|}{|B|}$ C(A,A) = 0$ ，因为$A$是非支配解集。 对于$\widetilde{C}(A,B)$、$C(A,B)$，值越高说明B中的解受A所$\preceq$的比例越多。 如果$W$是一个非支配解集，$A,B$满足$A \subseteq W$，$B \subseteq W$，但$C(A,B)=0$。 $\widetilde{C}(A,B)$与$C(A,B)$都没有考虑到前沿的延展性(extent)与一致性(uniformity)。 上图可以看出(minimise)：A的一致性(uniformity)更好，而B集中聚到了一个区域。 但有：$ C(A,B) = C(B,A) =\widetilde{C}(A,B) =\widetilde{C}(B,A) =\frac{4}{12}​$，即使A的元素在B的大部分区段上占主导地位。 上图，尽管B有很好的延展性(extent)， 但是：$ C(A,B)=\widetilde{C}(A,B) =\frac{2}{12}$ ， $C(B,A)=\widetilde{C}(B,A) =\frac{0}{12}$ ，从$C$、$\widetilde{C}$中的值看出$A$优于$B$。 Contribution indicatorThe contribution of algorithm $PO_2$ relatively to $PO_2$ is roughly the ratio of non dominated solutions produced by $PO_2$. 规定： $C = PO_1 \cap PO_2$ 集合$W_1$为$PO_1$中支配$PO_2$的解集，集合$W_2$为$PO_2$中支配$PO_1$的解集。 集合$L_1$为$PO_1$中被$PO_2$支配的解集，集合$L_2$为$PO_2$中被$PO_1$支配的解集， 集合$N_1$为$PO_1$中不可与$PO_2$构成不可比较的解集，即$PO_1 \backslash (C \cup W_1 \cup L_1) $ 集合$N_2​$为$PO_2​$中不可与$PO_1​$构成不可比较的解集，即$PO_2 \backslash (C \cup W_2 \cup L_2) ​$ 表达式为： CONT(PO_1 / PO_2) = \frac{\frac{|C|}{2}+|W_1|+|N_1|}{|C|+|W_1|+|N_1|+|W_2|+|N_2|}可知： ​ 如果$PO_1$与$PO_2$是相同的解集，那么$CONT(PO_1 / PO_2)=CONT(PO_2 / PO_1)=1/2$ ​ 如果$PO_2$中的所有解都被$PO_1$所支配，那么，$CONT(PO_2 / PO_1)=0$。 我的理解： CONT(PO_1 / PO_2) = \frac{\frac{|C|}{2}+|W_1|+|N_1|}{|C|+|W_1|+|N_1|+|W_2|+|N_2|}\\ =\frac{\frac{|C|}{2}+\frac{|W_1|+|W_1|}{2}+\frac{|N_1|+|N_1|}{2}}{|C|+|W_1|+|W_2|+|N_1|+|N_2|}\\ =\frac{1}{2}\frac{|C|+|W_1|+|W_1|+|N_1|+|N_1|}{|C|+|W_1|+|W_2|+|N_1|+|N_2|}也就是说：对于$CONT(PO_1 / PO_2)$，如果$|W_1|+|N_1| &gt; |W_2|+|N_2|$，则大于0.5。 也就是说：$PO_1$中支配$PO_2$的解和不能与$PO_2$比较的解越多，$CONT(PO_1 / PO_2)$越大。 $\sigma-\ \ \tau- \ \ \kappa- \ metric$前言对于一个评价指标，无论是类别如何，想要使他可用，都要满足以下五个特征： Monotonicity/compatibility(单调性/兼容性)：对于两个PFs的支配关系，度量标准应该满足单调性/兼容性，例如，设度量标准为$\xi$，如果A支配B，A就应该比B好或至少不能差于B。因此 $A \succeq B \Rightarrow \xi (A) \geq \xi(B)$或严格单调$A \succ B \Rightarrow \xi (A) &gt; \xi(B)$ 。 Transitivity(传递性)：在所比较的所有PFs的完全顺序中，一个度量应该是可传递的。如果A优于B，B优于C，那么通过$\xi()$也应得出，A优于C。直接比较度量通常会在被比较的不同PFs之间产生不可传递关系。传递性通常只在引用度量和独立度量中得到保证。这是因为这两种方法都为每个PF分配一个数字，并且实数之间的比较是可传递的。 Scaling/meaningfulness(缩放性/有意义性)：目标函数通常需要进行缩放，例如进行单调变换以映射给定范围内的目标值，例如在[0,1]中。在这种情况下，一个度量应该是缩放不变的或有意义的，即，该度量不应受任何缩放的影响。尺度不变度量通常只利用解之间的优势关系，而不是它们的绝对客观值。 Computational effort(计算工作量)：此属性用于计算给定pf的度量值所需的计算资源。为了比较不同度量的性能，通常只考虑运行时复杂性作为所需的计算工作。 Additional information(附加信息)：许多指标依赖于不同类型的附加问题信息。一些假设问题的POF是已知的，而另一些则依赖于一些用户定义的依赖于问题的引用目标向量或引用PFs。因此，希望一个度量具有尽可能少的参数。 $\sigma-metric$规定：a dominates b is $a \succ b$ 原文： Sigma-metric($\sigma $-metric): The performance value, $\sigma_{ij} $, assigned to the j-th PF of the i-th optimizeris the number of solutions of the r-th optimizer which are strictly dominated by at least one solution of that PF of the i-th optimizer,where $i,r \in {1,2}$ and $i \ne r$. 公式： \sigma_{ij}=\sum_{s=1}^{F_r}\sum_{t=1}^{L_{rs}}\max_{k\in \{1,...L_{ij} \}}I(p_{ijk}\succ \succ p_{rst})具体规定如下： optimizer\ i_{th}=\begin{cases} PF_1 & |PF_1|=L_{i1} \\ PF_2 & |PF_2|=L_{i3} \\ ...\\ PF_j & |PF_j|=L_{ij}\\ ...\\ PF_{F_i} & |PF_{F_i}|=L_{i{F_i}} \\ \end{cases}\\ optimizer\ r_{th}=\begin{cases} PF_1 & |PF_1|=L_{r1} \\ PF_2 & |PF_2|=L_{r3} \\ ...\\ PF_j & |PF_j|=L_{rj}\\ ...\\ PF_{F_r} & |PF_{F_{r}}|=L_{rF_r} \end{cases}有两个优化器 $i$ (optimizer)，每个优化器都$F_i$个$PFs$，对于第$i$个优化器，第$j$个$PF$，它有$L_{ij}$个解(solutions)。而$p_{ijk}$则为第$i$个优化器，第$j$个$PF$的第$k$个解。 $I(\bullet)$如果内部true则返回1，否则返回0。 \max_{k\in \{1,...L_{ij} \}}I(p_{ijk}\succ \succ p_{rst})翻译为：对于指定的解 $p_{rst}$ 如果在第$i$个优化器，第$j$个$PF$中有$\succ \succ p_{rst} $关系的解，就为1，都没有则为0。 整体来看：对于第$r$个优化器的所有解中，被第$i$个优化器的第$j$个$PF$的所有$L_{ij}$个解所支配的个数。 因此，最大值为$optimizer\ r_{th}$的所有解的个数。 ps.原论文写的是$F_rL_{rs}$,但是我不赞同…..我认为是$\sum_{s=1}^{F_r}{L_{rs}}$，当$L_{r1}=L_{r2}=…=L_{F_r}$时与原论文一致。 $\tau-metric$原文： Tau-metric ($\tau -metric$): The performance value, $\tau_{ij}$, assigned to the j-th PF of the i-th optimizer is the number of solutions of the r-th optimizer which are weakly dominated by at least one solution of that PF of the i-th optimizer,where $i,r \in \{1,2\}$ and $i \ne r$. Further, $\tau_{ij} $may also be rewarded if the j-th PF of the i-th optimizer weakly outperforms a PF of the r-th optimizer. Since the metricis based on the concept of weak dominance,it may be done just as an attempt to take into account the compatibility of the metric with the ‘‘weak outperformance relation’’ given indefinition (8). However, it would be a new dimension of research in order to generalize the outperformance relations in terms of multiple(more than two) PFs.​ 公式： \tau_{ij}=\sum_{s=1}^{F_r}\{ [\sum_{t=1}^{L_{rs}}\max_{k\in \{1,...L_{ij} \}}I(p_{ijk}\succeq p_{rst})] + I(A_{ij} \ \vartheta_w \ A_{rs} ) \}规定： $\vartheta_w$ (weakly outperform): $A \ \vartheta_w \ B$ means $ A \succeq B $ and $\exists c \in A \ but \ c \notin B $。 ​ A不会比B差，并且A有B不存在的解。 在遍历$r_{th}\ optimizer$的$PF_s$时，如果与第$i$个优化器，第$j$个$PF$ 满足 ： $A_{ij} \ \vartheta_w \ A_{rs} $，再加1。 因此，相对于$\sigma-metric$最大值再加上$F_r$即$F_r(L_{rs}+1)$。 $\kappa-metric$原文： Kappa-metric ($ \kappa-metric$): The performance value, $\kappa_{ij}$ , assigned to the j-th PF of the i-th optimizer is the number of solutions of the r-th optimizer which cannot weakly dominate a given solution of that PF of the i-th optimizer,where $i,r \in \{1,2\}$; and $i \ne r$. For the same reason as in the case of the $\tau-metric$, $k_{ij}$ may also be rewarded if the j-th PF of the i-th optimizer weakly outperforms a PF of the r-th optimizer. 公式： \kappa_{ij}=\sum_{s=1}^{F_r}\{ \sum_{l=1}^{L_{ij}} \sum_{t=1}^{L_{rs}} I(p_{rst}\nsucceq p_{ijl}) + I(A_{ij} \ \vartheta_w \ A_{rs} ) \}遍历$r_{th}\ optimizer$的所有解，对于每一个解$p_{rst}$，如果$p_{rst} \nsucceq p_{ijl} (l \in [1,…,L_{ij}])$，则加1。 如果与第$i$个优化器，第$j$个$PF$ 满足 ： $A_{ij} \ \vartheta_w \ A_{rs} $，再加1。 因此，最大值为 $F_r(L_{ij}L_{rs}+1)$。 至此三种indicator已介绍完毕。 再分析当初说的五个特点，探究是否满足： Monotonicity/compatibility(单调性/兼容性)：对于两个PFs的支配关系，度量标准应该满足单调性/兼容性。如果A支配B，通过度量标准得出的结果，A就应该比B好或至少不能差于B，这个概念可应用与两个PF之间，但并不能应用于M-ary度量标准，M-ary它是和很多个PFs进行比较的而不是仅仅和另一个PF比较。如果$A$与$\{ B_1,B_2,…B_m\}$进行比较，这是不可能的说A的分数和$B_i’s$的总分数有什么样的关系，尤其在$A$支配一些$B_i’s$ 或/和 $A$被一些$B_i’s$支配 或/和 $A$和一些/全部$B_i’s$交叉。在一些特殊的情况，比如当$A$支配所有的$B_i’s$时，$A$相对于与其他的所有$B_i’s$比较时，一定比任何$B_i$分数高。另一方面，当仅仅比较两个PFs时来作为简化的例子，M-ary度量标准遵守单调/兼容性，只要一个PF支配另一个PF而不是部分PF。 Transitivity(传递性)：就像刚刚谈及Monotonicity时解释的一样，当前的概念并不适用于M-ary度量指标。在对某些PFs进行成对比较简化的情况下，在提出的基于基数的M-ary度量中，并不能保证传递性。例如$\sigma(A,B) &gt; \sigma(B,A) \ and \ \sigma(B,C) &gt; \sigma(C,B)$并不能得出$\sigma(A,C) &gt; \sigma(C,A)$。正如Knowlesand Corne所观察到的，直接的比较指标往往会在被比较的不同PFs之间产生这种不可传递关系。这种情况在Noilublao and Bureerat被称为“剪刀-纸-石头”的情况。 Scaling/meaningfulness(缩放性/有意义性)：所提出的度量标准是基于解决方案之间不同形式的优势关系设计的。由于两个解之间的优势关系是基于它们在目标空间中的相对位置，所以这些关系不会因为它们的双射值的缩放而改变(例如在给定范围内的单调变换)。因此，所提出的度量是缩放不变的。 Computational effort(计算工作量)：因为一个优化器的PF与其它优化器相比,提出的每一个最糟糕的复杂性度量是$O(dFL^2)$,d是目标的数量,F是PFs的数量与一个给定的PF相比,和L的最大尺寸是比较PFs。 Additional information(附加信息)：除了比较优化器的PFs之外，所提出的度量中不需要其他信息。 实例讨论这些测试首先在一组基准实例上进行，这些基准实例包含不同共拓扑的PFs，并且知道PFs之间的确切关系。最后。这些指标应用于另一组实例，并与三个已知指标的结果进行比较。在这个集合中，每个优化器都涉及从多次运行中获得的多个PF，并且不知道PFs之间的确切关系。 izarraga等人提出了8个测试用例来评估指标的性能。测试用例是这样构造的:考虑的PFs之间的确切关系是已知的。每个测试用例包含五个PFs (A, B, C, D和E),除了第六测试此用例只包含两个PFs (A和B)。三维版本中也是如此创建的模式和关系,每个测试用例的PFs是类似的。 假设每一个优化器只有一个PF，并且也已知与其他优化器的PFs的关系如何。 a：此测试样例是关于PFs收敛性分析，$AO_cB; BO_cC;CO_cD;DO_cE​$，除此之外，所有的PFs都有相同数量的解集，多样性，延展性。 b：此测试样例是关于收敛性与多样性分析，$AO_cB,C; B,CO_cD,E$。$B$与$C$，$D$与$E$之间没有任何关系。所有的PFs有相同数量的解集，相同的多样性，但不同的延展性。 c：此测试样例中，所有的PFs有相同数量的解集，相同的收敛性，但是每一个PF都有一个洞，每个洞的大小不一。 d：此测试样例仅关于多样性。所有PFs有相同的收敛性和延展性但多样性不同。A是一致性分布，剩余的PFs都添加了一致性噪音(uniform noise)，但并没有影响其收敛性与延展性。 e：此测试样例用来独立评估收敛性和多样性的用例。A有三个均匀分布的解。B是通过给A添加一个新的非支配解来构造的，C是通过给B添加一个新的非支配解来构造的，以此类推，从而得到$EO_wDO_wCO_wBO_wA$。PFs也是这样构造的，E相对于D有一个更好的多样性，D相对于C有一个更好的多样性，依此类推。 f：此测试样例用于检测是否受到PF的凸性影响，所考虑的PFs具有相同的收敛性、多样性、扩散性和solu离子个数，但它们具有不同的凸性。 g：此测试样例是检查一个度量是否受到PF位置的影响，所有设计的PFs都具有相同的收敛性、多样性、扩张性和解的个数，但是它们都位于POF的不同位置。 h：最后一个测试样例被设计来研究具有多个解决方案的度量的行为。所考虑的五种PFs具有相同的收敛性、相同的扩散性和均匀的多样性，但解的个数不同。 最终实验结果如下： 请注意，测试用例5、7和8的PFs(图2(e)、g)和(h)由于以下原因不能正确区分。在测试用例5中，通过向A添加一个新的非支配解来构造B，通过向B添加一个新的非支配解来构造C，以此类推。因此，A完全被B重叠，B完全被C重叠，以此类推。因此使PFs不可区分。同样的，由于测试用例8的PFs具有相同的收敛性、相同的发散性和一致的多样性，所以它们之间是重叠的。另一方面，虽然测试用例7的每个PF在一个唯一的位置上都有一个曲线的模式，但是由于PF中有大量的高密度的解，所以PFs的指示符号并不能被清晰地识别出来。 论文中也介绍了一个optimizer with multiple PFs的情况。 但是实在不想翻译了。。。。。累死人 Purity原文： 其中的rank one可难倒我了，以为要看前文才能理解，结果看完了还是不懂，直到我查阅材料时发现以下这段话： an iterative ranking procedure: First all non-dominated individuals are assigned rank one and temporarily removed from the population. Then, the next nondominated individuals are assigned rank two and so forth. Finally, the rank of an individual determines its fitness value. 我才恍然大悟，原文里说的是$r_i$be the number of rank one solutions obtained from each MOO strategy.注意是solutions而不是nondominated solutions ，所以就会分等级制度，rank one、rank two。。。具体分法那段话就是步骤。 规定： 有N个MOO策略，$\{R^1_1,…R_1^N\} \ N &gt; 2$ ，下标是rank，上标是第几个策略。 $r_i$ 是第i个策略 $R_i$的等级1(rank one)的个数。 $R^* = \bigcup^N_{i=1}\{R^i_1\}$ 是所有集合的等级1集合的并集。 $r_i^*=|\{\gamma| \gamma \in R_1^i and \ \gamma \in R_1^*\}|$ 是在$R^i_1$与$R^*$的交集。 表达式为： P_i = \frac{r_i^*}{r_i}, i = 1,2,...,N该值是在[0,1]区间，并且越接近1越有良好的性能，纯度越高。 现在想想纯度的的命名还是很形象的。 Wave metric这个度量标准允许我们从这个解集中提取的以帕累托边界的个数来计算解集的深度。我们应该说“pareto layers”，但是下面的算法解释了为什么“pareto frontier”更适合这种情况。Wave metric只能应用于有限尺寸的解集。要计算wave，通常是这样进行的： set i=1 compute the Pareto frontier using solutions set points. Remove Pareto frontier points from the solutions set if the result set is empty, Wave = i else i = i + 1 and go to step 2 一个好的方法必须产生低wave的结果集。当wave = 1时，解集中的所有解都属于帕累托边界。在下图中，我们可以看到波度规在一个简单集合上的结果。对于这个集合，wave = 4： 实际上，我们可以从这个集合中提取4个帕累托边界。 wave metric有两个严重的缺点:它不能在两个解集之间进行区分，而且不可能在两个不同的解集上比较波度量计算的相同结果。 例如,如果我们计算解决方案上图的wave metric，,我们有wave = 4因为我们可以从这个集合中提取四个帕累托前沿。如果我们再加10分的Pareto frontier和计算wave metric,度量的值还是一样的。所以这个度规不能在这两个集合之间进行区分。第二，如果我们没有任何关于解集的先验信息，我们就不能说4是好是坏。 Dominance-based quality（有时间再说）Dominance ranking(太长了再说)Pareto dominance indicator(有时间再说)总结然而，所有dominance-based QIs都有一些弱点。它们提供的信息很少，不知道一组在多大程度上优于另一组。更重要的是，如果集的所有解互不支配，它们可能会使解集变得不可比较，这在多目标优化中经常发生。此外，值得注意的是，一些dominance-based QIs可能部分表示着解集的基数(cardinality)，因为一组尺寸大一点的解可能会导致更多的非支配解。]]></content>
      <categories>
        <category>indicators</category>
      </categories>
      <tags>
        <tag>MOEA</tag>
        <tag>indicator</tag>
        <tag>ConvergenceQI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[毕设]]></title>
    <url>%2F2019%2F01%2F12%2Findicator%2F</url>
    <content type="text"><![CDATA[放假回家了也要准备准备我的毕业设计，题目是《基于自适应的indicators的多目标优化算法》，如题古老的多目标优化的题目，首先当然是要先了解了解indicators，老师就把他最近写好的关于indicators的综述发给了我，真可谓综述啊！足足100个indicators，路漫漫。。。。。 概念介绍以下是解与解、集合与集合之间的关系： 把解与解的总结到表格里： 一般来说，解集的质量可以解释为它如何很好地表示帕累托前沿，可以分为四个方面:收敛性(convergence)、扩散性(spread)、一致性(uniformity)和基数性(cardinality)。 解集的收敛性(convergence)是指解集与帕累托前缘的距离。解集的扩展考虑集覆盖的区域。它涉及到集合的外部和内部部分。这不同于只考虑集合的边界的质量的广泛性(extensity)。注意，在存在问题帕累托前沿的情况下，解集的扩展也称为集的覆盖(coverage)。集的均匀性(uniformity)是指解分布在集中的均匀程度;解决方案之间的等距间距是所希望的。传播和均匀性是密切相关的,他们共同被称为一组的多样性(diversity)。解集的基数(cardinality)是指解决方案集的数量。总的来说,我们的期望足够的解决方案明确地描述集,但不是太多,可能会损害DM与选择。然而，如果使用相同数量的计算资源生成两个集，则认为具有更多解决方案的集是首选的。 比较解决方案集的质量的一种直接方法是将这些集可视化，并直观地判断一个集相对于另一个集的优越性。这种目视比较是最常用的方法之一，非常适用于双目标拖把或三目标拖把。当目标个数大于3时，解决方案集的直接观察不可用时(散点图),人们可能会求助于从数据分析领域的工具。然而，这些可视化方法可能无法清晰地反映解决方案集质量的所有方面;例如，常用的平行坐标只能部分反映收敛性、扩散性和均匀性。此外，可视化比较不能量化解决方案集之间的差异，因此不能用于指导最优化。 质量指标(Quality indicators, QIs)通过将解决方案集映射为实数来克服可视化比较的问题，从而提供解决方案集之间的数量差异。QIs能够提供解决方案集质量的精确表述，例如，在这些表述中，一个集的质量优于另一个集，以及一个集在某些方面比另一个集好多少。原则上，将一组向量映射成标量值的任何函数都可以看作是一个潜在的质量指示器，但通常它可能需要反映集合质量的一个或多个方面:收敛性、扩展性、一致性和基数性。注意，当比较由精确方法生成的解集时，由于生成的解集是问题的帕累托前沿的子集，所以不考虑解集的收敛性评价。 本节根据Qls主要捕获的质量方面来审查Qls。一般来说，QIs可分为六类:1)QIs用于收敛，2)QIs用于扩展，3)QIs用于均匀性，1)QIs用于基数性，5)QIs用于扩展和均匀性，6)Qls用于四个质量方面的组合质量。在每个类别中，我们还详细介绍了一个或几个示例指示器。这些QIs通常在文献中使用，并且/或在它们的类别中具有代表性。表2总结了所有100篇文献。请注意，它不包括由多个QIs组合而成的度量。 当当当！！！这是论文中总结的100个indicators！！WTF！！！老师让了解了解的时候我是崩溃的。我慢慢来… 加黑加粗的是我已经整理好的~ 安排： QIs for Convergence Dominance-based QIs Dominance-based QIs QIs for Spread]]></content>
      <categories>
        <category>indicators</category>
      </categories>
      <tags>
        <tag>MOEA</tag>
        <tag>indicators</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[matlab]]></title>
    <url>%2F2019%2F01%2F02%2Fmatlab%2F</url>
    <content type="text"><![CDATA[此文会持续更新，记录一些在matlab中的一些常用函数。 repmat123456&gt;&gt; a = [1 2 3];&gt;&gt; repmat(a,2,3) %把矩阵整体堆叠成新矩阵ans = 1 2 3 1 2 3 1 2 3 1 2 3 1 2 3 1 2 3 sort12345678910&gt;&gt; a = [6 3 2 1 4 5];&gt;&gt; [~,ans] = sort(a) % 默认从小到大的索引值ans = 4 3 2 5 6 1&gt;&gt; a(ans)ans = 1 2 3 4 5 6 尺寸扩展12345678&gt;&gt; a = ones(3);&gt;&gt; a(1,(4:5)) = 10a = 1 1 1 10 10 1 1 1 0 0 1 1 1 0 0]]></content>
      <categories>
        <category>matlab</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>matlab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MOEA/D算法(三)]]></title>
    <url>%2F2019%2F01%2F02%2Fmoead3%2F</url>
    <content type="text"><![CDATA[“MOEA/D: A Multiobjective Evolutionary Algorithm Based on Decomposition”第三部分，论文中一些具体的细节。 测试函数以下为具体函数，和所给定的前端解 ZDT1 f_1(1)=x_1 \\f_2=g(x)[1-\sqrt{\frac{f_1(x)}{g(x)}}] \\where \quad g(x)=1 + \frac{9(\sum_{i=2}^{n}{x_i})}{n-1} \\x=(x_1,...x_n) ，x_1\in [0,1]^n,n=30 ZDT2 f_1(x) = x_1 \\f_2=g(x)[1-(\frac{f_1(x)}{g(x)})^2] \\where \quad g(x)=1 + \frac{9(\sum_{i=2}^{n}{x_i)}}{n-1} \\x=(x_1,...x_n) ，x_1\in [0,1]^n,n=30 ZDT3 f_1(x) = x_1 \\f_2=g(x)[1-\sqrt{\frac{f_1(x)}{g(x)}}-\frac{f_1(x)}{g(x)}sin(10\pi x_1)] \\where \quad g(x)=1 + \frac{9(\sum_{i=2}^{n}{x_i)}}{n-1} \\x=(x_1,...x_n) ，x_1\in [0,1]^n,n=30 ZDT4 f_1(x) = x_1 \\f_2=g(x)[1-\sqrt{\frac{f_1(x)}{g(x)}}] \\where\quad g(x)=1 + 10(n-1)+\sum_{i=2}^{n}[x_i^2-10cos(4\pi x_i)] \\x=(x_1,...x_n) ，x_1\in [0,1] \times [-5,5]^{n-1},n=10 ZDT6 f_1(x)=1-exp(-4x_1)sin^6(6\pi x_1) \\f_2=g(x)[1-(\frac{f_1(x)}{g(x)})^2] \\g(x)=1 + 9[\frac{\sum_{i=2}^{n}{x_i}}{n-1}]^{0.25} \\x=(x_1,...x_n) ，x_1\in [0,1]^n,n=10 DTLZ1 f_1(x)=(1+g(x))x_1x_2 \\f_2(x)=(1+g(x))x_1(1-x_2) \\f_3(x)=(1+g(x))(1-x_1) \\where\quad g(x)=100(n-2)+100\sum_{i=3}^{n}{\{(x_i-0.5)^2-cos[20\pi (x_i-0.5)]\}} \\x=(x_1,...,x_n)^T \in [0,1]^n,n=10The function value of a Pareto optimal solution satisfies$\sum_{i=1}^{3}{f_i}=1,f_i \geq0$ DTLZ2 f_1(x)=(1+g(x))cos(\frac{x_1\pi}{2})cos(\frac{x_2\pi}{2}) \\f_2(x)=(1+g(x))cos(\frac{x_1\pi}{2})sin(\frac{x_2\pi}{2}) \\f_3(x)=(1+g(x))sin(\frac{x_1\pi}{2}) \\where\quad g(x)=\sum_{i=3}^{n}{x_i^2}, \\x=(x_1,...x_n)^T\in [0,1]^2\times [-1,1]^{n-2},n=10The function value of a Pareto optimal solution satisfies$\sum_{i=1}^{3}{f_i}^2=1,f_i \geq0$ 基本参数设置12345678910N=300;%种群大小T=20;%邻居规模大小max_gen=250;%进化代数pc=1;%交叉概率pm=1/x_num;%变异概率fun='DTLZ2';%有 ZDT1 ZDT2 ZDT3 ZDT4 ZDT6 DTLZ1 DTLZ2yita1=2;%模拟二进制交叉参数2yita2=5;%多项式变异参数5x_num = ;%根据以上每一个函数的定义f_num = ;%根据以上每一个函数的定义 权值向量初始化1234567891011121314151617181920212223242526272829303132function lamda = genrate_lamda( N,f_num )%产生初始化向量lamdalamda2=zeros(N+1,f_num);%初始化if f_num==2 array=(0:N)/N;%均匀分布的值 for i=1:N+1 lamda2(i,1)=array(i); lamda2(i,2)=1-array(i); end len = size(lamda2,1); index = randperm(len); index = sort(index(1:N)); lamda = lamda2(index,:);elseif f_num==3 k = 1; array = (0:25)/25;%产生均匀分布的值 for i=1:26 for j = 1:26 if i+j&lt;28 lamda3(k,1) = array(i); lamda3(k,2) = array(j); lamda3(k,3) = array(28-i-j); k=k+1; end end end len = size(lamda3,1); index = randperm(len); index = sort(index(1:N)); lamda = lamda3(index,:);endend 建立权值向量的邻域1B=look_neighbor(lamda,T); 其中look_neighbor.m为： 12345678910111213141516function B = look_neighbor( lamda,T )%计算任意两个权重向量间的欧式距离N =size(lamda,1);B=zeros(N,T);distance=zeros(N,N);for i=1:N for j=1:N l=lamda(i,:)-lamda(j,:); distance(i,j)=sqrt(l*l'); endend%查找每个权向量最近的T个权重向量的索引for i=1:N [~,index]=sort(distance(i,:)); B(i,:)=index(1:T);end 种群初始化1234567function X = initialize( N,f_num,x_num,x_min,x_max,fun )% 种群初始化X = repmat(x_min,N,1)+rand(N,x_num).*repmat(x_max-x_min,N,1); for i=1:N X(i,(x_num+1:(x_num+f_num))) = object_fun(X(i,:),f_num,x_num,fun); X(i,(x_num+f_num+1)) = 0;end 其中object_fun.m: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485function f = object_fun( x,f_num,x_num,fun )% 测试函数的设置%--------------------ZDT1--------------------if strcmp(fun,'ZDT1') f=[]; f(1)=x(1); sum=0; for i=2:x_num sum = sum+x(i); end g=1+9*(sum/(x_num-1)); f(2)=g*(1-(f(1)/g)^0.5);end%--------------------ZDT2--------------------if strcmp(fun,'ZDT2') f=[]; f(1)=x(1); sum=0; for i=2:x_num sum = sum+x(i); end g=1+9*(sum/(x_num-1)); f(2)=g*(1-(f(1)/g)^2);end%--------------------ZDT3--------------------if strcmp(fun,'ZDT3') f=[]; f(1)=x(1); sum=0; for i=2:x_num sum = sum+x(i); end g=1+9*(sum/(x_num-1)); f(2)=g*(1-(f(1)/g)^0.5-(f(1)/g)*sin(10*pi*f(1)));end%--------------------ZDT4--------------------if strcmp(fun,'ZDT4') f=[]; f(1)=x(1); sum=0; for i=2:x_num sum = sum+(x(i)^2-10*cos(4*pi*x(i))); end g=1+9*10+sum; f(2)=g*(1-(f(1)/g)^0.5);end%--------------------ZDT6--------------------if strcmp(fun,'ZDT6') f=[]; f(1)=1-(exp(-4*x(1)))*((sin(6*pi*x(1)))^6); sum=0; for i=2:x_num sum = sum+x(i); end g=1+9*((sum/(x_num-1))^0.25); f(2)=g*(1-(f(1)/g)^2);end%--------------------------------------------%--------------------DTLZ1-------------------if strcmp(fun,'DTLZ1') f=[]; sum=0; for i=3:x_num sum = sum+((x(i)-0.5)^2-cos(20*pi*(x(i)-0.5))); end g=100*(x_num-2)+100*sum; f(1)=(1+g)*x(1)*x(2); f(2)=(1+g)*x(1)*(1-x(2)); f(3)=(1+g)*(1-x(1));end%--------------------------------------------%--------------------DTLZ2-------------------if strcmp(fun,'DTLZ2') f=[]; sum=0; for i=3:x_num sum = sum+(x(i))^2; end g=sum; f(1)=(1+g)*cos(x(1)*pi*0.5)*cos(x(2)*pi*0.5); f(2)=(1+g)*cos(x(1)*pi*0.5)*sin(x(2)*pi*0.5); f(3)=(1+g)*sin(x(1)*pi*0.5);end%--------------------------------------------end 交叉变异操作模拟二进制交叉(SBX)for j = 1.....x_num x'_{1j}(t)=0.5\times[(1+\lambda_j)x_{1j}+(1-\lambda_j)x_{2j}(t)] \\x'_{2j}(t)=0.5\times[(1-\lambda_j)x_{1j}+(1+\lambda_j)x_{2j}(t)]其中： \lambda_j=\begin{cases} (2u_i)^{\frac{1}{\eta+1}}, & u_j < 0.5\\ \frac{1}{2(1-u_i)}^{\frac{1}{\eta+1}}, & other \end{cases}随机$u_j$，使$0 \leq u_j \leq 1$. endfor 多项式变异for j = 1.....x_num x_{1j}(t)=x_{1j}(t) + \Delta_j其中： \Delta_j=\begin{cases} (2u_i)^{\frac{1}{\eta+1}}-1, & u_j < 0.5\\ 1-(2(1-u_i))^{\frac{1}{\eta+1}}, & other \end{cases}随机$u_j$，使$0 \leq u_j \leq 1$. endfor 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273function chromo_offspring = cross_mutation( chromo_parent_1,chromo_parent_2,f_num,x_num,x_min,x_max,pc,pm,yita1,yita2,fun )%模拟二进制交叉与多项式变异%%%模拟二进制交叉if(rand(1)&lt;pc) %初始化子代种群 off_1=zeros(1,x_num+f_num); %进行模拟二进制交叉 u1=zeros(1,x_num); gama=zeros(1,x_num); for ind=1:x_num u1(ind)=rand(1); if u1(ind)&lt;=0.5 gama(ind)=(2*u1(ind))^(1/(yita1+1)); else gama(ind)=(1/(2*(1-u1(ind))))^(1/(yita1+1)); end off_1(ind)=0.5*((1-gama(ind))*chromo_parent_1(ind)+(1+gama(ind))*chromo_parent_2(ind)); %使子代在定义域内 if(off_1(ind)&gt;x_max(ind)) off_1(ind)=x_max(ind); elseif(off_1(ind)&lt;x_min(ind)) off_1(ind)=x_min(ind); end end %计算子代个体的目标函数值 off_1(1,(x_num+1):(x_num+f_num))=object_fun(off_1,f_num,x_num,fun);end% %%%多项式变异 注释这种方法为上方公式代码，但在ZDT4，DTLZ1中效果不好，% if(rand(1)&lt;pm) 因此换成下方代码，效果甚好！% u2=zeros(1,x_num);% delta=zeros(1,x_num);% for j=1:x_num% u2(j)=rand(1);% if(u2(j)&lt;0.5)% delta(j)=(2*u2(j))^(1/(yita2+1))-1;% else% delta(j)=1-(2*(1-u2(j)))^(1/(yita2+1));% end% off_1(j)=off_1(j)+delta(j);% %使子代在定义域内% if(off_1(j)&gt;x_max(j))% off_1(j)=x_max(j);% elseif(off_1(j)&lt;x_min(j))% off_1(j)=x_min(j);% end% end% %计算子代个体的目标函数值% off_1(1,(x_num+1):(x_num+f_num))=object_fun(off_1,f_num,x_num,fun);% end% chromo_offspring=off_1;% end%%%多项式变异 具体改变：一次变异只改变一个位置，并不是像之前那样都要变异if(rand &lt; pm) r=randperm(x_num); ind=r(1); u2=rand; if(u2 &lt; 0.5) delta=(2*u2)^(1/(yita2+1))-1; else delta=1-(2*(1-u2))^(1/(yita2+1)); end off_1(ind)=off_1(ind)+delta*(x_max(ind)-x_min(ind)); %使子代在定义域内 if(off_1(ind)&gt;x_max(ind)) off_1(ind)=x_max(ind); elseif(off_1(ind)&lt;x_min(ind)) off_1(ind)=x_min(ind); end %计算子代个体的目标函数值 off_1(1,(x_num+1):(x_num+f_num))=object_fun(off_1,f_num,x_num,fun);endchromo_offspring=off_1;end 更新领域解1X=updateNeighbor(lamda,z,X,B(i,:),off,x_num,f_num); 其中updateNeighbor.m： 1234567891011function X = updateNeighbor( lamda,z,X,Bi,off,x_num,f_num )%更新领域解for i=1:length(Bi) gte_xi=tchebycheff_approach(lamda,z,X(Bi(i),(x_num+1):(x_num+f_num)),Bi(i)); gte_off=tchebycheff_approach(lamda,z,off(:,(x_num+1):(x_num+f_num)),Bi(i));% gte_xi=ws_approach(lamda,X(Bi(i),(x_num+1):(x_num+f_num)),Bi(i));% gte_off=ws_approach(lamda,off(:,(x_num+1):(x_num+f_num)),Bi(i)); if gte_off &lt;= gte_xi X(Bi(i),:)=off; endend 其中tchebycheff_approach.m： 123456789function fs = tchebycheff_approach( lamda,z,f,i)%tchebycheff_approachfor j=1:length(lamda(i,:)) if(lamda(i,j)==0) lamda(i,j)=0.00001; endendfs=max(lamda(i,:).*abs(f-z));end 评价指标C-metric令 A和 B是一个 MOP中两个接近PF的集合，定义 C(A,B)如： C(A,B)=\frac{\{u\in B|\exists v\in A:v\quad dominates\quad u\}}{|B|}C(A,B)不等于 1-C(B,A)。C(A,B)=1意味着 B中所有的解都被 A中的某些解支配了， C(A,B)=0意味着 B中没有解被 A中的解支配。 1234567891011121314151617181920212223242526function C_AB = cal_c(A,B,f_num)[temp_A,~]=size(A);[temp_B,~]=size(B);number=0;for i=1:temp_B nn=0; for j=1:temp_A less=0;%当前个体的目标函数值小于多少个体的数目 equal=0;%当前个体的目标函数值等于多少个体的数目 for k=1:f_num if(B(i,k)&lt;A(j,k)) less=less+1; elseif(B(i,k)==A(j,k)) equal=equal+1; end end if(less==0 &amp;&amp; equal~=f_num) nn=nn+1;%被支配个体数目n+1 end end if(nn~=0) number=number+1; endendC_AB=number/temp_B;end D-metric令 $P^*$为一组均匀分布在 PF上的点集合。 A是一个接近 PF的集合。 的集合。 $P^*$到 A的平均距离定义为： D(A,P)=\frac{\sum_{v\in P^*}d(v,A)}{|P^*|}这里 $𝑑(𝑣,𝐴)$是v和A中的点最小欧式距离。如果 $P^*$足够大,说明其可以很好的代表PF。$D(A,P^*)$可以从某种意义上评估A的收敛性和多样。为了让$D(A,P^*)$的值很低，必须设置 A非常接近PF，并且不能缺失整个PF的任何部分。 12345678910function D_AP = cal_d(A,P)[temp_A,~]=size(A);[temp_P,~]=size(P);min_d=0;for v=1:temp_P d_va=(A-repmat(P(v,:),temp_A,1)).^2; min_d=min_d+min(sqrt(sum(d_va,2)));endD_AP=(min_d/temp_P);end ‘]]></content>
      <categories>
        <category>MOEA</category>
      </categories>
      <tags>
        <tag>MOEA</tag>
        <tag>MOEA\D</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MOEA/D算法(二)]]></title>
    <url>%2F2019%2F01%2F01%2Fmoead2%2F</url>
    <content type="text"><![CDATA[“MOEA/D: A Multiobjective Evolutionary Algorithm Based on Decomposition”第二部分，算法的流程框架。 规定本文提出的基于分解的多目标进化算法(MOEA/D)需要对MOPs进行分解。任何分解方法都可以达到这个目的。在下面的描述中，我们假设使用了Tchebycheff方法。在使用其他分解方法时，修改下面的MOEA/D也非常简单。 $\lambda^1​$,…$\lambda^N​$ 是均匀分布的权值向量 $z^*$ 是reference point 选用Tchebycheff Approach把多目标问题拆成N个标量优化子问题，表达式如下: g^{te}(x|\lambda^j,z^*)=\max\limits_{1\leq i \leq m}\{\lambda_i^j|f_i(x)-z_i^*|\} 其中 $\lambda ^j=(\lambda_1^j,…\lambda_m^j)^T$. $\lambda=(\lambda^1,…,\lambda^N)$ 可知$g^{te}$是关于$\lambda$连续的，当$\lambda^i$与$\lambda^j$彼此接近，那么接近$\lambda ^i$向量的$g^{te}$权向量的信息也对最优解$g^{te}(x|\lambda^j,z^*)$有一定的作用。这也是MOEA/D的理论基础。 在MOEA/D中，权向量的邻域被定义为它的几个最近的权向量的集合。第$i$个子问题的邻域由所有的子问题组成，这些子问题的权向量来自于第$i$个子问题的邻域。在MOEA/D中，只有相邻子问题的当前解被用来优化子问题。 切比雪夫法的MOEA/D算法中，有以下规定： $x^1,…x^N \in \Omega$ $x^i$是当前的第i个子问题 $FV^1,…,FV^N$ ，其中 $FV^i = F(x^i)$ $ x \in [1,N]$ $z=(z_1,…z_m)^T $ ，$z_i$ 是目前对目标$f_i$所找到的最好的点。 Input MOP(1) 一个终止准则 N：子问题的个数 N 个均匀分布的权值向量$\lambda_1,…\lambda_N$ T 每一个权值向量的邻居的数量Output: EP STEP 1) Initialization:Step 1.1) 使EP为空集 Step 1.2) 计算任意两个权值向量间的欧式距离，并找到离每个权值距离最近的T个点 ​ $B(i)=\{i_i,…i_T\}$ ，其中，$\lambda^{i_1},…\lambda^{i_T}$就是T个最近的权值向量 Step 1.3) 随机产生初始化种群 $x^1,…,x^N$ ，规定$FV^i=F(x^i).$ Step 1.4) 初始化 $z=(z_1,…z_m)^T $ STEP 2) Update:for i=1,…N Step 2.1) 复制 ：从$B(i)$随机产生两个索引$k,l$ ，然后通过遗传算子从$x_k,x_l$ 中产生新的子代$y$ Step 2.2) 提升 ：通过提升或者修理来启发式的由$y$产生$y’$ Step 2.3) 更新参考点$z$：if $z_j &lt; f_j(y’)$ then $z_j = f_j(y’)$ $j \in 1,…m$ Step 2.4) 更新相邻解：对于每一个$j \in B(i)$,if $g^{te}(y’|\lambda^j,z)\leq g^{te}(x^j|\lambda^j,z)$ then $x^j=y’, FV^j=F(y’)$ Step 2.5) 更新EP：​ — 从 EP中移除被 $F(y’)$支配的所有向量​ — 如果 EP中没有向量支配 $F(y’)​$，就将 F(y’)加入到EP中 STEP 3) Stopping Criteria 如果停止准则满足，并输出EP。否则，转向 STEP 2)。]]></content>
      <categories>
        <category>MOEA</category>
      </categories>
      <tags>
        <tag>MOEA</tag>
        <tag>MOEA\D</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MOEA/D算法(一)]]></title>
    <url>%2F2018%2F12%2F31%2Fmoead1%2F</url>
    <content type="text"><![CDATA[最近在复现“MOEA/D: A Multiobjective Evolutionary Algorithm Based on Decomposition”这篇论文，但多目标优化门都没入，所以作为复现的第一篇MOEA算法，我要趁此好好肢解这篇论文，尽量理解。 在Weighted Sum Approach表达式为： min\quad g^{ws}(x|\lambda)=\sum_{i=0}^{m}\lambda_if_i(x)m：m个优化目标， $\sum_{i=1}^{m}\lambda_i = 1$ $\lambda​$ 被称为权重向量。 通过公式，把算法求出的一个目标点和原点相连构造成一个向量与对应权重向量点乘，由向量点乘的几何意义可知，所得的数为该向量在权重向量方向上的投影长度，因为权重向量不变，最大/小化该长度值其实就是在优化该向量。可知若要增大该向量在权重向量上投影的长度，一方面可以增大/减小与权重向量的夹角，另一方面可以增大/减小该向量的长度。样例图如下： 红色权重向量，因为是最小化问题，所以减小长度，增大夹角都是可行的方案，绿色为等高线，垂直于权重向量。阴影部分为所有解，因此，在每一个绿色的等高线上找角度最大的即为边界。 Tchebycheff Approach表达式为： minimize\quad g^{te}(x|\lambda,z^*)=\max \limits_{1\leq i \leq m}\{\lambda_i|f_i(x)-z^*|\}注意该方法中不再含有$\sum$符号，故不能再从向量点乘的角度理解。该方法大致思想是减少最大差距从而将个体逼近PF。 首先解释等高线为什么是这样的。单看$f_1$函数，即只考虑纵坐标，若两点等值，必然是$\lambda_i|f_i(x)-z^*|$式中$f_1$的函数值相等（因为另外两个量是不变的），即纵坐标相等，所以$f_1$函数的等高线是一组平行于横轴的直线。$f_2$类似，为一组平行于纵轴的直线。第一次相比较的是m个维度中最大的$max ( \lambda _1(y-z_1),\lambda _2(x-z_2))$，所以等高线便是一个点之内各个维度的比较。那么，图中的等高线是横竖相交且刚好交在权重向量的方向上的，证明：可知，对于任何一个可行的解，我们从$f_1$的角度上可以得到一个$f_1$的值y，从$f_2$的角度上可以得到一个$f_2$ 的值x，他们的切比雪夫值是相等的，自然想到：点(x,y)（图中紫色点）为该切比雪夫值得横纵两条等值线的交点，那么有：$\lambda _1(y-z_1)=\lambda_2(x-z_2)$，化简的$(y-z_1)/(x-z_2)=\lambda_2/\lambda_1$，可知该交点位于权重向量的方向上。需要注意一点，这里的权重向量起点是$z^*$，不再是原点。此时可知，若某个个体位于其($\lambda -z^*$)向量方向的上部，则max得到的一定是其$f_1$部分，故优化也需要减小其$f_1$的值，即个体向下移动，相反，若在($\lambda -z^*$)向量方向的下部，则应像左移动。以此来保证个体目标值落在黄点附近。 一种可能的个体运动路线如下图，橘色—&gt;黄色所示： Boundary IntersectionApproach表达式为： minimize\quad g^{bi}(x|\lambda,z^*)=d \\subject\quad to\quad z^*-F(x)=d\lambda \\x \in \Omega参数含义如下如所示： 式子中等式约束其目的是为了保证F(x)位于权重向量λ的方向上，通过减小d来使算法求出的解逼近PF。但该条件不太容易实现，故将其改进为下边这种方法。 Penalty-based Boundary Intersection Approach minimize\quad g^{bip}(x|\lambda,z^*)=d_1 + \theta d_2 \\subject \quad to \quad x \in \Omega \\where \quad \quad d_1 =\frac{||(z_*-F(x))^T\lambda||}{||\lambda||} \\and \quad d_2 = ||F(x)-(z^*-d_1\lambda)||参数含义如下如所示： 可知算法放宽了对算法求出的解得要求，但加入了一个惩罚措施：你可以不把解生成在权重向量的方向上，但如果不在权重向量方向上，你就必须要接收惩罚，你距离权重向量越远，受的惩罚越厉害，以此来约束算法向权重向量的方向生成解。 接下来是关于$d_1$和$d_2$两个参数的计算表达式的含义说明，我依然是从几何角度理解的。 $d_1$——观察$d_1$的计算表达式，$Z^*-F(x)$可以看做原点到$Z^*$点的向量减去原点到$F(x)$的向量，得到的是从$F(x)$出发指向$Z^*$的一个向量，暂且命名为$\mu$，之后$\mu$与$\lambda$相乘得到$\mu$在方向上的投影，这$\lambda$个长度值与λ的长度值之比为$d_1$。$d_2$——其表达式的含义其实也无非就是利用向量运算构造出$d_2$所表示的向量，取模即可得到$d_2$.构造过程如下： $Z^*$表红色向量，$d_1\lambda$表蓝色向量（因为减法，所以方向取反），红色减蓝色得紫色向量，$F(x)$表绿色向量，绿色减紫色得黄色向量，即$d_2$表黄色向量的长度 引自]]></content>
      <categories>
        <category>MOEA</category>
      </categories>
      <tags>
        <tag>MOEA</tag>
        <tag>MOEA\D</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MOEA/D算法(0)]]></title>
    <url>%2F2018%2F12%2F30%2Fmoead0%2F</url>
    <content type="text"><![CDATA[最近在复现“MOEA/D: A Multiobjective Evolutionary Algorithm Based on Decomposition”这篇论文这是一个后补上的文章，几乎是翻译的原论文呢】，因为课程设计凑字数，也为了省事，就干脆发在我的小博客上了。 多目标优化问题可以表示如下： maximize \quad F(x)=(f_1(x),...,f_m(x))^T \\subject \ to \ x \in \Omega其中，$\Omega$是决策空间，$F$：$\Omega \rightarrow R^m$是m个实数目标函数，$R^m$叫做目标空间，可实现的目标定义如下： \Omega=\{x \in R^n|h_j(x)\leq 0,j=1,...,m\}$h_j$是连续的函数，因此，我们也称$F(x)$是连续的MOP问题。 在现实生活中，大多数的目标函数却是相互矛盾的，并不存在$\Omega$可以同时放大所有的目标值。因此需要找相应的方法去平衡这些目标。目标之间的最佳权衡可以用帕累托(Pareto)最优性来定义。 定义$u,v\in R^m$,如果对于$\forall i \in \{1,…,m\}$，使得$u_i\geq v_i$，并且$\exists j \in \{1,…,m\} $，使得$u_i &gt; v_i$，则称$u$支配$v$。如果存在这种点$x^\in \Omega$，不存在点$x$，使$F(x)$支配$F(x^)$，那么称$F(x^*）$为帕累托最优目标向量。换言之，一个目标中帕累托最优点的任何改进都必须导致至少另一个目标的恶化。所有帕累托最优点的集合称为帕累托集合(PS)，所有帕累托最优目标向量的集合称为帕累托阵(PF)。 在多目标优化的许多实际应用中，决策者需要近似于PF来选择最终的首选解决方案。大多数MOPs可能有许多甚至无限帕累托最优向量。获取完整的PF是非常耗时的。另一方面，由于信息的溢出，决策者可能对拥有过多的帕累托最优向量不感兴趣。因此，许多多目标优化算法都是为了找到一个可管理的帕累托最优向量。一些研究者也尝试用数学模型来近似PF。 目前没有涉及到分解的大部分多目标进化算法，将MOP视为一个整体。它们不会将每个单独的解决方案与任何特定的标量优化问题关联起来。在标量目标优化问题，所有的解决方案都可以在它们目标函数值的基础上进行比较，标量目标的任务进化算法(EA)往往是寻找一个单一的最优的解决方案。然而，在MOPs中，支配并非定义目标函数中解的完整顺序空间，MOEAs旨在产生一些帕累托最优尽可能多样化的解决方案来代表整体PF。 因此，最初设计用于标量优化的传统选择算子不能直接用于非分解MOEAs。那么可以说，如果有一种适合度分配方案，用于为单个解决方案分配一个相对适合度值，以反映其选择的实用价值，那么标量优化EAs可以很容易地扩展到处理MOPs。因此，适应度分配一直是当前的一个主要问题MOEA研究。目前流行的适应度分配策略包括基于交互目标的适应度分配，如向量评价遗传算法(VEGA);基于优势的适应度分配，如帕累托存档进化策略（PAES）。 分解的思想在一些针对MOPs的元启发式中得到了一定程度的应用。例如，两阶段局部搜索(TPLS)考虑了一组标量优化问题，其中目标是所考虑的MOP中的目标的集合，基于集合系数的序列将标量优化算法应用于这些标量优化问题中，将前一个问题得到的解作为下一个问题求解的起点，因为它的集合目标与前一个问题的集合目标略有不同。多目标遗传局部搜索(MOGLS)旨在同时优化加权和方法或Tchebycheff方法构建的所有聚合。在每次迭代中，它优化随机生成的聚合目标。]]></content>
      <categories>
        <category>MOEA</category>
      </categories>
      <tags>
        <tag>MOEA</tag>
        <tag>MOEA\D</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vscode配置c环境]]></title>
    <url>%2F2018%2F12%2F22%2Fvscode%E9%85%8D%E7%BD%AEc%2F</url>
    <content type="text"><![CDATA[在sublime和vscode的权衡下，选择了vscode，毕竟之前一直用的是sublime，想换一换了。于是就遇到一个老问题，配环境！ 此内容几乎完全来自于某乎 安装 vscode LLVM 选Pre-Built Binaries中的Clang for Windows (64-bit)，不需要下.sig文件 添加环境变量：Add LLVM to the system PATH for all users 安装路径推荐：C:\LLVM 工具链：MinGW 其他默认 MinGW-w64 - for 32 and 64 bit Windows 链接，提取码：dclo 下好后，把x86_64-7.2.0-posix-seh-rt_v5-rev0.7z\mingw64 中所有的文件都复制到 C:\LLVM中 检验：打开cmd 输入gcc，如果为no input files而不是其他，即为成功。 ​ 输入clang，如果为no input files而不是其他，即为成功。 ​ 插件一定要下： C/C++ C/C++ Clang Command Adapter Code Runner 自由推荐： Bracket Pair Colorizer：彩虹花括号 Include Autocomplete：提供头文件名字的补全 One Dark Pro：VS Code安装量最高的主题 环境配置打开vscode，一定要选 open folder 选择刚才那个文件夹，点VS Code上的新建文件夹，名称为.vscode（这样做的原因是Windows的Explorer不允许创建的文件夹第一个字符是点），然后创建 launch.json，tasks.json，settings.json，c_cpp_properties.json放到.vscode文件夹下 launch.json:12345678910111213141516171819202122232425262728// https://github.com/Microsoft/vscode-cpptools/blob/master/launch.md&#123; &quot;version&quot;: &quot;0.2.0&quot;, &quot;configurations&quot;: [ &#123; &quot;name&quot;: &quot;(gdb) Launch&quot;, // 配置名称，将会在启动配置的下拉菜单中显示 &quot;type&quot;: &quot;cppdbg&quot;, // 配置类型，这里只能为cppdbg &quot;request&quot;: &quot;launch&quot;, // 请求配置类型，可以为launch（启动）或attach（附加） &quot;program&quot;: &quot;$&#123;fileDirname&#125;/$&#123;fileBasenameNoExtension&#125;.exe&quot;, // 将要进行调试的程序的路径 &quot;args&quot;: [], // 程序调试时传递给程序的命令行参数，一般设为空即可 &quot;stopAtEntry&quot;: false, // 设为true时程序将暂停在程序入口处，我一般设置为true &quot;cwd&quot;: &quot;$&#123;workspaceFolder&#125;&quot;, // 调试程序时的工作目录 &quot;environment&quot;: [], // （环境变量？） &quot;externalConsole&quot;: true, // 调试时是否显示控制台窗口，一般设置为true显示控制台 &quot;internalConsoleOptions&quot;: &quot;neverOpen&quot;, // 如果不设为neverOpen，调试时会跳到“调试控制台”选项卡，你应该不需要对gdb手动输命令吧？ &quot;MIMode&quot;: &quot;gdb&quot;, // 指定连接的调试器，可以为gdb或lldb。但目前lldb在windows下没有预编译好的版本。 &quot;miDebuggerPath&quot;: &quot;gdb.exe&quot;, // 调试器路径，Windows下后缀不能省略，Linux下则去掉 &quot;setupCommands&quot;: [ // 用处未知，模板如此 &#123; &quot;description&quot;: &quot;Enable pretty-printing for gdb&quot;, &quot;text&quot;: &quot;-enable-pretty-printing&quot;, &quot;ignoreFailures&quot;: false &#125; ], &quot;preLaunchTask&quot;: &quot;Compile&quot; // 调试会话开始前执行的任务，一般为编译程序。与tasks.json的label相对应 &#125; ]&#125; tasks.json:命令行参数方面，-std根据自己的需要修改。如果使用Clang编写C语言，把command的值改成clang。如果使用MinGW，编译C用gcc，编译c++用g++，并把-target和-fcolor那两条删去。 123456789101112131415161718192021222324252627282930313233// https://code.visualstudio.com/docs/editor/tasks&#123; &quot;version&quot;: &quot;2.0.0&quot;, &quot;tasks&quot;: [ &#123; &quot;label&quot;: &quot;Compile&quot;, // 任务名称，与launch.json的preLaunchTask相对应 &quot;command&quot;: &quot;clang++&quot;, // 要使用的编译器 &quot;args&quot;: [ &quot;$&#123;file&#125;&quot;, &quot;-o&quot;, // 指定输出文件名，不加该参数则默认输出a.exe，Linux下默认a.out &quot;$&#123;fileDirname&#125;/$&#123;fileBasenameNoExtension&#125;.exe&quot;, &quot;-g&quot;, // 生成和调试有关的信息 &quot;-Wall&quot;, // 开启额外警告 &quot;-static-libgcc&quot;, // 静态链接 &quot;-fcolor-diagnostics&quot;, // 彩色的错误信息？但貌似clang默认开启而gcc不接受此参数 &quot;--target=x86_64-w64-mingw&quot;, // clang的默认target为msvc，不加这一条就会找不到头文件；Linux下去掉这一条 &quot;-std=c++17&quot; // C语言最新标准为c11，或根据自己的需要进行修改 ], // 编译命令参数 &quot;type&quot;: &quot;shell&quot;, // 可以为shell或process，前者相当于先打开shell再输入命令，后者是直接运行命令 &quot;group&quot;: &#123; &quot;kind&quot;: &quot;build&quot;, &quot;isDefault&quot;: true // 设为false可做到一个tasks.json配置多个编译指令，需要自己修改本文件，我这里不多提 &#125;, &quot;presentation&quot;: &#123; &quot;echo&quot;: true, &quot;reveal&quot;: &quot;always&quot;, // 在“终端”中显示编译信息的策略，可以为always，silent，never。具体参见VSC的文档 &quot;focus&quot;: false, // 设为true后可以使执行task时焦点聚集在终端，但对编译c和c++来说，设为true没有意义 &quot;panel&quot;: &quot;shared&quot; // 不同的文件的编译信息共享一个终端面板 &#125; // &quot;problemMatcher&quot;:&quot;$gcc&quot; // 如果你不使用clang，去掉前面的注释符，并在上一条之后加个逗号。照着我的教程做的不需要改（也可以把这行删去) &#125; ]&#125; settings.json: Code Runner的命令行和某些选项可以根据自己的需要在此处修改，用法还是参见此扩展的文档和百度gcc使用教程。如果你要使用其他地方的头文件和库文件，可能要往clang.cflags和clang.cxxflags里加-I和-L，用法百度gcc使用教程。12345678910111213141516171819202122232425262728293031&#123; &quot;files.defaultLanguage&quot;: &quot;cpp&quot;, // ctrl+N新建文件后默认的语言 &quot;editor.formatOnType&quot;: true, // 输入时就进行格式化，默认触发字符较少，分号可以触发 &quot;editor.snippetSuggestions&quot;: &quot;top&quot;, // snippets代码优先显示补全 &quot;code-runner.runInTerminal&quot;: true, // 设置成false会在“输出”中输出，无法输入 &quot;code-runner.executorMap&quot;: &#123; &quot;c&quot;: &quot;cd $dir &amp;&amp; clang $fileName -o $fileNameWithoutExt.exe -Wall -g -Og -static-libgcc -fcolor-diagnostics --target=x86_64-w64-mingw -std=c11 &amp;&amp; $dir$fileNameWithoutExt&quot;, &quot;cpp&quot;: &quot;cd $dir &amp;&amp; clang++ $fileName -o $fileNameWithoutExt.exe -Wall -g -Og -static-libgcc -fcolor-diagnostics --target=x86_64-w64-mingw -std=c++17 &amp;&amp; $dir$fileNameWithoutExt&quot; &#125;, // 设置code runner的命令行 &quot;code-runner.saveFileBeforeRun&quot;: true, // run code前保存 &quot;code-runner.preserveFocus&quot;: true, // 若为false，run code后光标会聚焦到终端上。如果需要频繁输入数据可设为false &quot;code-runner.clearPreviousOutput&quot;: false, // 每次run code前清空属于code runner的终端消息 &quot;C_Cpp.clang_format_sortIncludes&quot;: true, // 格式化时调整include的顺序（按字母排序） &quot;C_Cpp.intelliSenseEngine&quot;: &quot;Default&quot;, // 可以为Default或Tag Parser，后者较老，功能较简单。具体差别参考cpptools扩展文档 &quot;C_Cpp.errorSquiggles&quot;: &quot;Disabled&quot;, // 因为有clang的lint，所以关掉 &quot;C_Cpp.autocomplete&quot;: &quot;Disabled&quot;, // 因为有clang的补全，所以关掉 &quot;clang.cflags&quot;: [ // 控制c语言静态检测的参数 &quot;--target=x86_64-w64-mingw&quot;, &quot;-std=c11&quot;, &quot;-Wall&quot; ], &quot;clang.cxxflags&quot;: [ // 控制c++静态检测时的参数 &quot;--target=x86_64-w64-mingw&quot;, &quot;-std=c++17&quot;, &quot;-Wall&quot; ], &quot;clang.completion.enable&quot;:true // 效果效果比cpptools要好&#125; c_cpp_properties.json: 1234567891011121314151617181920212223&#123; &quot;configurations&quot;: [ &#123; &quot;name&quot;: &quot;MinGW&quot;, &quot;intelliSenseMode&quot;: &quot;clang-x64&quot;, &quot;compilerPath&quot;: &quot;C:/LLVM/bin/gcc.exe&quot;, &quot;includePath&quot;: [ &quot;$&#123;workspaceFolder&#125;&quot; ], &quot;defines&quot;: [], &quot;browse&quot;: &#123; &quot;path&quot;: [ &quot;$&#123;workspaceFolder&#125;&quot; ], &quot;limitSymbolsToIncludedHeaders&quot;: true, &quot;databaseFilename&quot;: &quot;&quot; &#125;, &quot;cStandard&quot;: &quot;c11&quot;, &quot;cppStandard&quot;: &quot;c++17&quot; &#125; ], &quot;version&quot;: 4&#125; 编译技巧 ctrl+shift+B单纯编译 按F5为运行并调试（运行前会自动编译） 加断点在列号前面点一下就行，如果想从一开始就停下来，可以加在main函数那里，或者launch.json中设置&quot;stopAtEntry&quot;: true。 按f11可以一步一步进行，箭头所指的那行代码就是下一步要运行的代码。 左边有个调试栏，可以看到变量的值,自动栏没有的可以手动添加表达式 把鼠标放到变量上可以看到变量的值，但是只能识别简单的表达式 栈帧对于递归很有用；在某些时候还可以抓取“异常”。 如果你不需要调试，可以直接右键选run code。 输出端可以输入，在settings.json中添加&quot;code-runner.runInTerminal&quot;: true]]></content>
      <categories>
        <category>vscode</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>vscode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo恢复]]></title>
    <url>%2F2018%2F12%2F22%2Fhexo%E6%81%A2%E5%A4%8D%2F</url>
    <content type="text"><![CDATA[想重新开始写博客，第一件事当然是恢复博客的正常使用啦！搜了小半天终于找到了符合我条件的教程。 背景：起初已配置好，但之后从未使用，期间重新做了一次系统。待我有时间再查询一下如何备份至云端。(已完成) 恢复安装git、node.js在原来储存博客的文件夹中(blog)`右键`-&gt;`选择`-&gt;`Git Bash Here` 再输入：1npm install hexo -g 因为重装系统有可能删除了配置文件包括环境变量里面的，没有配置 name 和 email 的话，git 是无法正常工作的。所以首先得重新配置name跟email在git bash里面输入下面两行 12git config --global user.name &quot;你的名字&quot;git config --global user.email &quot;你的邮箱&quot; 如果上面两条命令fail了的话，记得先用命令git init再输入上面两条命令 创建SSH输入 ssh-keygen -t rsa -C &quot;myemail@example.com&quot; 再按两次回车输入 cd ~/.ssh 再输入 cat id_rsa.pub会输出 12ssh-rsa xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxmyemail@example.com 登陆我的Github在settings中找到ssh and GPG keys点击new ssh key，title随意 把ssh-rsa xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx输入到key位置在git bash输入ssh -T git@github.com 可验证时候正确 修改blog目录下_config.yml如果执行hexo deploy提示 123Logon failed, use ctrl+c to cancel basic credential prompt.bash: /dev/tty: No such device or addressINFO Catch you later 则需要把下方的 1234deploy: type: git repo: https://github.com/mygithubName/mygithubName.github.io.git branch: master 修改成： 1234deploy: type: git repo: ssh://git@github.com/mygithubName/mygithubName.github.io.git branch: master 执行 hexo g -d 大功告成 常规操作： 1234hexo cleanhexo generatehexo server(本地测试用)hexo deploy 至此，网站已基本恢复。 云备份至Github为了以后更方便的从云端备份下来，我又查了一些教程，下面便是详细步骤 基本原理网站的部署其实就是生成静态文件，hexo下所有生成的静态文件会放在public/文件夹中，所谓部署deploy其实就是 将public/文件夹中内容上传到git仓库myname.github.io中。也就是说，你的仓库myname.github.io中的文件只是blog（或者命名为hexo）文件夹下的public/下的文件。本背景下，方便放在myname.github.io的repository下创建一个分支来管理 建立分支hexo 在本地磁盘下（位置任意）右键 -&gt; Git bash here，执行以下指令将myname.github.io项目文件克隆到本地： 1git clone git@github.com:myname/myname.github.io.git 此目录下便有myname.github.io文件夹，把此文件夹中除了.git之外的所有文件删掉 把blog中所有文件复制到myname.github.io 文件夹中，其中会提示是否替换，选择跳过。 如果有.gitignore文件，把里面的内容修改成 1234567.DS_StoreThumbs.dbdb.json*.lognode_modules/public/.deploy*/ 如果没有此文件，便在git bash中输入touch .gitignore 在myname.github.io 文件夹中右键 -&gt; Git bash here 创建一个叫hexo的分支并切换到这个分支上 git checkout -b hexo 提交复制过来的文件到暂存区git add --all 提交git commit -m &quot;&quot; 推送分支到githubgit push --set-upstream origin hexo在github上可以看到 branch中有master和hexo，至此，已经成功。并且hexo中的文件便在.gitirnore所忽略而剩下需要备份的文件， 更新文章，修改主题等步骤 在github中myname.github.io中，找到settings -&gt; Branches 将hexo设为默认 从此更新文章，修改主题等操作一直都在myname.github.io了 执行如下 123456hexo cleanhexo generatehexo deploygit add .git commit -m &quot;&quot;git push origin hexo 注意 -m “要写一点东西” 从github上还原此部分完全摘抄自网站，我并非试过，并不知道是否可行。 克隆项目 1git clone -b hexo git@github.com:myname/myname.github.io.git 进入博客目录 1cd myname.github.io.git 切换到博客文件分支 1git checkout -b hexo origin/hexo 安装hexo 1nmp install hexo --save 编辑，查看 12hexo ghexo s 提交git若提交过程中出现ERROR Deployer not found: git,可执行以下代码，然后重新提交 1npm install hexo-deployer-git --save 新的文章等更新 123git add .git commit -m &quot;新增博客&quot;git push origin hexo END]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>教程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[小小念]]></title>
    <url>%2F2018%2F12%2F22%2F%E5%B0%8F%E5%B0%8F%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[​ 啊啊啊啊啊啊，当时心一热搭建了一个博客，时隔四个月一直却没有更新博客善哉善哉，但期间也经历了好多，从准备保研的焦头烂额，到现在天天看剧打游戏的糜烂生活，落差之大，以至于日日积累的罪恶感促使我又有好好学习之意，遂重新在网上找了小半天的教程，把静静躺在H盘的blog文件夹重新唤醒。​ 当时心心念的保研，经历了很多很多次的失败，多方权衡下，最后以去南方科技大学而告终，毕业设计的题目也基本确定，很经典的问题——多目标优化，这也可能是我研究生研究的方向了。 ​ 从今天开始，可能就要持续更新我的小博客，记录一下~~]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>感慨</tag>
        <tag>随想</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[markdown语法]]></title>
    <url>%2F2018%2F08%2F23%2Fmarkdown%2F</url>
    <content type="text"><![CDATA[Typora For Markdown 语法，才刚刚学习，用着可能不熟练，先自行收藏一下~ 数学表达式要启用这个功能，首先到Preference-&gt;Editor中启用。然后使用`符号包裹Tex命令，例如：`$lim_{x \to \infty} \ exp(-x)=0将产生如下的数学表达式： $\lim_{x \to \infty} \exp(-x)=0$ 下标下标使用~包裹，例如：H~2~O将产生H~2~O, 即水的分子式。 上标上标使用^包裹，例如：y^2^=4将产生表达式y^2^ = 4 插入表情:happy:使用:happy:输入表情:happy:,使用:sad:输入表情:sad:,使用:cry:输入表情:cry:等。以此类推！ 下划线用HTML的语法&lt;u&gt;Underline&lt;/u&gt;将产生下划线Underline. 删除线GFM添加了删除文本的语法，这是标准的Markdown语法木有的。使用~~包裹的文本将会具有删除的样式，例如~删除文本~将产生删除文本的样式。 代码 使用`包裹的内容将会以代码样式显示，例如 1使用`printf()` 则会产生printf()样式。 输入`12* ​1234public Class HelloWorld&#123; System.out.println("Hello World!");&#125;​ 1234567将会产生~~~javapublic Class HelloWorld&#123; System.out.println(&quot;Hello World!&quot;);&#125; 强调使用两个*号或者两个_包裹的内容将会被强调。例如 12**使用两个*号强调内容**__使用两个下划线强调内容__ 将会输出 使用两个*号强调内容使用两个下划线强调内容Typroa 推荐使用两个*号。 斜体在标准的Markdown语法中，*和_包裹的内容会是斜体显示，但是GFM下划线一般用来分隔人名和代码变量名，因此我们推荐是用星号来包裹斜体内容。如果要显示星号，则使用转义： 1\* 插入图片我们可以通过拖拉的方式，将本地文件夹中的图片或者网络上的图片插入。 ​ ​ 插入URL连接使用尖括号包裹的url将产生一个连接，例如：&lt;www.baidu.com&gt;将产生连接:. 如果是标准的url，则会自动产生连接，例如:www.google.com 目录列表Table of Contents（TOC）输入[toc]然后回车，将会产生一个目录，这个目录抽取了文章的所有标题，自动更新内容。 水平分割线使用***或者---，然后回车，来产生水平分割线。 标注我们可以对某一个词语进行标注。例如 12某些人用过了才知道[^注释][^注释]:Somebody that I used to know. 将产生： 某些人用过了才知道注释注释: Somebody that I used to know. 把鼠标放在注释上，将会有提示内容。 表格12345|姓名|性别|毕业学校|工资||:---|:---:|:---:|---:||杨洋|男|重庆交通大学|3200||峰哥|男|贵州大学|5000||坑货|女|北京大学|2000| 将产生: 姓名 性别 毕业学校 工资 杨洋 男 重庆交通大学 3200 峰哥 男 贵州大学 5000 坑货 女 北京大学 2000 其中代码的第二行指定对齐的方式，第一个是左对齐，第二个和第三个是居中，最后一个是右对齐。 数学表达式块输入两个美元符号，然后回车，就可以输入数学表达式块了。例如： 1$$\mathbf&#123;V&#125;_1 \times \mathbf&#123;V&#125;_2 = \begin&#123;vmatrix&#125; \mathbf&#123;i&#125; &amp; \mathbf&#123;j&#125; &amp; \mathbf&#123;k&#125; \\\frac&#123;\partial X&#125;&#123;\partial u&#125; &amp; \frac&#123;\partial Y&#125;&#123;\partial u&#125; &amp; 0 \\\frac&#123;\partial X&#125;&#123;\partial v&#125; &amp; \frac&#123;\partial Y&#125;&#123;\partial v&#125; &amp; 0 \\\end&#123;vmatrix&#125;$$ 将会产生: \mathbf{V}_1 \times \mathbf{V}_2 = \begin{vmatrix} \mathbf{i} & \mathbf{j} & \mathbf{k} \\\frac{\partial X}{\partial u} & \frac{\partial Y}{\partial u} & 0 \\\frac{\partial X}{\partial v} & \frac{\partial Y}{\partial v} & 0 \\\end{vmatrix}任务列表使用如下的代码创建任务列表，在[]中输入x表示完成，也可以通过点击选择完成或者没完成。 1234- [ ] 吃饭- [ ] 逛街- [ ] 看电影- [ ] 约泡 [x] 吃饭 ​ [x] 逛街 ​ [x] 看电影 ​ [x] 约泡 列表输入+, -, *,创建无序的列表，使用任意数字开头，创建有序列表，例如： 1234**无序的列表*** tfboys* 杨洋* 我爱你 无序的列表 tfboys 杨洋 我爱你 1234**有序的列表**1. 苹果6. 香蕉10. 我都不喜欢 有序的列表 苹果 香蕉 我都不喜欢 块引用使用&gt;来插入块引用。例如： 1&gt;这是一个块引用！ 将产生： 这是一个块引用！ 标题使用#表示一级标题，##表示二级标题，以此类推，有6个标题。]]></content>
      <categories>
        <category>markdown</category>
      </categories>
      <tags>
        <tag>markdown</tag>
        <tag>语法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello]]></title>
    <url>%2F2018%2F08%2F22%2FHello%2F</url>
    <content type="text"><![CDATA[大学已然过三年，也浑浑噩噩过了三年。一时兴起，想搞一个属于自己的博客，把未来生活与学习路上的点点滴滴记录下来，万事开头难，于是偷个懒，就把建这个网站的过程来作为我的第一篇博客吧，记录一下，哈哈哈哈哈 安装安装git、node.js新建一个储存博客的文件夹(blogblog)打开后右键-选择-Git Bash Here输入12npm install hexo -g hexo init -g表示全局安装, npm默认为当前项目安装 node_modules：是依赖包 public：存放的是生成的页面 source：用命令创建的各种文章 themes：主题 _config.yml：整个博客的配置 db.json：source解析所得到的 package.json：项目所需模块项目的配置信息 输入123hexo cleanhexo generatehexo server 游览器打开 http://localhost:4000 但是只能在本地登录，下一步便是可以从其他地点登录 搭桥到github 选择New repository/myname.github.iomyname 必须为github的账号名 输入 12git config --global user.name &quot;my name&quot;git config --global user.email &quot;my email&quot; 创建SSH输入 ssh-keygen -t rsa -C &quot;myemail@example.com&quot; 再按两次回车输入 cd ~/.ssh 再输入 cat id_rsa.pub会输出 12ssh-rsa xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxmyemail@example.com 把ssh-rsa xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx输入到key位置输入ssh -T git@github.com 可验证时候正确 打开在blogblog目录下的_config.yml 注意冒号后有一个空格 1234deploy: type: git repo: https://github.com/mygithubName/mygithubName.github.io.git branch: master 注意：如果同一个电脑建第二个hexo需要如下： 1234deploy: type: git repo: git@github.com:mygithubName/mygithubName.github.io.git branch: master 在blogblog目录中打开 gitbash执行npm i hexo-server再执行npm install hexo-deployer-git --save执行 123hexo cleanhexo generatehexo deploy 打开 myname.github.io 就可以看到了~ 绑定域名 买一个域名，我是在阿里云买的 在项目的source文件夹中新建一个名为CNAME的文件(不需要文件后缀)，编辑文档时把所购 买的域名添加其中，注意，只可添加一个 在DNS中添加一条记录，也可以直接通过新手引导设置，其中所需的地址只需在cmd中执行 ping myname.github.io 再执行一次 123hexo cleanhexo generatehexo deploy 更换主题可以访问hexo的主题官网，我选择的是NexT主题，一来好看实用；二来很多功能都已经写好，添加功能时会更方便一些(渣渣没办法…)，因此以下为安装NexT主题为例。 执行$ git clone https://github.com/theme-next/hexo-theme-next-themes/next 打开blogblog目录的_config.yml ,其中，修改为 theme: next emmmmm…. 没错 主题就换完了，打开试试，突然就高大上了~ 修改blogblog下_config.yml的:1234567title: 清 泉subtitle:description:keywords:author: springlanguage: zh-CNtimezone: 修改blogblog/themes/next/_config.yml: 123456789menu: home: / || home #about: /about/ || user #tags: /tags/ || tags #categories: /categories/ || th archives: /archives/ || archive #schedule: /schedule/ || calendar #sitemap: /sitemap.xml || sitemap #commonweal: /404/ || heartbeat 我习惯修改为 123456789menu: home: / || home #about: /about/ || user tags: /tags/ || tags categories: /categories/ || th archives: /archives/ || archive #schedule: /schedule/ || calendar #sitemap: /sitemap.xml || sitemap #commonweal: /404/ || heartbeat 想要选择哪个把前面的#去掉即可 对于tags项： 执行hexo new page &quot;tags&quot;打开\source\tags\index.md 123456---title:date: 2018-08-21 14:56:51type: &quot;tags&quot;comments: false--- 对于categories项： 执行hexo new page &quot;categories&quot; 打开\source\categories\index.md 123456--- title: date: 2018-08-21 14:57:23 type: &quot;categories&quot; comments: false --- Next主题 又分为四种形式，可自选： 12345# Schemesscheme: Muse#scheme: Mist#scheme: Pisces#scheme: Gemini 头像12345678avatar: url: #/images/avatar.gif 你的头像图片的路径 # If true, the avatar would be dispalyed in circle. rounded: false # The value of opacity should be choose from 0 to 1 to set the opacity of the avatar. opacity: 1 # If true, the avatar would be rotated with the cursor. rotated: false 删除底部隐藏由Hexo强力驱动、主题—NexT.Mist 打开blogblog/themes/next/layout/_partials/footer.swig，注释掉相应代码 1234567891011121314151617181920212223242526//用下面的符号注释，注释代码用下面括号括起来 &lt;!-- --&gt; &lt;!-- &lt;span class=&quot;post-meta-divider&quot;&gt;|&lt;/span&gt; &#123;% if theme.footer.powered %&#125; &lt;div class=&quot;powered-by&quot;&gt;&#123;# #&#125;&#123;&#123; __(&apos;footer.powered&apos;, &apos;&lt;a class=&quot;theme-link&quot; target=&quot;_blank&quot; href=&quot;https://hexo.io&quot;&gt;Hexo&lt;/a&gt;&apos;) &#125;&#125;&#123;##&#125;&lt;/div&gt;&#123;% endif %&#125;&#123;% if theme.footer.powered and theme.footer.theme.enable %&#125; &lt;span class=&quot;post-meta-divider&quot;&gt;|&lt;/span&gt;&#123;% endif %&#125;&#123;% if theme.footer.theme.enable %&#125; &lt;div class=&quot;theme-info&quot;&gt;&#123;# #&#125;&#123;&#123; __(&apos;footer.theme&apos;) &#125;&#125; &amp;mdash; &#123;# #&#125;&lt;a class=&quot;theme-link&quot; target=&quot;_blank&quot; href=&quot;https://github.com/iissnan/hexo-theme-next&quot;&gt;&#123;# #&#125;NexT.&#123;&#123; theme.scheme &#125;&#125;&#123;# #&#125;&lt;/a&gt;&#123;% if theme.footer.theme.version %&#125; v&#123;&#123; theme.version &#125;&#125;&#123;% endif %&#125;&#123;##&#125;&lt;/div&gt; &#123;% endif %&#125; &#123;% if theme.footer.custom_text %&#125; &lt;div class=&quot;footer-custom&quot;&gt;&#123;# #&#125;&#123;&#123; theme.footer.custom_text &#125;&#125;&#123;##&#125;&lt;/div&gt;&#123;% endif %&#125;--&gt; 背景动态 canvas_nest git clone https://github.com/theme-next/theme-next-canvas-nest source/lib/canvas-nest 把&lt;script type=&quot;text/javascript&quot; src=&quot;//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js&quot;&gt;&lt;/script&gt; 插入至\blogblog\themes\next\layout\_layout.swig如下： 1234567891011&lt;html&gt;&lt;head&gt; ...&lt;/head&gt;&lt;body&gt; ... ... ... 插入到这里&lt;/body&gt;&lt;/html&gt; 再修改主题配置文件 打开/next/_config.yml,修改如下： 123# Canvas-nest# Dependencies: https://github.com/theme-next/theme-next-canvas-nestcanvas_nest: true 添加DaoVoice在线联系 首先到DaoVoice注册账号，邀请码是0f81ff2f ，登录成过后，进入到后台管理，点击应用设置——&gt;安装到网站查看安装代码和AppID。 找到app_id ，在主题配置文件中找到(没有的话添加) 123# Online contact daovoice: truedaovoice_app_id: 这里填你的刚才获得的 app_id 打开/themes/next/layout/_partials/head.swig ,代码放进去，哪行都可以 123456789&#123;% if theme.daovoice %&#125; &lt;script&gt; (function(i,s,o,g,r,a,m)&#123;i[&quot;DaoVoiceObject&quot;]=r;i[r]=i[r]||function()&#123;(i[r].q=i[r].q||[]).push(arguments)&#125;,i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;a.charset=&quot;utf-8&quot;;m.parentNode.insertBefore(a,m)&#125;)(window,document,&quot;script&quot;,(&apos;https:&apos; == document.location.protocol ? &apos;https:&apos; : &apos;http:&apos;) + &quot;//widget.daovoice.io/widget/0f81ff2f.js&quot;,&quot;daovoice&quot;) daovoice(&apos;init&apos;, &#123; app_id: &quot;&#123;&#123;theme.daovoice_app_id&#125;&#125;&quot; &#125;); daovoice(&apos;update&apos;); &lt;/script&gt;&#123;% endif %&#125; 在DaoVoice中找到聊天设置调节窗口的颜色以及位置我的参数：右侧像素20.0，下侧像素：80.0 在右上角或者左上角实现fork me on github 点击这里 或者 这里挑选自己喜欢的样式，并复制代码。 然后粘贴刚才复制的代码到themes/next/layout/_layout.swig文件中(放在&lt;div class=&quot;headband&quot;&gt;&lt;/div&gt;的下面)，并把href改为你的github地址 。 添加RSS 在blogblog中打开githash 执行 npm install --save hexo-generator-feed 在blogblog/_config.yml中添加 123# Extensions## Plugins: http://hexo.io/plugins/plugins: hexo-generate-feed 在主题配置文件中修改为： 1234# Set rss to false to disable feed link.# Leave rss as empty to use site&apos;s feed link.# Set rss to specific value if you have burned your feed already.rss: /atom.xml 添加音乐 在博客配置文件中执行npm install hexo-tag-aplayer@2.0.1 新建themes\next\source\dist\music.js ,添加内容： 12345678910111213141516171819202122232425const ap = new APlayer(&#123; container: document.getElementById(&apos;aplayer&apos;), fixed: true, autoplay: false, audio: [ &#123; name: &quot;Dream It Possible&quot;, artist: &apos;Delacey&apos;, url: &apos;http://www.ytmp3.cn/down/47868.mp3&apos;, cover: &apos;http://oeff2vktt.bkt.clouddn.com/image/84.jpg&apos;, &#125;, &#123; name: &apos;いとしすぎて&apos;, artist: &apos;KG&apos;, url: &apos;http://www.ytmp3.cn/down/35726.mp3&apos;, cover: &apos;http://oeff2vktt.bkt.clouddn.com/image/8.jpg&apos;, &#125;, &#123; name: &apos;茜さす&apos;, artist: &apos;Aimer&apos;, url: &apos;http://www.ytmp3.cn/down/44578.mp3&apos;, cover: &apos;http://oeff2vktt.bkt.clouddn.com/image/96.jpg&apos;, &#125; ]&#125;); 修改网站主题字体大小在主题配置文件中123456789101112131415161718192021222324252627282930313233font: enable: true # Uri of fonts host. E.g. //fonts.googleapis.com (Default) # 亲测这个可用，如果不可用，自己搜索 [Google 字体 国内镜像]，找个能用的就行 host: https://fonts.cat.net # Global font settings used on &lt;body&gt; element. # 全局字体，应用在 body 元素上 global: external: true family: Lato size: 16 #csdn上就是16看着舒服多了 # 标题字体 (h1, h2, h3, h4, h5, h6) headings: external: true family: Roboto Slab # 文章字体 posts: external: true family: # Logo 字体 logo: external: true family: Lobster Two size: 24 # 代码字体，应用于 code 以及代码块 codes: external: true family: Roboto Mono 站点收录百度收录在主题配置文件中修改成： 1baidu_site_verification: true 进入百度站点检验网站 ，选择http:// ,purespring.top 信息技术 由于前两个验证一直通过不了，所以我选择了CNAME验证 进入阿里云 我是在阿里云买的域名，所以进入那里。 进入解析设置 添加记录 类型： CNAME 主机记录： xxxxx.purespring.top(这个会告诉你) 记录值：zz.baidu(这个会告诉你) 就可以完成确认 更改细节主题在文件\themes\next\source\css\_custom\custom.styl中，放入如下代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600// Custom styles//首页头部样式.header &#123; background: url("/images/header-bk.jpg");&#125;.site-meta &#123; margin-left: 0px; text-align: center;&#125;.site-meta .site-title &#123; font-size: 20px; font-family: 'Comic Sans MS', sans-serif; color: #fff; letter-spacing: 1px; width: 81%;&#125;// 点文章进去的页面背景色.container &#123; background-color: rgba(255, 255, 255, 0.747);&#125;// 页面留白更改.header-inner &#123; padding-top: 0px; padding-bottom: 0px;&#125;.posts-expand &#123; padding-top: 80px;&#125;.posts-expand .post-meta &#123; margin: 5px 0px 0px 0px;&#125;.post-button &#123; margin-top: 0px;&#125;// 顶栏宽度.container .header-inner &#123; width: 100%;&#125;// 站点名背景.brand&#123; background-color: rgb(56, 53, 53); margin-top: 15px; padding: 0px;&#125;// 站点名字体.site-title &#123; line-height: 35px; letter-spacing: 3px;&#125;// 站点子标题.site-subtitle&#123; margin: 0px; font-size: 16px; letter-spacing: 1px; padding-bottom: 3px; font-weight: bold; color: rgb(219, 95, 95); border-bottom-width: 3px; border-bottom-style: solid; border-bottom-color: rgb(161, 102, 171);&#125;.logo-line-after &#123; display: none;&#125;.logo-line-before &#123; display: none;&#125;// 菜单.menu &#123; float: none;&#125;// 菜单超链接字体大小.menu .menu-item a &#123; font-size: 14px; color: rgb(15, 46, 65); border-radius: 4px;&#125;// 菜单各项边距.menu .menu-item &#123; margin: 5px 15px;&#125;// 菜单超链接样式.menu .menu-item a:hover &#123; border-bottom-color: rgba(161, 102, 171, 0);&#125;// 文章.post &#123; margin-bottom: 50px; padding: 45px 36px 36px 36px; box-shadow: 0px 0px 10px 0px rgba(0, 0, 0, 0.5); background-color: rgb(255, 255, 255);&#125;// 文章标题字体.posts-expand .post-title &#123; font-size: 26px; font-weight: 700;&#125;// 文章标题动态效果.posts-expand .post-title-link::before &#123; background-image: linear-gradient(90deg, #a166ab 0%, #ef4e7b 25%, #f37055 50%, #ef4e7b 75%, #a166ab 100%);&#125;// 文章元数据（meta）留白更改.posts-expand .post-meta &#123; margin: 10px 0px 20px 0px;&#125;// 文章的描述description.posts-expand .post-meta .post-description &#123; font-style: italic; font-size: 14px; margin-top: 30px; margin-bottom: 0px; color: #666;&#125;// [Read More]按钮样式.post-button .btn &#123; color: rgba(219, 210, 210, 0.911)!important; background-color: rgba(56, 52, 52, 0.911); border-radius: 3px; font-size: 15px; box-shadow: inset 0px 0px 10px 0px rgba(0, 0, 0, 0.35); border: none !important; transition-property: unset; padding: 0px 15px;&#125;.post-button .btn:hover &#123; color: rgba(219, 210, 210, 0.911) !important; border-radius: 3px; font-size: 15px; box-shadow: inset 0px 0px 10px 0px rgba(0, 0, 0, 0.35); background-image: linear-gradient(100deg, #a166ab 0%, #ef4e7b 25%, #f37055 50%, #ef4e7b 75%, #a166ab 100%);&#125;// 去除在页面文章之间的分割线.posts-expand .post-eof &#123; margin: 0px; background-color: rgba(255, 255, 255, 0);&#125;// 去除页面底部页码上面的横线.pagination &#123; border: none; margin: 0px;&#125;// 页面底部页码.pagination .page-number.current &#123; border-radius: 100%; box-shadow: 0px 0px 10px 0px rgba(0, 0, 0, 0.5); background-color: rgba(255, 255, 255, 0.35);&#125;.pagination .prev, .pagination .next, .pagination .page-number &#123; margin-bottom: 10px; border: none;&#125;.pagination .space &#123; color: rgb(255, 255, 255);&#125;// 页面底部页脚.footer &#123; line-height: 1.5; background-color: rgba(255, 255, 255, 0.75); color: #333; border-top-width: 3px; border-top-style: solid; border-top-color: rgb(161, 102, 171); box-shadow: 0px -10px 10px 0px rgba(0, 0, 0, 0.15);&#125;// 文章底部的tags.posts-expand .post-tags a &#123; border-bottom: none; margin-right: 0px; font-size: 13px; padding: 0px 5px; border-radius: 3px; transition-duration: 0.2s; transition-timing-function: ease-in-out; transition-delay: 0s;&#125;.posts-expand .post-tags a:hover &#123; background: #eee;&#125;// 文章底部留白更改.post-widgets &#123; padding-top: 0px;&#125;.post-nav &#123; margin-top: 30px;&#125;// 文章底部页面跳转.post-nav-item a &#123; color: rgb(80, 115, 184); font-weight: bold;&#125;.post-nav-item a:hover &#123; color: rgb(161, 102, 171); font-weight: bold;&#125;// 文章底部评论.comments &#123; background-color: rgb(255, 255, 255); box-shadow: 0px 0px 10px 0px rgba(0, 0, 0, 0.35); margin: 80px 0px 40px 0px;&#125;// 超链接样式a &#123; color: rgb(80, 115, 184); border-bottom-color: rgb(80, 115, 184);&#125;a:hover &#123; color: rgb(161, 102, 171); border-bottom-color: rgb(161, 102, 171);&#125;// 分割线样式hr &#123; margin: 10px 0px 30px 0px;&#125;// 文章内标题样式（左边的竖线）.post-body h2, h3, h4, h5, h6 &#123; border-left: 4px solid rgb(161, 102, 171); margin-left: -36px; padding-left: 32px;&#125;// 去掉图片边框.posts-expand .post-body img &#123; border: none; padding: 0px;&#125;.post-gallery .post-gallery-img img &#123; padding: 3px;&#125;// 文章``代码块的自定义样式code &#123; margin: 0px 4px;&#125;// 文章```代码块顶部样式.highlight figcaption &#123; margin: 0em; padding: 0.5em; background: #eee; border-bottom: 1px solid #e9e9e9;&#125;.highlight figcaption a &#123; color: rgb(80, 115, 184);&#125;// 文章```代码块diff样式pre .addition &#123; background: #e6ffed;&#125;pre .deletion &#123; background: #ffeef0;&#125;// 右下角侧栏按钮样式.sidebar-toggle &#123; right: 10px; bottom: 43px; background-color: rgba(247, 149, 51, 0.75); border-radius: 5px; box-shadow: 0px 0px 10px 0px rgba(0, 0, 0, 0.35);&#125;.page-post-detail .sidebar-toggle-line &#123; background: rgb(17, 185, 163);&#125;// 右下角返回顶部按钮样式.back-to-top &#123; line-height: 1.5; right: 10px; padding-right: 5px; padding-left: 5px; padding-top: 2.5px; padding-bottom: 2.5px; background-color: rgba(247, 149, 51, 0.75); border-radius: 5px; box-shadow: 0px 0px 10px 0px rgba(0, 0, 0, 0.35);&#125;.back-to-top.back-to-top-on &#123; bottom: 10px;&#125;// 侧栏.sidebar &#123; box-shadow: inset 0px 0px 10px 0px rgba(0, 0, 0, 0.5); background-color: rgba(0, 0, 0, 0.75);&#125;.sidebar-inner &#123; margin-top: 30px;&#125;// 侧栏顶部文字.sidebar-nav li &#123; font-size: 15px; font-weight: bold; color: rgb(7, 179, 155);&#125;.sidebar-nav li:hover &#123; color: rgb(161, 102, 171);&#125;.sidebar-nav .sidebar-nav-active &#123; color: rgb(7, 179, 155); border-bottom-color: rgb(161, 102, 171); border-bottom-width: 1.5px;&#125;.sidebar-nav .sidebar-nav-active:hover &#123; color: rgb(7, 179, 155);&#125;// 侧栏站点概况行高.site-overview &#123; line-height: 1.3;&#125;// 侧栏头像（圆形以及旋转效果）.site-author-image &#123; border: 2px solid rgb(255, 255, 255); border-radius: 100%; transition: transform 1.0s ease-out;&#125;img:hover &#123; transform: rotateZ(360deg);&#125;.posts-expand .post-body img:hover &#123; transform: initial;&#125;// 侧栏站点作者名.site-author-name &#123; display: none;&#125;// 侧栏站点描述.site-description &#123; letter-spacing: 5px; font-size: 15px; font-weight: bold; margin-top: 15px; margin-left: 13px; color: rgb(243, 112, 85);&#125;// 侧栏站点文章、分类、标签.site-state &#123; line-height: 1.3; margin-left: 12px;&#125;.site-state-item &#123; padding: 0px 15px; border-left: 1.5px solid rgb(161, 102, 171);&#125;// 侧栏RSS按钮样式.feed-link &#123; margin-top: 15px; margin-left: 7px;&#125;.feed-link a &#123; color: rgb(255, 255, 255); border: 1px solid rgb(158, 158, 158) !important; border-radius: 15px;&#125;.feed-link a:hover &#123; background-color: rgb(161, 102, 171);&#125;.feed-link a i &#123; color: rgb(255, 255, 255);&#125;// 侧栏社交链接.links-of-author &#123; margin-top: 0px;&#125;// 侧栏友链标题.links-of-blogroll-title &#123; margin-bottom: 10px; margin-top: 15px; color: rgba(7, 179, 156, 0.74); margin-left: 6px; font-size: 15px; font-weight: bold;&#125;// 侧栏超链接样式（友链的样式）.sidebar a &#123; color: #ccc; border-bottom: none;&#125;.sidebar a:hover &#123; color: rgb(255, 255, 255);&#125;// 自定义的侧栏时间样式#days &#123; display: block; color: rgb(7, 179, 155); font-size: 13px; margin-top: 15px;&#125;// 侧栏目录链接样式.post-toc ol a &#123; color: rgb(75, 240, 215); border-bottom: 1px solid rgb(96, 125, 139);&#125;.post-toc ol a:hover &#123; color: rgb(161, 102, 171); border-bottom-color: rgb(161, 102, 171);&#125;// 侧栏目录链接样式之当前目录.post-toc .nav .active &gt; a &#123; color: rgb(161, 102, 171); border-bottom-color: rgb(161, 102, 171);&#125;.post-toc .nav .active &gt; a:hover &#123; color: rgb(161, 102, 171); border-bottom-color: rgb(161, 102, 171);&#125;/* 修侧栏目录bug，如果主题配置文件_config.yml的toc是wrap: true */.post-toc ol &#123; padding: 0px 10px 5px 10px;&#125;/* 侧栏目录默认全展开，已注释.post-toc .nav .nav-child &#123; display: block;&#125;*/// 时间轴样式.posts-collapse &#123; margin: 50px 0px;&#125;@media (max-width: 1023px) &#123; .posts-collapse &#123; margin: 50px 20px; &#125;&#125;// 时间轴左边线条.posts-collapse::after &#123; margin-left: -2px; background-image: linear-gradient(180deg,#f79533 0,#f37055 15%,#ef4e7b 30%,#a166ab 44%,#5073b8 58%,#1098ad 72%,#07b39b 86%,#6dba82 100%);&#125;// 时间轴左边线条圆点颜色.posts-collapse .collection-title::before &#123; background-color: rgb(255, 255, 255);&#125;// 时间轴文章标题左边圆点颜色.posts-collapse .post-header:hover::before &#123; background-color: rgb(161, 102, 171);&#125;// 时间轴年份.posts-collapse .collection-title h1, .posts-collapse .collection-title h2 &#123; color: rgb(255, 255, 255);&#125;// 时间轴文章标题.posts-collapse .post-title a &#123; color: rgb(80, 115, 184);&#125;.posts-collapse .post-title a:hover &#123; color: rgb(161, 102, 171);&#125;// 时间轴文章标题底部虚线.posts-collapse .post-header:hover &#123; border-bottom-color: rgb(161, 102, 171);&#125;// archives页面顶部文字.page-archive .archive-page-counter &#123; color: rgb(255, 255, 255);&#125;// archives页面时间轴左边线条第一个圆点颜色.page-archive .posts-collapse .archive-move-on &#123; top: 10px; opacity: 1; background-color: rgb(255, 255, 255); box-shadow: 0px 0px 10px 0px rgba(0, 0, 0, 0.5);&#125;// 分类页面.post-block.page &#123; margin-top: 40px;&#125;.category-all-page &#123; margin: -80px 50px 40px 50px; box-shadow: 0px 0px 10px 0px rgba(0, 0, 0, 0.5); background-color: rgb(255, 255, 255); padding: 86px 36px 36px 36px;&#125;@media (max-width: 767px) &#123; .category-all-page &#123; margin: -73px 15px 50px 15px; &#125; .category-all-page .category-all-title &#123; margin-top: -5px; &#125;&#125;// 标签云页面.tag-cloud &#123; margin: -80px 50px 40px 50px; box-shadow: 0px 0px 10px 0px rgba(0, 0, 0, 0.5); background-color: rgb(255, 255, 255); padding: 86px 36px 36px 36px;&#125;.tag-cloud-title &#123; margin-bottom: 15px;&#125;@media (max-width: 767px) &#123; .tag-cloud &#123; margin: -73px 15px 50px 15px; padding: 86px 5px 36px 5px; &#125;&#125;// 自定义的TopX页面样式#top &#123; display: block; text-align: center; margin: -100px 50px 40px 50px; box-shadow: 0px 0px 10px 0px rgba(0, 0, 0, 0.5); background-color: rgb(255, 255, 255); padding: 106px 36px 10px 36px;&#125;@media (max-width: 767px) &#123; #top &#123; margin: -93px 15px 50px 15px; padding: 96px 10px 0px 10px; &#125;&#125;// 自定义ABOUT页面的样式.about-page &#123; margin: -80px 0px 60px 0px; box-shadow: 0px 0px 10px 0px rgba(0, 0, 0, 0.5); background-color: rgb(255, 255, 255); padding: 106px 36px 36px 36px;&#125;@media (max-width: 767px) &#123; .about-page &#123; margin: -73px 0px 50px 0px; padding: 96px 15px 20px 15px; &#125;&#125;h2.about-title &#123; border-left: none !important; margin-left: 0px !important; padding-left: 0px !important; text-align: center; background-image: linear-gradient(90deg, #a166ab 0%, #a166ab 40%, #ef4e7b 45%, #f37055 50%, #ef4e7b 55%, #a166ab 60%, #a166ab 100%); background-size: cover; -webkit-background-clip: text; -webkit-text-fill-color: transparent; user-select: none;&#125;// 本地搜索框.local-search-popup .search-icon, .local-search-popup .popup-btn-close &#123; color: rgb(247, 149, 51); margin-top: 7px;&#125;.local-search-popup .local-search-input-wrapper input &#123; padding: 9px 0px; height: 21px; background-color: rgb(255, 255, 255);&#125;.local-search-popup .popup-btn-close &#123; border-left: none;&#125;// 选中文字部分的样式::selection &#123; background-color: rgb(255, 241, 89); color: #555;&#125;/* 设置滚动条的样式 *//* 参考https://segmentfault.com/a/1190000003708894 */::-webkit-scrollbar &#123; height: 5px;&#125;/* 滚动槽 */::-webkit-scrollbar-track &#123; background: #eee;&#125;/* 滚动条滑块 */::-webkit-scrollbar-thumb &#123; border-radius: 5px; background-color: #ccc;&#125;::-webkit-scrollbar-thumb:hover &#123; background-color: rgb(247, 149, 51);&#125;// 音乐播放器aplayer.aplayer &#123; font-family: Lato, -apple-system, BlinkMacSystemFont, "PingFang SC", "Hiragino Sans GB", "Heiti SC", STHeiti, "Source Han Sans SC", "Noto Sans CJK SC", "WenQuanYi Micro Hei", "Droid Sans Fallback", "Microsoft YaHei", sans-serif !important;&#125;.aplayer-withlrc.aplayer .aplayer-info &#123; background-color: rgb(255, 255, 255);&#125;// 音乐播放器aplayer歌单.aplayer .aplayer-list ol &#123; background-color: rgb(255, 255, 255);&#125;// 修视频播放器dplayer页面全屏的bug.use-motion .post-body &#123; transform: inherit !important;&#125;// 自定义emoji样式img#github-emoji &#123; margin: 0px; padding: 0px; display: inline !important; vertical-align: text-bottom; border: none; cursor: text; box-shadow: none;&#125;.site-meta .brand &#123; width: 10%;&#125;// 页面最顶部的横线.headband &#123; height: 1.5px; background-image: linear-gradient(90deg, #F79533 0%, #F37055 15%, #EF4E7B 30%, #A166AB 44%, #5073B8 58%, #1098AD 72%, #07B39B 86%, #6DBA82 100%);&#125; 打开网站缓冲条式特效打开\themes\next\layout\_partials\head\head.swig文件 在下面增加如下代码 123456789101112131415161718&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1, maximum-scale=1&quot;/&gt;&lt;!-- S 新增代码 --&gt;&lt;script src=&quot;//cdn.bootcss.com/pace/1.0.2/pace.min.js&quot;&gt;&lt;/script&gt;&lt;link href=&quot;//cdn.bootcss.com/pace/1.0.2/themes/pink/pace-theme-flash.css&quot; rel=&quot;stylesheet&quot;&gt;&lt;style&gt; .pace .pace-progress &#123; background: #24292e; /*进度条颜色*/ height: 3px; &#125; .pace .pace-progress-inner &#123; box-shadow: 0 0 10px #1E92FB, 0 0 5px #1E92FB; /*阴影颜色*/ &#125; .pace .pace-activity &#123; border-top-color: #1E92FB; /*上边框颜色*/ border-left-color: #1E92FB; /*左边框颜色*/ &#125;&lt;/style&gt;&lt;!-- E 新增代码 --&gt; 至此，网站已基本配置完成。]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>教程</tag>
      </tags>
  </entry>
</search>
