---
title: MOEA/D算法(0)
date: 2018-12-30 07:17:02
categories: MOEA
tags: 
- MOEA
- MOEA\D
mathjax: true
description:
---

最近在复现“MOEA/D: A Multiobjective Evolutionary Algorithm Based on Decomposition”这篇论文这是一个后补上的文章，几乎是翻译的原论文呢】，因为课程设计凑字数，也为了省事，就干脆发在我的小博客上了。

<!--more-->

多目标优化问题可以表示如下：
$$
maximize \quad F(x)=(f_1(x),...,f_m(x))^T
\\subject \ to \ x \in \Omega
$$
其中，$\Omega$是决策空间，$F$：$\Omega \rightarrow  R^m$是m个实数目标函数，$R^m$叫做目标空间，可实现的目标定义如下：
$$
\Omega=\{x \in R^n|h_j(x)\leq 0,j=1,...,m\}
$$
$h_j$是连续的函数，因此，我们也称$F(x)$是连续的MOP问题。

在现实生活中，大多数的目标函数却是相互矛盾的，并不存在$\Omega$可以同时放大所有的目标值。因此需要找相应的方法去平衡这些目标。目标之间的最佳权衡可以用帕累托(Pareto)最优性来定义。

定义$u,v\in R^m$,如果对于$\forall i \in \{1,...,m\}$，使得$u_i\geq v_i$，并且$\exists j \in \{1,...,m\} $，使得$u_i > v_i$，则称$u$支配$v$。如果存在这种点$x^*\in \Omega$，不存在点$x$，使$F(x)$支配$F(x^*)$，那么称$F(x^*）$为帕累托最优目标向量。换言之，一个目标中帕累托最优点的任何改进都必须导致至少另一个目标的恶化。所有帕累托最优点的集合称为帕累托集合(PS)，所有帕累托最优目标向量的集合称为帕累托阵(PF)。

在多目标优化的许多实际应用中，决策者需要近似于PF来选择最终的首选解决方案。大多数MOPs可能有许多甚至无限帕累托最优向量。获取完整的PF是非常耗时的。另一方面，由于信息的溢出，决策者可能对拥有过多的帕累托最优向量不感兴趣。因此，许多多目标优化算法都是为了找到一个可管理的帕累托最优向量。一些研究者也尝试用数学模型来近似PF。

目前没有涉及到分解的大部分多目标进化算法，将MOP视为一个整体。它们不会将每个单独的解决方案与任何特定的标量优化问题关联起来。在标量目标优化问题，所有的解决方案都可以在它们目标函数值的基础上进行比较，标量目标的任务进化算法(EA)往往是寻找一个单一的最优的解决方案。然而，在MOPs中，支配并非定义目标函数中解的完整顺序空间，MOEAs旨在产生一些帕累托最优尽可能多样化的解决方案来代表整体PF。

因此，最初设计用于标量优化的传统选择算子不能直接用于非分解MOEAs。那么可以说，如果有一种适合度分配方案，用于为单个解决方案分配一个相对适合度值，以反映其选择的实用价值，那么标量优化EAs可以很容易地扩展到处理MOPs。因此，适应度分配一直是当前的一个主要问题MOEA研究。目前流行的适应度分配策略包括基于交互目标的适应度分配，如向量评价遗传算法(VEGA);基于优势的适应度分配，如帕累托存档进化策略（PAES）。

分解的思想在一些针对MOPs的元启发式中得到了一定程度的应用。例如，两阶段局部搜索(TPLS)考虑了一组标量优化问题，其中目标是所考虑的MOP中的目标的集合，基于集合系数的序列将标量优化算法应用于这些标量优化问题中，将前一个问题得到的解作为下一个问题求解的起点，因为它的集合目标与前一个问题的集合目标略有不同。多目标遗传局部搜索(MOGLS)旨在同时优化加权和方法或Tchebycheff方法构建的所有聚合。在每次迭代中，它优化随机生成的聚合目标。















