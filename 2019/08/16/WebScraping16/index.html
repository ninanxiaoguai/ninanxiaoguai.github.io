<!DOCTYPE html>












  


<html class="theme-next muse use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">



<!-- S 新增代码 -->
<script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
<link href="//cdn.bootcss.com/pace/1.0.2/themes/pink/pace-theme-flash.css" rel="stylesheet">
<style>
    .pace .pace-progress {
        background: #24292e; /*进度条颜色*/
        height: 3px;
    }
    .pace .pace-progress-inner {
         box-shadow: 0 0 10px #1E92FB, 0 0 5px     #1E92FB; /*阴影颜色*/
    }
    .pace .pace-activity {
        border-top-color: #1E92FB;    /*上边框颜色*/
        border-left-color: #1E92FB;    /*左边框颜色*/
    }
</style>
<!-- E 新增代码 -->





 <script>(function(i,s,o,g,r,a,m){i["DaoVoiceObject"]=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;a.charset="utf-8";m.parentNode.insertBefore(a,m)})(window,document,"script",('https:' == document.location.protocol ? 'https:' : 'http:') + "//widget.daovoice.io/widget/37874f6b.js","daovoice")
 
daovoice('init', {
      app_id: "5052a9e6"
    });
  daovoice('update');
  
  </script>



  <meta name="baidu-site-verification" content="Ji5duS2dR8">
















<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">



  <meta name="google-site-verification" content="true">













  <meta name="baidu-site-verification" content="true">










  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=6.3.0" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.3.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/logoo32.png?v=6.3.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/logoo16.png?v=6.3.0">


  <link rel="mask-icon" href="/images/logo.svg?v=6.3.0" color="#222">









<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '6.3.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  







  <meta name="description" content="网络爬行速度很快。至少，它通常比雇佣一打实习生手工从互联网上复制数据快得多!当然，技术的进步和享乐跑步机要求在某一时刻，即使是这样也“不够快”。“这就是人们开始关注分布式计算的时候。">
<meta name="keywords" content="Web-Scraping,python">
<meta property="og:type" content="article">
<meta property="og:title" content="WebScraping-16">
<meta property="og:url" content="https://purespring.top/2019/08/16/WebScraping16/index.html">
<meta property="og:site_name" content="清 泉">
<meta property="og:description" content="网络爬行速度很快。至少，它通常比雇佣一打实习生手工从互联网上复制数据快得多!当然，技术的进步和享乐跑步机要求在某一时刻，即使是这样也“不够快”。“这就是人们开始关注分布式计算的时候。">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://purespring.top/2019/08/16/WebScraping16/1.png">
<meta property="og:updated_time" content="2019-08-16T14:14:08.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="WebScraping-16">
<meta name="twitter:description" content="网络爬行速度很快。至少，它通常比雇佣一打实习生手工从互联网上复制数据快得多!当然，技术的进步和享乐跑步机要求在某一时刻，即使是这样也“不够快”。“这就是人们开始关注分布式计算的时候。">
<meta name="twitter:image" content="https://purespring.top/2019/08/16/WebScraping16/1.png">



  <link rel="alternate" href="/atom.xml" title="清 泉" type="application/atom+xml">




  <link rel="canonical" href="https://purespring.top/2019/08/16/WebScraping16/">



<script type="text/javascript" id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>WebScraping-16 | 清 泉</title>
  









  <noscript>
  <style type="text/css">
    .use-motion .motion-element,
    .use-motion .brand,
    .use-motion .menu-item,
    .sidebar-inner,
    .use-motion .post-block,
    .use-motion .pagination,
    .use-motion .comments,
    .use-motion .post-header,
    .use-motion .post-body,
    .use-motion .collection-title { opacity: initial; }

    .use-motion .logo,
    .use-motion .site-title,
    .use-motion .site-subtitle {
      opacity: initial;
      top: initial;
    }

    .use-motion {
      .logo-line-before i { left: initial; }
      .logo-line-after i { right: initial; }
    }
  </style>
</noscript>

</head>


<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>


<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-CN">


  
  <link rel="stylesheet" href="/dist/APlayer.min.css">
<div id="aplayer"></div>
<script type="text/javascript" src="/dist/APlayer.min.js"></script>
<script type="text/javascript" src="/dist/music.js"></script>





  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>




<a href="https://github.com/ninanxiaoguai" class="github-corner" aria-label="View source on Github"><svg width="80" height="80" viewbox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"/><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"/><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"/></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>







    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">清 泉</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">
    <a href="/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">
    <a href="/tags/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">
    <a href="/categories/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">
    <a href="/archives/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>
  </li>

      
      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>搜索</a>
        </li>
      
    </ul>
  

  
    

  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://purespring.top/2019/08/16/WebScraping16/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="spring">
      <meta itemprop="description" content="梦想天空分外蓝~">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="清 泉">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">WebScraping-16
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-08-16 22:05:46 / 修改时间：22:14:08" itemprop="dateCreated datePublished" datetime="2019-08-16T22:05:46+08:00">2019-08-16</time>
            

            
              

              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/Web-Scraping/" itemprop="url" rel="index"><span itemprop="name">Web-Scraping</span></a></span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/08/16/WebScraping16/#comments" itemprop="discussionUrl">
                  <span class="post-meta-item-text">评论数：</span> <span class="post-comments-count valine-comment-count" data-xid="/2019/08/16/WebScraping16/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2019/08/16/WebScraping16/" class="leancloud_visitors" data-flag-title="WebScraping-16">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数：</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">本文字数：</span>
                
                <span title="本文字数">18k</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">16 分钟</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>网络爬行速度很快。至少，它通常比雇佣一打实习生手工从互联网上复制数据快得多!当然，技术的进步和享乐跑步机要求在某一时刻，即使是这样也“不够快”。“这就是人们开始关注分布式计算的时候。</p>
<a id="more"></a>
<p>与大多数其他技术领域不同，web爬行通常不能仅仅通过“在问题上投入更多的周期”来改进。“运行一个进程非常快;运行两个进程的速度不一定是原来的两倍。运行三个进程可能会禁止您访问正在处理所有请求的远程服务器!</p>
<p>然而，在某些情况下，并行web爬行或运行并行线程/进程仍然是有益的:</p>
<ul>
<li>从多个源(多个远程服务器)而不是单个源收集数据</li>
<li>对收集的数据执行长时间/复杂的操作(例如进行图像分析或OCR)，这些操作可以与获取数据并行完成</li>
<li>从为每个查询付费的大型web服务收集数据，或者在使用协议的范围内创建到服务的多个连接</li>
</ul>
<h3 id="Processes-versus-Threads"><a href="#Processes-versus-Threads" class="headerlink" title="Processes versus Threads"></a>Processes versus Threads</h3><p>Python同时支持多处理和多线程。多处理和多线程都实现了相同的最终目标:同时执行两个编程任务，而不是以更传统的线性方式运行程序。</p>
<p>在计算机科学中，在操作系统上运行的每个进程可以有多个线程。每个进程都有自己分配的内存，这意味着多个线程可以访问相同的内存，而多个进程不能而且必须显式地通信信息。<br>使用多线程编程在具有共享内存的单独线程中执行任务通常被认为比多进程编程更容易。但这种便利是有代价的。</p>
<p>Python的全局解释器锁(或GIL)的作用是防止线程同时执行同一行代码。GIL确保所有进程共享的公共内存不会被破坏(例如，内存中的字节一半用一个值写，一半用另一个值写)。这种锁定使编写多线程程序成为可能，并且知道在同一行中您将得到什么，但是它也有可能产生瓶颈。</p>
<h3 id="Multithreaded-Crawling"><a href="#Multithreaded-Crawling" class="headerlink" title="Multithreaded Crawling"></a>Multithreaded Crawling</h3><p>Python 3.x使用<code>_thread</code>模块;不推荐使用<code>thread</code>程模块。</p>
<p>下面的例子说明了如何使用多个线程执行任务:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> _thread</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">print_time</span><span class="params">(threadName, delay, iterations)</span>:</span></span><br><span class="line">	start = int(time.time())</span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,iterations):</span><br><span class="line">		time.sleep(delay)</span><br><span class="line">		seconds_elapsed = str(int(time.time()) - start)</span><br><span class="line">		<span class="keyword">print</span> (<span class="string">"&#123;&#125; &#123;&#125;"</span>.format(seconds_elapsed, threadName))</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">	_thread.start_new_thread(print_time, (<span class="string">'Fizz'</span>, <span class="number">3</span>, <span class="number">33</span>))</span><br><span class="line">	_thread.start_new_thread(print_time, (<span class="string">'Buzz'</span>, <span class="number">5</span>, <span class="number">20</span>))</span><br><span class="line">	_thread.start_new_thread(print_time, (<span class="string">'Counter'</span>, <span class="number">1</span>, <span class="number">100</span>))</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">	<span class="keyword">print</span> (<span class="string">'Error: unable to start thread'</span>)</span><br><span class="line"><span class="keyword">while</span> <span class="number">1</span>:</span><br><span class="line">	<span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<p>这是对经典FizzBuzz编程测试的一个参考，输出有点冗长:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">1 Counter</span><br><span class="line">2 Counter</span><br><span class="line">3 Fizz</span><br><span class="line">3 Counter</span><br><span class="line">4 Counter</span><br><span class="line">5 Buzz</span><br><span class="line">5 Counter</span><br><span class="line">6 Fizz</span><br><span class="line">6 Counter</span><br><span class="line">7 Counter</span><br><span class="line">...</span><br><span class="line">15 Buzz</span><br><span class="line">15 Fizz</span><br><span class="line">15 Counter</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>脚本启动三个线程，一个线程每三秒打印“Fizz”，另一个线程每五秒打印“Buzz”，第三个线程每秒钟打印“Counter”。</p>
<p>启动线程后，主执行线程将执行while 1循环，该循环将保持程序(及其子线程)执行，直到用户按Ctrl-C停止执行。</p>
<p>其中，代码解释：<code>time.time()</code>读取当前时间，<code>time.sleep(1)</code>，延时1s再进行下一行代码，因此，会每隔1s中输出一个数字，依次为<code>1 2 3 4 5</code>，如果将第三行注释掉，因为处理过快，将输出<code>0 0 0 0 0</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">start = int(time.time())</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">5</span>):</span><br><span class="line">    time.sleep(<span class="number">1</span>)</span><br><span class="line">    now = str(int(time.time()) - start)</span><br><span class="line">    print(now)</span><br></pre></td></tr></table></figure>
<p>可以在线程中执行一个有用的任务，而不是打印嘶嘶声和嗡嗡声，例如爬行一个网站:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> urlopen</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> _thread</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">visited = []</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getLinks</span><span class="params">(thread_name, bsObj)</span>:</span></span><br><span class="line">    print(<span class="string">'Getting links in &#123;&#125;'</span>.format(thread_name))</span><br><span class="line">    links = bsObj.find(<span class="string">'div'</span>, &#123;<span class="string">'id'</span>:<span class="string">'bodyContent'</span>&#125;).find_all(<span class="string">'a'</span>, href=re.compile(<span class="string">'^(/wiki/)((?!:).)*$'</span>))</span><br><span class="line">    <span class="keyword">return</span> [link <span class="keyword">for</span> link <span class="keyword">in</span> links <span class="keyword">if</span> link <span class="keyword">not</span> <span class="keyword">in</span> visited]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">scrape_article</span><span class="params">(thread_name, path)</span>:</span></span><br><span class="line">    visited.append(path)</span><br><span class="line">    html = urlopen(<span class="string">'http://en.wikipedia.org&#123;&#125;'</span>.format(path))</span><br><span class="line">    time.sleep(<span class="number">5</span>)</span><br><span class="line">    bsObj = BeautifulSoup(html, <span class="string">'html.parser'</span>)</span><br><span class="line">    title = bsObj.find(<span class="string">'h1'</span>).get_text()</span><br><span class="line">    print(<span class="string">'Scraping &#123;&#125; in thread &#123;&#125;'</span>.format(title, thread_name))</span><br><span class="line">    links = getLinks(thread_name, bsObj)</span><br><span class="line">    <span class="keyword">if</span> len(links) &gt; <span class="number">0</span>:</span><br><span class="line">        newArticle = links[random.randint(<span class="number">0</span>, len(links)<span class="number">-1</span>)].attrs[<span class="string">'href'</span>]</span><br><span class="line">        print(newArticle)</span><br><span class="line">        scrape_article(thread_name, newArticle)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">   _thread.start_new_thread(scrape_article, (<span class="string">'Thread 1'</span>, <span class="string">'/wiki/Kevin_Bacon'</span>,))</span><br><span class="line">   _thread.start_new_thread(scrape_article, (<span class="string">'Thread 2'</span>, <span class="string">'/wiki/Monty_Python'</span>,))</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">   <span class="keyword">print</span> (<span class="string">'Error: unable to start threads'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="number">1</span>:</span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Scraping Monty Python in thread Thread 2</span><br><span class="line">Getting links in Thread 2</span><br><span class="line">/wiki/International_Standard_Name_Identifier</span><br><span class="line">Scraping Kevin Bacon in thread Thread 1</span><br><span class="line">Getting links in Thread 1</span><br><span class="line">/wiki/Critics%27_Choice_Movie_Award_for_Best_Actor</span><br><span class="line">Scraping International Standard Name Identifier in thread Thread 2</span><br><span class="line">Getting links in Thread 2</span><br><span class="line">/wiki/ISO_639-3</span><br><span class="line">Scraping Critics&apos; Choice Movie Award for Best Actor in thread Thread 1</span><br><span class="line">Getting links in Thread 1</span><br><span class="line">/wiki/Darkest_Hour_(film)</span><br><span class="line">Scraping ISO 639-3 in thread Thread 2</span><br><span class="line">Getting links in Thread 2</span><br></pre></td></tr></table></figure>
<p>因为爬行Wikipedia的速度几乎是单线程爬行速度的两倍，所以包含<code>time.sleep(5)</code>这一行可以防止脚本在Wikipedia的服务器上增加太多的负载。实际上，当运行在请求数量不成问题的服务器上时，应该删除这一行。</p>
<p>如果您想稍微重写一下这个代码，以跟踪到目前为止线程已经共同看到的文章，这样就不会有文章被访问两次了，那该怎么办?您可以在多线程环境中使用列表，就像在单线程环境中使用列表一样:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">visited = []</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getLinks</span><span class="params">(thread_name, bsObj)</span>:</span></span><br><span class="line">    print(<span class="string">'Getting links in &#123;&#125;'</span>.format(thread_name))</span><br><span class="line">    links = bsObj.find(<span class="string">'div'</span>, &#123;<span class="string">'id'</span>:<span class="string">'bodyContent'</span>&#125;).find_all(<span class="string">'a'</span>, href=re.compile(<span class="string">'^(/wiki/)((?!:).)*$'</span>))</span><br><span class="line">    <span class="keyword">return</span> [link <span class="keyword">for</span> link <span class="keyword">in</span> links <span class="keyword">if</span> link <span class="keyword">not</span> <span class="keyword">in</span> visited]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">scrape_article</span><span class="params">(thread_name, path)</span>:</span></span><br><span class="line">    visited.append(path)</span><br></pre></td></tr></table></figure>
<p>注意，您正在将路径附加到已访问路径列表中，作为<code>scrape_article</code>采取的第一个操作。这减少了，但并没有完全消除，它将被抓取两次的机会。</p>
<p>如果您运气不好，两个线程可能仍然在同一时刻偶然遇到相同的路径，两个线程都将看到它不在已访问列表中，然后两个线程都将随后将其添加到列表中并同时删除。然而，实际上，由于执行速度和Wikipedia包含的页面数量，这种情况不太可能发生。</p>
<p>这是竞态条件的一个例子。竞态条件调试起来很棘手，即使对于经验丰富的程序员也是如此，因此针对这些潜在的情况评估代码、估计其可能性并预测其影响的严重性是非常重要的。在这种特殊的竞争条件下，爬虫在同一页面上重复运行两次，可能不值得到处写。</p>
<h4 id="Race-Conditions-and-Queues"><a href="#Race-Conditions-and-Queues" class="headerlink" title="Race Conditions and Queues"></a>Race Conditions and Queues</h4><p>虽然您可以使用列表在线程之间进行通信，但是列表并不是专门为线程之间的通信而设计的，滥用列表很容易导致程序执行缓慢，甚至由于竞争条件而导致错误。列表非常适合添加或从列表中读取内容，但不适合在任意点删除项目，特别是从列表的开头删除项目。例如：<code>myList.pop(0)</code>，实际上需要Python重写整个列表，从而降低程序执行速度。</p>
<p>更危险的是，列表还可以方便地意外地在不线程安全的行中编写。例如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">myList[len(myList)<span class="number">-1</span>]</span><br></pre></td></tr></table></figure>
<p>实际上，在多线程环境中可能不会得到列表中的最后一项，或者在另一个操作修改列表之前立即计算<code>len(myList)-1</code>的值时，它甚至可能引发异常。</p>
<p>有人可能会争辩说，前面的语句可以更“python化”地写成<code>myList[-1]</code>，当然，没有人曾经在虚弱的时候意外地编写了非python代码(尤其是Java开发人员回想起他们使用<code>myList[myList.length-1]</code>,长度是1)!但是，即使您的代码无可挑剔，也请考虑其他形式的非线程安全行，包括列表:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">my_list[i] = my_list[i] + <span class="number">1</span></span><br><span class="line">my_list.append(my_list[<span class="number">-1</span>])</span><br></pre></td></tr></table></figure>
<p>这两种情况都可能导致竞态条件，从而导致意想不到的结果。因此，让我们放弃列表，使用非列表变量将消息传递给线程!</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Read the message in from the global list</span></span><br><span class="line">my_message = global_message</span><br><span class="line"><span class="comment"># Write a message back</span></span><br><span class="line">global_message = <span class="string">"I've retrieved the message"</span></span><br><span class="line"><span class="comment"># do something with my_message</span></span><br></pre></td></tr></table></figure>
<p>这似乎很好，直到您意识到您可能无意中覆盖了来自另一个线程的另一条消息，即在第一行和第二行之间的那一瞬间，“我收到了您的消息”。“所以现在您只需要为每个线程构造一系列精心设计的个人消息对象，并使用一些逻辑来确定谁得到了什么……或者您可以使用为此目的构建的队列模块。</p>
<p>队列是类似列表的对象，可以使用先进先出(FIFO)方法或后进先出(LIFO)方法进行操作。队列通过队列接收来自任何线程的消息。<code>put(&#39;My message&#39;)</code>可以将消息传输到调用<code>queue.get()</code>的任何线程。队列的设计目的不是存储静态数据，而是以线程安全的方式传输它。从队列中检索后，它应该只存在于检索它的线程中。因此，它们通常用于委托任务或发送临时通知。</p>
<p>这在web爬行中非常有用。例如，假设您希望将scraper收集的数据持久化到数据库中，并且希望每个线程都能够快速地持久化它的数据。为所有线程提供一个共享连接可能会导致问题(单个连接不能并行处理请求)，但是为每个抓取线程提供自己的数据库连接没有任何意义。随着scraper的增长(您可能最终要在100个不同的线程中从100个不同的网站收集数据)，这可能会转化为大量的数据库连接，这些连接大部分是空闲的，在页面加载之后，它们只会偶尔执行一次写操作。</p>
<p>相反，您可以使用数量更少的数据库线程，每个线程都有自己的连接，可以从队列中取出项目并存储它们。这提供了一组更易于管理的数据库连接。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> urlopen</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> _thread</span><br><span class="line"><span class="keyword">from</span> queue <span class="keyword">import</span> Queue</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> pymysql</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">storage</span><span class="params">(queue)</span>:</span></span><br><span class="line">    conn = pymysql.connect(host=<span class="string">'127.0.0.1'</span>, unix_socket=<span class="string">'/tmp/mysql.sock'</span>, user=<span class="string">'root'</span>, passwd=<span class="string">''</span>, db=<span class="string">'mysql'</span>, charset=<span class="string">'utf8'</span>)</span><br><span class="line">    cur = conn.cursor()</span><br><span class="line">    cur.execute(<span class="string">'USE wiki_threads'</span>)</span><br><span class="line">    <span class="keyword">while</span> <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> queue.empty():</span><br><span class="line">            article = queue.get()</span><br><span class="line">            cur.execute(<span class="string">'SELECT * FROM pages WHERE path = %s'</span>, (article[<span class="string">"path"</span>]))</span><br><span class="line">            <span class="keyword">if</span> cur.rowcount == <span class="number">0</span>:</span><br><span class="line">                print(<span class="string">"Storing article &#123;&#125;"</span>.format(article[<span class="string">"title"</span>]))</span><br><span class="line">                cur.execute(<span class="string">'INSERT INTO pages (title, path) VALUES (%s, %s)'</span>, (article[<span class="string">"title"</span>], article[<span class="string">"path"</span>]))</span><br><span class="line">                conn.commit()</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                print(<span class="string">"Article already exists: &#123;&#125;"</span>.format(article[<span class="string">'title'</span>]))</span><br><span class="line"></span><br><span class="line">visited = []</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getLinks</span><span class="params">(thread_name, bsObj)</span>:</span></span><br><span class="line">    print(<span class="string">'Getting links in &#123;&#125;'</span>.format(thread_name))</span><br><span class="line">    links = bsObj.find(<span class="string">'div'</span>, &#123;<span class="string">'id'</span>:<span class="string">'bodyContent'</span>&#125;).find_all(<span class="string">'a'</span>, href=re.compile(<span class="string">'^(/wiki/)((?!:).)*$'</span>))</span><br><span class="line">    <span class="keyword">return</span> [link <span class="keyword">for</span> link <span class="keyword">in</span> links <span class="keyword">if</span> link <span class="keyword">not</span> <span class="keyword">in</span> visited]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">scrape_article</span><span class="params">(thread_name, path, queue)</span>:</span></span><br><span class="line">    visited.append(path)</span><br><span class="line">    html = urlopen(<span class="string">'http://en.wikipedia.org&#123;&#125;'</span>.format(path))</span><br><span class="line">    time.sleep(<span class="number">5</span>)</span><br><span class="line">    bsObj = BeautifulSoup(html, <span class="string">'html.parser'</span>)</span><br><span class="line">    title = bsObj.find(<span class="string">'h1'</span>).get_text()</span><br><span class="line">    print(<span class="string">'Added &#123;&#125; for storage in thread &#123;&#125;'</span>.format(title, thread_name))</span><br><span class="line">    queue.put(&#123;<span class="string">"title"</span>:title, <span class="string">"path"</span>:path&#125;)</span><br><span class="line">    links = getLinks(thread_name, bsObj)</span><br><span class="line">    <span class="keyword">if</span> len(links) &gt; <span class="number">0</span>:</span><br><span class="line">        newArticle = links[random.randint(<span class="number">0</span>, len(links)<span class="number">-1</span>)].attrs[<span class="string">'href'</span>]</span><br><span class="line">        scrape_article(thread_name, newArticle, queue)</span><br><span class="line"></span><br><span class="line">queue = Queue()</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">   _thread.start_new_thread(scrape_article, (<span class="string">'Thread 1'</span>, <span class="string">'/wiki/Kevin_Bacon'</span>, queue,))</span><br><span class="line">   _thread.start_new_thread(scrape_article, (<span class="string">'Thread 2'</span>, <span class="string">'/wiki/Monty_Python'</span>, queue,))</span><br><span class="line">   _thread.start_new_thread(storage, (queue,))</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">   <span class="keyword">print</span> (<span class="string">'Error: unable to start threads'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="number">1</span>:</span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<p>这个脚本创建了三个线程:两个线程从Wikipedia中随机抓取页面，第三个线程将收集到的数据存储在MySQL数据库中。有关MySQL和数据存储的更多信息，请参见第6章。</p>
<h4 id="The-threading-Module"><a href="#The-threading-Module" class="headerlink" title="The threading Module"></a>The threading Module</h4><p>Python <code>_thread</code>模块是一个相当底层的模块，它允许您对线程进行微管理，但是没有提供很多高级函数来简化工作。<code>threading</code>模块是一个高级接口，它允许您干净地使用线程，同时仍然公开底层_thread的所有特性。</p>
<p>例如，您可以使用enumerate等静态函数来获得通过线程模块初始化的所有活动线程的列表，而不需要自己跟踪它们。activeCount函数同样提供线程总数。_thread中的许多函数都被赋予了更方便或更容易记住的名称，比如currentThread而不是get_ident来获取当前线程的名称。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">print_time</span><span class="params">(threadName, delay, iterations)</span>:</span></span><br><span class="line">    start = int(time.time())</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,iterations):</span><br><span class="line">        time.sleep(delay)</span><br><span class="line">        seconds_elapsed = str(int(time.time()) - start)</span><br><span class="line">        <span class="keyword">print</span> (<span class="string">'&#123;&#125; &#123;&#125;'</span>.format(seconds_elapsed, threadName))</span><br><span class="line"></span><br><span class="line">t = threading.Thread(target=print_time, args=(<span class="string">'Fizz'</span>, <span class="number">3</span>, <span class="number">33</span>)).start()</span><br><span class="line">t = threading.Thread(target=print_time, args=(<span class="string">'Buzz'</span>, <span class="number">5</span>, <span class="number">20</span>)).start()</span><br><span class="line">t = threading.Thread(target=print_time, args=(<span class="string">'Counter'</span>, <span class="number">1</span>, <span class="number">100</span>)).start()</span><br></pre></td></tr></table></figure>
<p>它生成与前面简单<code>_thread</code>示例相同的“FizzBuzz”输出。</p>
<p>线程模块的优点之一是易于创建其他线程不可用的本地线程数据。如果您有多个线程，每个线程都抓取不同的网站，并且每个线程都跟踪自己的本地访问页面列表，那么这可能是一个很好的特性。</p>
<p>这个本地数据可以通过调用<code>thread .local()</code>在thread函数的任何位置创建:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">crawler</span><span class="params">(url)</span>:</span></span><br><span class="line">	data = threading.local()</span><br><span class="line">	data.visited = []</span><br><span class="line">	<span class="comment"># Crawl site</span></span><br><span class="line">threading.Thread(target=crawler, args=(<span class="string">'http://brookings.edu'</span>)).start()</span><br></pre></td></tr></table></figure>
<p>这解决了线程中共享对象之间发生竞争条件的问题。当一个对象不需要被共享时，它不应该被共享，而应该保存在本地线程内存中。为了在线程之间安全地共享对象，仍然可以使用上一节中的队列。    </p>
<p>通常情况下，爬行器的设计运行时间很长。isAlive方法可以确保，如果线程崩溃，它会重新启动:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">threading.Thread(target=crawler)</span><br><span class="line">t.start()</span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">	time.sleep(<span class="number">1</span>)</span><br><span class="line">	<span class="keyword">if</span> <span class="keyword">not</span> t.isAlive():</span><br><span class="line">		t = threading.Thread(target=crawler)</span><br><span class="line">		t.start()</span><br></pre></td></tr></table></figure>
<p>可以通过扩展线程添加其他监视方法。<code>threading.Thread</code>对象:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Crawler</span><span class="params">(threading.Thread)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        threading.Thread.__init__(self)</span><br><span class="line">        self.done = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isDone</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"exe isDone"</span>)</span><br><span class="line">        <span class="keyword">return</span> self.done</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"exe run"</span>)</span><br><span class="line">        time.sleep(<span class="number">5</span>)</span><br><span class="line">        self.done = <span class="literal">True</span></span><br><span class="line">        <span class="keyword">raise</span> Exception(<span class="string">'Something bad happened!'</span>)</span><br><span class="line"></span><br><span class="line">tim = int(time.time())</span><br><span class="line">t = Crawler()</span><br><span class="line">t.start()</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    print(<span class="string">"loop------"</span>)</span><br><span class="line">    now = str(int(time.time())-tim)</span><br><span class="line">    print(now)</span><br><span class="line">    time.sleep(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">if</span> t.isDone():</span><br><span class="line">        print(<span class="string">'Done'</span>)</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> t.isAlive():</span><br><span class="line">        t = Crawler()</span><br><span class="line">        t.start()</span><br></pre></td></tr></table></figure>
<p>这是我加入调试输出的，因此输出如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">exe run</span><br><span class="line">loop------</span><br><span class="line">0</span><br><span class="line">exe isDone</span><br><span class="line">loop------</span><br><span class="line">1</span><br><span class="line">exe isDone</span><br><span class="line">loop------</span><br><span class="line">2</span><br><span class="line">exe isDone</span><br><span class="line">loop------</span><br><span class="line">3</span><br><span class="line">exe isDone</span><br><span class="line">loop------</span><br><span class="line">4</span><br><span class="line">exe isDone</span><br><span class="line">Done</span><br><span class="line">Exception in thread Thread-1:</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;D:\Anaconda3\lib\threading.py&quot;, line 917, in _bootstrap_inner</span><br><span class="line">    self.run()</span><br><span class="line">  File &quot;threading_crawler.py&quot;, line 17, in run</span><br><span class="line">    raise Exception(&apos;Something bad happened!&apos;)</span><br><span class="line">Exception: Something bad happened!</span><br></pre></td></tr></table></figure>
<p>这个新的爬虫类包含一个<code>isDone</code>方法，可以用来检查爬虫程序是否完成了爬行。如果需要完成一些额外的日志记录方法，使线程无法关闭，但是爬行工作的大部分已经完成，那么这可能是有用的。通常，<code>isDone</code>可以替换为某种状态或进度度量——例如，记录了多少页面，或者当前页面。</p>
<p><code>Crawler.run</code>所引发的任何异常都会导致类被重新启动，直到<code>isDone</code>为真且程序退出为止。</p>
<p>扩展<code>threading.Thread</code>在您的爬虫类可以提高他们的健壮性和灵活性，以及您的能力，以监测任何属性的许多爬虫一次。</p>
<h3 id="Multiprocess-Crawling"><a href="#Multiprocess-Crawling" class="headerlink" title="Multiprocess Crawling"></a>Multiprocess Crawling</h3><p>Python<code>Processing</code>处理模块创建了可以从主进程启动和连接的新进程对象。下面的代码使用了线程进程一节中的FizzBuzz示例来演示。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Process</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> freeze_support</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">print_time</span><span class="params">(threadName, delay, iterations)</span>:</span></span><br><span class="line">    start = int(time.time())</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,iterations):</span><br><span class="line">        time.sleep(delay)</span><br><span class="line">        seconds_elapsed = str(int(time.time()) - start)</span><br><span class="line">        <span class="keyword">print</span> (threadName <span class="keyword">if</span> threadName <span class="keyword">else</span> seconds_elapsed)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">processes = []</span><br><span class="line">processes.append(Process(target=print_time, args=(<span class="literal">None</span>, <span class="number">1</span>, <span class="number">100</span>)))</span><br><span class="line">processes.append(Process(target=print_time, args=(<span class="string">"Fizz"</span>, <span class="number">3</span>, <span class="number">33</span>)))</span><br><span class="line">processes.append(Process(target=print_time, args=(<span class="string">"Buzz"</span>, <span class="number">5</span>, <span class="number">20</span>)))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    freeze_support()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> processes:</span><br><span class="line">        p.start()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> processes:</span><br><span class="line">        p.join()</span><br><span class="line">    </span><br><span class="line">print(<span class="string">"Program complete"</span>)</span><br></pre></td></tr></table></figure>
<p>请记住，每个进程都被操作系统。如果您通过OS的活动监视器或任务管理器查看流程，您应该会看到这一点，如图16-1所示</p>
<p><img src="/2019/08/16/WebScraping16/1.png" alt=""></p>
<h4 id="Multiprocess-Crawling-1"><a href="#Multiprocess-Crawling-1" class="headerlink" title="Multiprocess Crawling"></a>Multiprocess Crawling</h4><p>多线程Wikipedia爬行示例可以修改为使用单独的进程，而不是单独的线程:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> urlopen</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Process, Queue</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> Thread</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getLinks</span><span class="params">(bsObj, queue)</span>:</span></span><br><span class="line">    print(<span class="string">'Getting links in &#123;&#125;'</span>.format(os.getpid()))</span><br><span class="line">    links = bsObj.find(<span class="string">'div'</span>, &#123;<span class="string">'id'</span>:<span class="string">'bodyContent'</span>&#125;).find_all(<span class="string">'a'</span>, href=re.compile(<span class="string">'^(/wiki/)((?!:).)*$'</span>))</span><br><span class="line">    <span class="keyword">return</span> [link <span class="keyword">for</span> link <span class="keyword">in</span> links <span class="keyword">if</span> link <span class="keyword">not</span> <span class="keyword">in</span> queue.get()]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">scrape_article</span><span class="params">(path, queue)</span>:</span></span><br><span class="line">    queue.get().append()</span><br><span class="line">    print(<span class="string">"Process &#123;&#125; list is now: &#123;&#125;"</span>.format(os.getpid(), visited))</span><br><span class="line">    html = urlopen(<span class="string">'http://en.wikipedia.org&#123;&#125;'</span>.format(path))</span><br><span class="line">    time.sleep(<span class="number">5</span>)</span><br><span class="line">    bsObj = BeautifulSoup(html, <span class="string">'html.parser'</span>)</span><br><span class="line">    title = bsObj.find(<span class="string">'h1'</span>).get_text()</span><br><span class="line">    print(<span class="string">'Scraping &#123;&#125; in process &#123;&#125;'</span>.format(title, os.getpid()))</span><br><span class="line">    links = getLinks(bsObj)</span><br><span class="line">    <span class="keyword">if</span> len(links) &gt; <span class="number">0</span>:</span><br><span class="line">        newArticle = links[random.randint(<span class="number">0</span>, len(links)<span class="number">-1</span>)].attrs[<span class="string">'href'</span>]</span><br><span class="line">        print(newArticle)</span><br><span class="line">        scrape_article(newArticle)</span><br><span class="line"></span><br><span class="line">processes = []</span><br><span class="line">queue = Queue()</span><br><span class="line">processes.append(Process(target=scrape_article, args=(<span class="string">'/wiki/Kevin_Bacon'</span>, queue,)))</span><br><span class="line">processes.append(Process(target=scrape_article, args=(<span class="string">'/wiki/Monty_Python'</span>, queue,)))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> processes:</span><br><span class="line">    p.start()</span><br></pre></td></tr></table></figure>
<p>同样，通过包含<code>time.sleep(5)</code>，您可以人为地减慢scraper的进程，这样就可以在不给Wikipedia的服务器增加不合理的高负载的情况下使用它。<br>在这里，您将用<code>os.getpid()</code>替换用户定义的<code>thread_name</code>(作为参数传递)，它不需要作为参数传递，并且可以在任何时候访问。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Scraping Kevin Bacon in process 84275</span><br><span class="line">Getting links in 84275</span><br><span class="line">/wiki/Philadelphia</span><br><span class="line">Scraping Monty Python in process 84276</span><br><span class="line">Getting links in 84276</span><br><span class="line">/wiki/BBC</span><br><span class="line">Scraping BBC in process 84276</span><br><span class="line">Getting links in 84276</span><br><span class="line">/wiki/Television_Centre,_Newcastle_upon_Tyne</span><br><span class="line">Scraping Philadelphia in process 84275</span><br></pre></td></tr></table></figure>
<p>从理论上讲，在单独的进程中爬行比在单独的线程中爬行稍微快一些，主要有两个原因:</p>
<ul>
<li>进程不受GIL的锁定限制，可以执行相同的代码行并同时修改相同的对象(实际上是相同对象的单独实例化)。</li>
<li>进程可以运行在多个CPU内核上，如果每个进程或线程都是处理器密集型的，那么这可能会提供速度优势。</li>
</ul>
<p>然而，这些优势伴随着一个主要的缺点。在前面的程序中，所有找到的url都存储在一个全局访问列表中。当您使用多个线程时，此列表在所有线程之间共享;在没有罕见竞争条件的情况下，一个线程不能访问已经被另一个线程访问过的页面。但是，每个进程现在都有自己独立的已访问列表版本，并且可以自由访问其他进程已经访问过的页面。</p>
<h4 id="Communicating-Between-Processes"><a href="#Communicating-Between-Processes" class="headerlink" title="Communicating Between Processes"></a>Communicating Between Processes</h4><p>进程在它们自己的独立内存中运行，如果希望它们共享信息，这可能会导致问题。</p>
<p>修改前一个例子，打印当前输出的访问列表，你可以看到这个原则的行动:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">scrape_article</span><span class="params">(path)</span>:</span></span><br><span class="line">	visited.append(path)</span><br><span class="line">	print(<span class="string">"Process &#123;&#125; list is now: &#123;&#125;"</span>.format(os.getpid(), visited))</span><br></pre></td></tr></table></figure>
<p>这将导致如下输出:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Process 84552 list is now: [&apos;/wiki/Kevin_Bacon&apos;]</span><br><span class="line">Process 84553 list is now: [&apos;/wiki/Monty_Python&apos;]</span><br><span class="line">Scraping Kevin Bacon in process 84552</span><br><span class="line">Getting links in 84552</span><br><span class="line">/wiki/Desert_Storm</span><br><span class="line">Process 84552 list is now: [&apos;/wiki/Kevin_Bacon&apos;, &apos;/wiki/Desert_Storm&apos;]</span><br><span class="line">Scraping Monty Python in process 84553</span><br><span class="line">Getting links in 84553</span><br><span class="line">/wiki/David_Jason</span><br><span class="line">Process 84553 list is now: [&apos;/wiki/Monty_Python&apos;, &apos;/wiki/David_Jason&apos;]</span><br></pre></td></tr></table></figure>
<p>但是有一种方法可以通过两种类型的Python对象(队列和管道)在同一台机器上的进程之间共享信息。队列类似于前面看到的线程队列。信息可以由一个进程放入其中，然后由另一个进程删除。删除此信息后，它将从队列中删除。因为队列被设计为“临时数据传输”，它们不太适合保存静态引用，如“已访问的网页列表”。</p>
<p>但是，如果这个静态的web页面列表被某种类型的抓取委托器所替代呢?刮刀可以弹出一个任务队列的形式从一个路径刮(例如,/ wiki / Monty_Python)作为回报,添加一个列表,发现url回到一个单独的队列处理刮的全权代表,因此只有新url添加到第一个任务队列。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> urlopen</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Process, Queue</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">task_delegator</span><span class="params">(taskQueue, foundUrlsQueue)</span>:</span></span><br><span class="line">    <span class="comment">#Initialize with a task for each process</span></span><br><span class="line">    visited = [<span class="string">'/wiki/Kevin_Bacon'</span>, <span class="string">'/wiki/Monty_Python'</span>]</span><br><span class="line">    taskQueue.put(<span class="string">'/wiki/Kevin_Bacon'</span>)</span><br><span class="line">    taskQueue.put(<span class="string">'/wiki/Monty_Python'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> <span class="number">1</span>:</span><br><span class="line">        <span class="comment">#Check to see if there are new links in the foundUrlsQueue for processing</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> foundUrlsQueue.empty():</span><br><span class="line">            links = [link <span class="keyword">for</span> link <span class="keyword">in</span> foundUrlsQueue.get() <span class="keyword">if</span> link <span class="keyword">not</span> <span class="keyword">in</span> visited]</span><br><span class="line">            <span class="keyword">for</span> link <span class="keyword">in</span> links:</span><br><span class="line">                <span class="comment">#Add new link to the taskQueue</span></span><br><span class="line">                taskQueue.put(link)</span><br><span class="line">                <span class="comment">#Add new link to the visited list</span></span><br><span class="line">                visited.append(link)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_links</span><span class="params">(bsObj)</span>:</span></span><br><span class="line">    links = bsObj.find(<span class="string">'div'</span>, &#123;<span class="string">'id'</span>:<span class="string">'bodyContent'</span>&#125;).find_all(<span class="string">'a'</span>, href=re.compile(<span class="string">'^(/wiki/)((?!:).)*$'</span>))</span><br><span class="line">    <span class="keyword">return</span> [link.attrs[<span class="string">'href'</span>] <span class="keyword">for</span> link <span class="keyword">in</span> links]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">scrape_article</span><span class="params">(taskQueue, foundUrlsQueue)</span>:</span></span><br><span class="line">    <span class="keyword">while</span> <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">while</span> taskQueue.empty():</span><br><span class="line">            <span class="comment">#Sleep 100 ms while waiting for the task queue </span></span><br><span class="line">            <span class="comment">#This should be rare</span></span><br><span class="line">            time.sleep(<span class="number">.1</span>)</span><br><span class="line">        path = taskQueue.get()</span><br><span class="line">        html = urlopen(<span class="string">'http://en.wikipedia.org&#123;&#125;'</span>.format(path))</span><br><span class="line">        time.sleep(<span class="number">5</span>)</span><br><span class="line">        bsObj = BeautifulSoup(html, <span class="string">'html.parser'</span>)</span><br><span class="line">        title = bsObj.find(<span class="string">'h1'</span>).get_text()</span><br><span class="line">        print(<span class="string">'Scraping &#123;&#125; in process &#123;&#125;'</span>.format(title, os.getpid()))</span><br><span class="line">        links = get_links(bsObj)</span><br><span class="line">        <span class="comment">#Send these to the delegator for processing</span></span><br><span class="line">        foundUrlsQueue.put(links)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">processes = []</span><br><span class="line">taskQueue = Queue()</span><br><span class="line">foundUrlsQueue = Queue()</span><br><span class="line">processes.append(Process(target=task_delegator, args=(taskQueue, foundUrlsQueue,)))</span><br><span class="line">processes.append(Process(target=scrape_article, args=(taskQueue, foundUrlsQueue,)))</span><br><span class="line">processes.append(Process(target=scrape_article, args=(taskQueue, foundUrlsQueue,)))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> processes:</span><br><span class="line">    p.start()</span><br></pre></td></tr></table></figure>
<p>此爬虫与最初制造的铲运机在结构上存在一些差异。不是每个进程或线程从它们被分配的起点开始按照自己的随机游走，而是一起对网站进行完整的覆盖爬行。每个进程都可以从队列中提取任何“任务”，而不仅仅是它们自己找到的链接。</p>
<h3 id="Multiprocess-Crawling—Another-Approach"><a href="#Multiprocess-Crawling—Another-Approach" class="headerlink" title="Multiprocess Crawling—Another Approach"></a>Multiprocess Crawling—Another Approach</h3><p>所有讨论的多线程和进程爬行的方法都假定您需要对子线程和进程进行某种“父级指导”。<br>您可以同时启动它们，也可以同时结束它们，还可以在它们之间发送消息或共享内存。</p>
<p>但是，如果您的爬虫的设计方式是不需要指导或通信的呢?也许没有什么理由开始疯狂<code>import _thread</code>。</p>
<p>例如，假设您想并行爬行两个类似的网站。您已经编写了一个爬行器，它可以爬行这两个网站中的任何一个，由一个小的配置更改或命令行参数决定。你完全没有理由不能简单地做以下事情:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ python my_crawler.py website1</span><br><span class="line">$ python my_crawler.py website2</span><br></pre></td></tr></table></figure>
<p>瞧，您刚刚启动了一个多进程web爬虫程序，同时节省了您的CPU维护要引导的父进程的开销!</p>
<p>当然，这种方法也有缺点。如果您想以这种方式在同一个网站上运行两个web爬虫程序，您需要某种方法来确保它们不会意外地开始抓取相同的页面。解决方案可能是创建一个URL规则(“爬虫1抓取博客页面，爬虫2抓取产品页面”)或以某种方式分割站点。</p>
<p>或者，您可以通过某种中间数据库来处理这种协调。在进入一个新的链接之前，爬虫程序可能会向数据库发出一个请求，询问这个页面是否已被爬行?爬虫程序使用数据库作为进程间通信系统。当然，如果没有仔细考虑，如果数据库连接很慢，这种方法可能会导致竞争条件或延迟(只有在连接到远程数据库时才可能出现问题)。</p>
<p>您可能还会发现，这种方法的可伸缩性不太好。使用Process模块可以动态地增加或减少爬行站点的进程数量，甚至可以存储数据。手动启动它们需要一个人亲自运行脚本或一个单独的管理脚本(无论是bash脚本、cron作业还是其他东西)来完成此任务。<br>然而，这是我过去成功地使用过的一种方法。对于小型的one - off项目，它是快速获取大量信息的好方法，尤其是跨多个网站。</p>

      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Web-Scraping/" rel="tag"># Web-Scraping</a>
          
            <a href="/tags/python/" rel="tag"># python</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/08/09/WebScraping15/" rel="next" title="WebScraping-15">
                <i class="fa fa-chevron-left"></i> WebScraping-15
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/08/17/WebScraping17/" rel="prev" title="WebScraping-17">
                WebScraping-17 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          
  <div class="comments" id="comments"></div>
    
    <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
    <script src="//cdn.jsdelivr.net/npm/valine@1.1.6/dist/Valine.min.js"></script>
    <script>
        new Valine({
            av: AV,
            el: '.comments',
            notify: true, // 邮件提醒 v1.1.4新增，下一步中有具体的邮箱设置
            verify: true,
            app_id: '',
            app_key: '',
            placeholder: 'ヾﾉ≧∀≦)o来啊，快活啊!'
        });
    </script>
    

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/avatar.jpg" alt="spring">
            
              <p class="site-author-name" itemprop="name">spring</p>
              <p class="site-description motion-element" itemprop="description">梦想天空分外蓝~</p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">51</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  <a href="/categories/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">12</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">27</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              



            </nav>
          

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  <a href="https://github.com/ninanxiaoguai" target="_blank" title="GitHub"><i class="fa fa-fw fa-github"></i>GitHub</a>
                  
                </span>
              
                <span class="links-of-author-item">
                  <a href="mailto:ninanxiaoguai@163.com" target="_blank" title="E-Mail"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  
                </span>
              
            </div>
          

          
          

          
          

          
            
          
          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#Processes-versus-Threads"><span class="nav-number">1.</span> <span class="nav-text">Processes versus Threads</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Multithreaded-Crawling"><span class="nav-number">2.</span> <span class="nav-text">Multithreaded Crawling</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Race-Conditions-and-Queues"><span class="nav-number">2.1.</span> <span class="nav-text">Race Conditions and Queues</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#The-threading-Module"><span class="nav-number">2.2.</span> <span class="nav-text">The threading Module</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Multiprocess-Crawling"><span class="nav-number">3.</span> <span class="nav-text">Multiprocess Crawling</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Multiprocess-Crawling-1"><span class="nav-number">3.1.</span> <span class="nav-text">Multiprocess Crawling</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Communicating-Between-Processes"><span class="nav-number">3.2.</span> <span class="nav-text">Communicating Between Processes</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Multiprocess-Crawling—Another-Approach"><span class="nav-number">4.</span> <span class="nav-text">Multiprocess Crawling—Another Approach</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        
<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

<div class="copyright">
  <!--
  &copy; 

<span itemprop="copyrightYear">2020</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">spring</span>
-->
  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">站点总字数：</span>
    
    <span title="站点总字数">458k</span>
  

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    
    <span title="站点阅读时长">6:57</span>
  
</div>




<span>
  Hosted by <a href="https://pages.coding.me" style="font-weight: bold">Coding Pages</a>
 </span>




<!--

<div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动 v3.9.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 – <a class="theme-link" target="_blank" href="https://theme-next.org">NexT.Muse</a> v6.3.0</div>


-->



        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    
	
    

    
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


















  
  









  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/three/three.min.js"></script>
  

  
  
    <script type="text/javascript" src="/lib/three/canvas_lines.min.js"></script>
  


  



  <script type="text/javascript" src="/js/src/utils.js?v=6.3.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=6.3.0"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=6.3.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=6.3.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=6.3.0"></script>



  






  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  
  
  <script src="//unpkg.com/valine/dist/Valine.min.js"></script>
  
  <script type="text/javascript">
    var GUEST = ['nick','mail','link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(function (item) {
      return GUEST.indexOf(item)>-1;
    });
    new Valine({
        el: '#comments' ,
        verify: false,
        notify: false,
        appId: 'NUATd6a1PUQYtIT7MpFYzq4X-gzGzoHsz',
        appKey: 'Iny9yO41c59ioJOJc84vGygI',
        placeholder: '如果填写邮箱，可以直接回复至您邮箱中~',
        avatar:'mm',
        meta:guest,
        pageSize:'10' || 10,
        visitor: true
    });
  </script>



  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  
  

  
  

  
    
      <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      },
      TeX: {equationNumbers: { autoNumber: "AMS" }}
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

    
  


  
  

  

  

  

  

  

</body>
</html>
